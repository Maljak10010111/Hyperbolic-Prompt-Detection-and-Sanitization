2025-06-02 12:37:06,016 - root - INFO - Log file is ../log/log.txt.
2025-06-02 12:37:06,016 - root - INFO - Data path is ../data.
2025-06-02 12:37:06,016 - root - INFO - Export path is ../log.
2025-06-02 12:37:06,016 - root - INFO - Dataset: visu
2025-06-02 12:37:06,016 - root - INFO - Normal class: 0
2025-06-02 12:37:06,016 - root - INFO - Network: mlp
2025-06-02 12:37:06,016 - root - INFO - Deep SVDD objective: one-class
2025-06-02 12:37:06,016 - root - INFO - Nu-paramerter: 0.10
2025-06-02 12:37:06,016 - root - INFO - Computation device: cpu
2025-06-02 12:37:06,016 - root - INFO - Number of dataloader workers: 0
2025-06-02 12:38:18,859 - root - INFO - Log file is ../log/log.txt.
2025-06-02 12:38:18,859 - root - INFO - Data path is ../data.
2025-06-02 12:38:18,859 - root - INFO - Export path is ../log.
2025-06-02 12:38:18,859 - root - INFO - Dataset: visu
2025-06-02 12:38:18,859 - root - INFO - Normal class: 0
2025-06-02 12:38:18,859 - root - INFO - Network: mlp
2025-06-02 12:38:18,859 - root - INFO - Deep SVDD objective: one-class
2025-06-02 12:38:18,859 - root - INFO - Nu-paramerter: 0.10
2025-06-02 12:38:18,859 - root - INFO - Computation device: cpu
2025-06-02 12:38:18,859 - root - INFO - Number of dataloader workers: 0
2025-06-02 12:39:22,885 - root - INFO - Log file is ../log/log.txt.
2025-06-02 12:39:22,885 - root - INFO - Data path is ../data.
2025-06-02 12:39:22,885 - root - INFO - Export path is ../log.
2025-06-02 12:39:22,900 - root - INFO - Dataset: visu
2025-06-02 12:39:22,900 - root - INFO - Normal class: 0
2025-06-02 12:39:22,900 - root - INFO - Network: mlp
2025-06-02 12:39:22,900 - root - INFO - Deep SVDD objective: one-class
2025-06-02 12:39:22,900 - root - INFO - Nu-paramerter: 0.10
2025-06-02 12:39:22,900 - root - INFO - Computation device: cpu
2025-06-02 12:39:22,900 - root - INFO - Number of dataloader workers: 0
2025-06-02 12:40:23,377 - root - INFO - Log file is ../log/log.txt.
2025-06-02 12:40:23,377 - root - INFO - Data path is ../data.
2025-06-02 12:40:23,377 - root - INFO - Export path is ../log.
2025-06-02 12:40:23,377 - root - INFO - Dataset: visu
2025-06-02 12:40:23,377 - root - INFO - Normal class: 0
2025-06-02 12:40:23,377 - root - INFO - Network: mlp
2025-06-02 12:40:23,377 - root - INFO - Deep SVDD objective: one-class
2025-06-02 12:40:23,377 - root - INFO - Nu-paramerter: 0.10
2025-06-02 12:40:23,377 - root - INFO - Computation device: cpu
2025-06-02 12:40:23,377 - root - INFO - Number of dataloader workers: 0
2025-06-02 12:41:26,862 - root - INFO - Log file is ../log/log.txt.
2025-06-02 12:41:26,862 - root - INFO - Data path is ../data.
2025-06-02 12:41:26,862 - root - INFO - Export path is ../log.
2025-06-02 12:41:26,862 - root - INFO - Dataset: visu
2025-06-02 12:41:26,862 - root - INFO - Normal class: 0
2025-06-02 12:41:26,862 - root - INFO - Network: mlp
2025-06-02 12:41:26,862 - root - INFO - Deep SVDD objective: one-class
2025-06-02 12:41:26,862 - root - INFO - Nu-paramerter: 0.10
2025-06-02 12:41:26,862 - root - INFO - Computation device: cpu
2025-06-02 12:41:26,862 - root - INFO - Number of dataloader workers: 0
2025-06-02 12:42:22,956 - root - INFO - Log file is ../log/log.txt.
2025-06-02 12:42:22,956 - root - INFO - Data path is ../data.
2025-06-02 12:42:22,956 - root - INFO - Export path is ../log.
2025-06-02 12:42:22,956 - root - INFO - Dataset: visu
2025-06-02 12:42:22,956 - root - INFO - Normal class: 0
2025-06-02 12:42:22,956 - root - INFO - Network: mlp
2025-06-02 12:42:22,956 - root - INFO - Deep SVDD objective: one-class
2025-06-02 12:42:22,956 - root - INFO - Nu-paramerter: 0.10
2025-06-02 12:42:22,956 - root - INFO - Computation device: cpu
2025-06-02 12:42:22,956 - root - INFO - Number of dataloader workers: 0
2025-06-02 12:42:23,254 - root - INFO - Pretraining: True
2025-06-02 12:42:23,254 - root - INFO - Pretraining optimizer: adam
2025-06-02 12:42:23,254 - root - INFO - Pretraining learning rate: 0.001
2025-06-02 12:42:23,254 - root - INFO - Pretraining epochs: 100
2025-06-02 12:42:23,254 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-02 12:42:23,254 - root - INFO - Pretraining batch size: 128
2025-06-02 12:42:23,254 - root - INFO - Pretraining weight decay: 1e-06
2025-06-02 12:44:39,017 - root - INFO - Log file is ../log/log.txt.
2025-06-02 12:44:39,017 - root - INFO - Data path is ../data.
2025-06-02 12:44:39,017 - root - INFO - Export path is ../log.
2025-06-02 12:44:39,017 - root - INFO - Dataset: visu
2025-06-02 12:44:39,017 - root - INFO - Normal class: 0
2025-06-02 12:44:39,017 - root - INFO - Network: mlp
2025-06-02 12:44:39,017 - root - INFO - Deep SVDD objective: one-class
2025-06-02 12:44:39,017 - root - INFO - Nu-paramerter: 0.10
2025-06-02 12:44:39,017 - root - INFO - Computation device: cpu
2025-06-02 12:44:39,017 - root - INFO - Number of dataloader workers: 0
2025-06-02 12:44:39,284 - root - INFO - Pretraining: True
2025-06-02 12:44:39,284 - root - INFO - Pretraining optimizer: adam
2025-06-02 12:44:39,284 - root - INFO - Pretraining learning rate: 0.001
2025-06-02 12:44:39,284 - root - INFO - Pretraining epochs: 100
2025-06-02 12:44:39,284 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-02 12:44:39,284 - root - INFO - Pretraining batch size: 128
2025-06-02 12:44:39,284 - root - INFO - Pretraining weight decay: 1e-06
2025-06-02 12:44:39,304 - root - INFO - Starting pretraining...
2025-06-02 13:59:08,956 - root - INFO - Log file is ../log/log.txt.
2025-06-02 13:59:08,956 - root - INFO - Data path is ../data.
2025-06-02 13:59:08,956 - root - INFO - Export path is ../log.
2025-06-02 13:59:08,956 - root - INFO - Dataset: visu
2025-06-02 13:59:08,956 - root - INFO - Normal class: 0
2025-06-02 13:59:08,972 - root - INFO - Network: mlp
2025-06-02 13:59:08,972 - root - INFO - Deep SVDD objective: one-class
2025-06-02 13:59:08,972 - root - INFO - Nu-paramerter: 0.10
2025-06-02 13:59:08,972 - root - INFO - Computation device: cpu
2025-06-02 13:59:08,972 - root - INFO - Number of dataloader workers: 0
2025-06-02 13:59:09,185 - root - INFO - Pretraining: True
2025-06-02 13:59:09,185 - root - INFO - Pretraining optimizer: adam
2025-06-02 13:59:09,185 - root - INFO - Pretraining learning rate: 0.001
2025-06-02 13:59:09,185 - root - INFO - Pretraining epochs: 100
2025-06-02 13:59:09,185 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-02 13:59:09,200 - root - INFO - Pretraining batch size: 128
2025-06-02 13:59:09,200 - root - INFO - Pretraining weight decay: 1e-06
2025-06-02 13:59:09,200 - root - INFO - Starting pretraining...
2025-06-02 14:09:41,681 - root - INFO - Log file is ../log/log.txt.
2025-06-02 14:09:41,681 - root - INFO - Data path is ../data.
2025-06-02 14:09:41,681 - root - INFO - Export path is ../log.
2025-06-02 14:09:41,681 - root - INFO - Dataset: visu
2025-06-02 14:09:41,681 - root - INFO - Normal class: 0
2025-06-02 14:09:41,681 - root - INFO - Network: mlp
2025-06-02 14:09:41,681 - root - INFO - Deep SVDD objective: one-class
2025-06-02 14:09:41,681 - root - INFO - Nu-paramerter: 0.10
2025-06-02 14:09:41,681 - root - INFO - Computation device: cpu
2025-06-02 14:09:41,681 - root - INFO - Number of dataloader workers: 0
2025-06-02 14:09:41,948 - root - INFO - Pretraining: True
2025-06-02 14:09:41,948 - root - INFO - Pretraining optimizer: adam
2025-06-02 14:09:41,948 - root - INFO - Pretraining learning rate: 0.001
2025-06-02 14:09:41,948 - root - INFO - Pretraining epochs: 100
2025-06-02 14:09:41,948 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-02 14:09:41,948 - root - INFO - Pretraining batch size: 64
2025-06-02 14:09:41,948 - root - INFO - Pretraining weight decay: 1e-06
2025-06-02 14:09:41,979 - root - INFO - Starting pretraining...
2025-06-02 14:10:19,496 - root - INFO -   Epoch 1/100	 Time: 37.517	 Loss: 0.03822794
2025-06-02 14:10:57,335 - root - INFO -   Epoch 2/100	 Time: 37.838	 Loss: 0.02457654
2025-06-02 14:11:34,474 - root - INFO -   Epoch 3/100	 Time: 37.139	 Loss: 0.02097147
2025-06-02 14:12:11,742 - root - INFO -   Epoch 4/100	 Time: 37.268	 Loss: 0.01927047
2025-06-02 14:12:48,987 - root - INFO -   Epoch 5/100	 Time: 37.245	 Loss: 0.01811125
2025-06-02 14:13:26,465 - root - INFO -   Epoch 6/100	 Time: 37.477	 Loss: 0.01717181
2025-06-02 14:14:03,920 - root - INFO -   Epoch 7/100	 Time: 37.455	 Loss: 0.01645298
2025-06-02 14:14:41,362 - root - INFO -   Epoch 8/100	 Time: 37.442	 Loss: 0.01592257
2025-06-02 14:15:19,029 - root - INFO -   Epoch 9/100	 Time: 37.668	 Loss: 0.01550568
2025-06-02 14:15:56,819 - root - INFO -   Epoch 10/100	 Time: 37.790	 Loss: 0.01521808
2025-06-02 14:16:34,841 - root - INFO -   Epoch 11/100	 Time: 38.022	 Loss: 0.01494522
2025-06-02 14:17:12,903 - root - INFO -   Epoch 12/100	 Time: 38.046	 Loss: 0.01475395
2025-06-02 14:17:50,525 - root - INFO -   Epoch 13/100	 Time: 37.607	 Loss: 0.01456282
2025-06-02 14:18:28,395 - root - INFO -   Epoch 14/100	 Time: 37.869	 Loss: 0.01439204
2025-06-02 14:19:06,118 - root - INFO -   Epoch 15/100	 Time: 37.722	 Loss: 0.01425126
2025-06-02 14:19:43,709 - root - INFO -   Epoch 16/100	 Time: 37.591	 Loss: 0.01413437
2025-06-02 14:20:21,363 - root - INFO -   Epoch 17/100	 Time: 37.653	 Loss: 0.01401151
2025-06-02 14:20:59,126 - root - INFO -   Epoch 18/100	 Time: 37.763	 Loss: 0.01388090
2025-06-02 14:21:37,370 - root - INFO -   Epoch 19/100	 Time: 38.244	 Loss: 0.01373632
2025-06-02 14:22:16,725 - root - INFO -   Epoch 20/100	 Time: 39.355	 Loss: 0.01362947
2025-06-02 14:22:57,186 - root - INFO -   Epoch 21/100	 Time: 40.462	 Loss: 0.01354388
2025-06-02 14:23:38,566 - root - INFO -   Epoch 22/100	 Time: 41.380	 Loss: 0.01346404
2025-06-02 14:24:20,737 - root - INFO -   Epoch 23/100	 Time: 42.171	 Loss: 0.01338726
2025-06-02 14:25:06,282 - root - INFO -   Epoch 24/100	 Time: 45.544	 Loss: 0.01330769
2025-06-02 14:25:51,310 - root - INFO -   Epoch 25/100	 Time: 45.029	 Loss: 0.01322828
2025-06-02 14:26:37,941 - root - INFO -   Epoch 26/100	 Time: 46.631	 Loss: 0.01313366
2025-06-02 14:27:27,022 - root - INFO -   Epoch 27/100	 Time: 49.082	 Loss: 0.01306423
2025-06-02 14:28:19,880 - root - INFO -   Epoch 28/100	 Time: 52.858	 Loss: 0.01300077
2025-06-02 14:29:12,796 - root - INFO -   Epoch 29/100	 Time: 52.916	 Loss: 0.01294856
2025-06-02 14:30:04,497 - root - INFO -   Epoch 30/100	 Time: 51.700	 Loss: 0.01290570
2025-06-02 14:30:54,432 - root - INFO -   Epoch 31/100	 Time: 49.935	 Loss: 0.01285840
2025-06-02 14:31:43,848 - root - INFO -   Epoch 32/100	 Time: 49.415	 Loss: 0.01281137
2025-06-02 14:32:34,395 - root - INFO -   Epoch 33/100	 Time: 50.547	 Loss: 0.01276125
2025-06-02 14:33:24,014 - root - INFO -   Epoch 34/100	 Time: 49.619	 Loss: 0.01271464
2025-06-02 14:34:15,031 - root - INFO -   Epoch 35/100	 Time: 51.016	 Loss: 0.01267928
2025-06-02 14:35:07,564 - root - INFO -   Epoch 36/100	 Time: 52.534	 Loss: 0.01265348
2025-06-02 14:35:59,164 - root - INFO -   Epoch 37/100	 Time: 51.600	 Loss: 0.01262380
2025-06-02 14:36:52,005 - root - INFO -   Epoch 38/100	 Time: 52.841	 Loss: 0.01260447
2025-06-02 14:37:46,352 - root - INFO -   Epoch 39/100	 Time: 54.346	 Loss: 0.01258032
2025-06-02 14:38:37,334 - root - INFO -   Epoch 40/100	 Time: 50.982	 Loss: 0.01255776
2025-06-02 14:39:28,291 - root - INFO -   Epoch 41/100	 Time: 50.957	 Loss: 0.01254373
2025-06-02 14:40:20,699 - root - INFO -   Epoch 42/100	 Time: 52.408	 Loss: 0.01251739
2025-06-02 14:41:13,796 - root - INFO -   Epoch 43/100	 Time: 53.096	 Loss: 0.01248527
2025-06-02 14:42:04,704 - root - INFO -   Epoch 44/100	 Time: 50.908	 Loss: 0.01245176
2025-06-02 14:42:55,306 - root - INFO -   Epoch 45/100	 Time: 50.601	 Loss: 0.01243475
2025-06-02 14:43:45,561 - root - INFO -   Epoch 46/100	 Time: 50.255	 Loss: 0.01240422
2025-06-02 14:44:36,356 - root - INFO -   Epoch 47/100	 Time: 50.796	 Loss: 0.01238684
2025-06-02 14:45:27,058 - root - INFO -   Epoch 48/100	 Time: 50.701	 Loss: 0.01235361
2025-06-02 14:46:18,962 - root - INFO -   Epoch 49/100	 Time: 51.903	 Loss: 0.01234318
2025-06-02 14:47:11,120 - root - INFO -   Epoch 50/100	 Time: 52.158	 Loss: 0.01233057
2025-06-02 14:48:04,255 - root - INFO -   Epoch 51/100	 Time: 53.134	 Loss: 0.01231786
2025-06-02 14:48:54,597 - root - INFO -   Epoch 52/100	 Time: 50.341	 Loss: 0.01229930
2025-06-02 14:49:43,718 - root - INFO -   Epoch 53/100	 Time: 49.120	 Loss: 0.01229169
2025-06-02 14:50:32,594 - root - INFO -   Epoch 54/100	 Time: 48.877	 Loss: 0.01227738
2025-06-02 14:51:21,402 - root - INFO -   Epoch 55/100	 Time: 48.807	 Loss: 0.01228250
2025-06-02 14:52:10,219 - root - INFO -   Epoch 56/100	 Time: 48.818	 Loss: 0.01226060
2025-06-02 14:52:59,099 - root - INFO -   Epoch 57/100	 Time: 48.879	 Loss: 0.01225664
2025-06-02 14:53:48,259 - root - INFO -   Epoch 58/100	 Time: 49.160	 Loss: 0.01225197
2025-06-02 14:54:37,016 - root - INFO -   Epoch 59/100	 Time: 48.757	 Loss: 0.01224412
2025-06-02 14:55:25,885 - root - INFO -   Epoch 60/100	 Time: 48.867	 Loss: 0.01222827
2025-06-02 14:56:14,599 - root - INFO -   Epoch 61/100	 Time: 48.714	 Loss: 0.01222738
2025-06-02 14:57:04,045 - root - INFO -   Epoch 62/100	 Time: 49.446	 Loss: 0.01221255
2025-06-02 14:57:52,947 - root - INFO -   Epoch 63/100	 Time: 48.901	 Loss: 0.01221116
2025-06-02 14:58:41,953 - root - INFO -   Epoch 64/100	 Time: 49.005	 Loss: 0.01221009
2025-06-02 14:59:33,152 - root - INFO -   Epoch 65/100	 Time: 51.199	 Loss: 0.01219505
2025-06-02 15:00:22,426 - root - INFO -   Epoch 66/100	 Time: 49.273	 Loss: 0.01219094
2025-06-02 15:01:14,162 - root - INFO -   Epoch 67/100	 Time: 51.736	 Loss: 0.01218322
2025-06-02 15:02:04,028 - root - INFO -   Epoch 68/100	 Time: 49.866	 Loss: 0.01217048
2025-06-02 15:02:52,907 - root - INFO -   Epoch 69/100	 Time: 48.878	 Loss: 0.01215892
2025-06-02 15:03:41,889 - root - INFO -   Epoch 70/100	 Time: 48.981	 Loss: 0.01214536
2025-06-02 15:04:31,832 - root - INFO -   Epoch 71/100	 Time: 49.943	 Loss: 0.01211370
2025-06-02 15:05:20,556 - root - INFO -   Epoch 72/100	 Time: 48.723	 Loss: 0.01209913
2025-06-02 15:06:09,174 - root - INFO -   Epoch 73/100	 Time: 48.618	 Loss: 0.01207247
2025-06-02 15:06:58,418 - root - INFO -   Epoch 74/100	 Time: 49.244	 Loss: 0.01206145
2025-06-02 15:07:47,928 - root - INFO -   Epoch 75/100	 Time: 49.509	 Loss: 0.01205516
2025-06-02 15:08:37,468 - root - INFO -   Epoch 76/100	 Time: 49.540	 Loss: 0.01204751
2025-06-02 15:09:26,864 - root - INFO -   Epoch 77/100	 Time: 49.396	 Loss: 0.01203605
2025-06-02 15:10:15,110 - root - INFO -   Epoch 78/100	 Time: 48.246	 Loss: 0.01202160
2025-06-02 15:11:06,109 - root - INFO -   Epoch 79/100	 Time: 50.998	 Loss: 0.01201676
2025-06-02 15:11:56,682 - root - INFO -   Epoch 80/100	 Time: 50.573	 Loss: 0.01200560
2025-06-02 15:12:46,832 - root - INFO -   Epoch 81/100	 Time: 50.149	 Loss: 0.01201239
2025-06-02 15:13:35,226 - root - INFO -   Epoch 82/100	 Time: 48.393	 Loss: 0.01199622
2025-06-02 15:14:23,559 - root - INFO -   Epoch 83/100	 Time: 48.332	 Loss: 0.01199552
2025-06-02 15:15:11,904 - root - INFO -   Epoch 84/100	 Time: 48.344	 Loss: 0.01199292
2025-06-02 15:16:00,104 - root - INFO -   Epoch 85/100	 Time: 48.200	 Loss: 0.01197614
2025-06-02 15:16:48,534 - root - INFO -   Epoch 86/100	 Time: 48.429	 Loss: 0.01198223
2025-06-02 15:17:37,480 - root - INFO -   Epoch 87/100	 Time: 48.945	 Loss: 0.01197770
2025-06-02 15:18:25,719 - root - INFO -   Epoch 88/100	 Time: 48.239	 Loss: 0.01196457
2025-06-02 15:19:14,294 - root - INFO -   Epoch 89/100	 Time: 48.574	 Loss: 0.01196693
2025-06-02 15:20:05,496 - root - INFO -   Epoch 90/100	 Time: 51.201	 Loss: 0.01196196
2025-06-02 15:20:54,140 - root - INFO -   Epoch 91/100	 Time: 48.644	 Loss: 0.01195988
2025-06-02 15:21:42,778 - root - INFO -   Epoch 92/100	 Time: 48.637	 Loss: 0.01195667
2025-06-02 15:22:31,454 - root - INFO -   Epoch 93/100	 Time: 48.675	 Loss: 0.01195879
2025-06-02 15:23:20,090 - root - INFO -   Epoch 94/100	 Time: 48.635	 Loss: 0.01194694
2025-06-02 15:24:08,748 - root - INFO -   Epoch 95/100	 Time: 48.658	 Loss: 0.01194697
2025-06-02 15:24:57,458 - root - INFO -   Epoch 96/100	 Time: 48.710	 Loss: 0.01194739
2025-06-02 15:25:46,515 - root - INFO -   Epoch 97/100	 Time: 49.055	 Loss: 0.01193444
2025-06-02 15:26:36,085 - root - INFO -   Epoch 98/100	 Time: 49.570	 Loss: 0.01194687
2025-06-02 15:27:26,419 - root - INFO -   Epoch 99/100	 Time: 50.333	 Loss: 0.01193648
2025-06-02 15:28:16,167 - root - INFO -   Epoch 100/100	 Time: 49.748	 Loss: 0.01193221
2025-06-02 15:28:16,168 - root - INFO - Pretraining time: 4714.189
2025-06-02 15:28:16,168 - root - INFO - Finished pretraining.
2025-06-02 15:28:16,175 - root - INFO - Testing autoencoder...
2025-06-02 15:33:19,829 - root - INFO - Log file is ../log/log.txt.
2025-06-02 15:33:19,829 - root - INFO - Data path is ../data.
2025-06-02 15:33:19,829 - root - INFO - Export path is ../log.
2025-06-02 15:33:19,830 - root - INFO - Dataset: visu
2025-06-02 15:33:19,830 - root - INFO - Normal class: 0
2025-06-02 15:33:19,830 - root - INFO - Network: mlp
2025-06-02 15:33:19,830 - root - INFO - Deep SVDD objective: one-class
2025-06-02 15:33:19,830 - root - INFO - Nu-paramerter: 0.10
2025-06-02 15:33:19,831 - root - INFO - Computation device: cpu
2025-06-02 15:33:19,831 - root - INFO - Number of dataloader workers: 0
2025-06-02 15:33:20,126 - root - INFO - Pretraining: False
2025-06-02 15:33:20,127 - root - INFO - Training optimizer: adam
2025-06-02 15:33:20,127 - root - INFO - Training learning rate: 0.001
2025-06-02 15:33:20,127 - root - INFO - Training epochs: 50
2025-06-02 15:33:20,127 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-02 15:33:20,127 - root - INFO - Training batch size: 128
2025-06-02 15:33:20,127 - root - INFO - Training weight decay: 1e-06
2025-06-02 15:33:20,128 - root - INFO - Initializing center c...
2025-06-02 15:34:17,348 - root - INFO - Log file is ../log/log.txt.
2025-06-02 15:34:17,348 - root - INFO - Data path is ../data.
2025-06-02 15:34:17,349 - root - INFO - Export path is ../log.
2025-06-02 15:34:17,349 - root - INFO - Dataset: visu
2025-06-02 15:34:17,349 - root - INFO - Normal class: 0
2025-06-02 15:34:17,349 - root - INFO - Network: mlp
2025-06-02 15:34:17,349 - root - INFO - Deep SVDD objective: one-class
2025-06-02 15:34:17,349 - root - INFO - Nu-paramerter: 0.10
2025-06-02 15:34:17,349 - root - INFO - Computation device: cpu
2025-06-02 15:34:17,349 - root - INFO - Number of dataloader workers: 0
2025-06-02 15:34:17,494 - root - INFO - Pretraining: True
2025-06-02 15:34:17,494 - root - INFO - Pretraining optimizer: adam
2025-06-02 15:34:17,494 - root - INFO - Pretraining learning rate: 0.001
2025-06-02 15:34:17,494 - root - INFO - Pretraining epochs: 100
2025-06-02 15:34:17,494 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-02 15:34:17,495 - root - INFO - Pretraining batch size: 64
2025-06-02 15:34:17,495 - root - INFO - Pretraining weight decay: 1e-06
2025-06-02 15:34:17,502 - root - INFO - Starting pretraining...
2025-06-02 15:34:52,749 - root - INFO -   Epoch 1/100	 Time: 35.246	 Loss: 0.03880362
2025-06-02 15:35:39,211 - root - INFO -   Epoch 2/100	 Time: 46.462	 Loss: 0.02484403
2025-06-02 15:36:26,006 - root - INFO -   Epoch 3/100	 Time: 46.795	 Loss: 0.02155926
2025-06-02 15:37:08,276 - root - INFO -   Epoch 4/100	 Time: 42.269	 Loss: 0.01975118
2025-06-02 15:37:45,151 - root - INFO -   Epoch 5/100	 Time: 36.875	 Loss: 0.01853033
2025-06-02 16:00:00,041 - root - INFO - Log file is ../log/log.txt.
2025-06-02 16:00:00,041 - root - INFO - Data path is ../data.
2025-06-02 16:00:00,042 - root - INFO - Export path is ../log.
2025-06-02 16:00:00,042 - root - INFO - Dataset: visu
2025-06-02 16:00:00,042 - root - INFO - Normal class: 0
2025-06-02 16:00:00,042 - root - INFO - Network: mlp
2025-06-02 16:00:00,043 - root - INFO - Deep SVDD objective: one-class
2025-06-02 16:00:00,043 - root - INFO - Nu-paramerter: 0.10
2025-06-02 16:00:00,043 - root - INFO - Computation device: cuda
2025-06-02 16:00:00,044 - root - INFO - Number of dataloader workers: 0
2025-06-02 16:00:00,874 - root - INFO - Pretraining: True
2025-06-02 16:00:00,874 - root - INFO - Pretraining optimizer: adam
2025-06-02 16:00:00,875 - root - INFO - Pretraining learning rate: 0.001
2025-06-02 16:00:00,875 - root - INFO - Pretraining epochs: 100
2025-06-02 16:00:00,875 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-02 16:00:00,875 - root - INFO - Pretraining batch size: 128
2025-06-02 16:00:00,875 - root - INFO - Pretraining weight decay: 1e-06
2025-06-02 16:00:01,131 - root - INFO - Starting pretraining...
2025-06-02 16:00:09,420 - root - INFO -   Epoch 1/100	 Time: 8.288	 Loss: 0.04547751
2025-06-02 16:00:15,103 - root - INFO -   Epoch 2/100	 Time: 5.683	 Loss: 0.02904844
2025-06-02 16:00:20,831 - root - INFO -   Epoch 3/100	 Time: 5.727	 Loss: 0.02450101
2025-06-02 16:00:26,502 - root - INFO -   Epoch 4/100	 Time: 5.671	 Loss: 0.02199670
2025-06-02 16:00:32,074 - root - INFO -   Epoch 5/100	 Time: 5.572	 Loss: 0.02046228
2025-06-02 16:00:37,601 - root - INFO -   Epoch 6/100	 Time: 5.527	 Loss: 0.01920364
2025-06-02 16:00:43,152 - root - INFO -   Epoch 7/100	 Time: 5.551	 Loss: 0.01828929
2025-06-02 16:00:48,767 - root - INFO -   Epoch 8/100	 Time: 5.615	 Loss: 0.01762853
2025-06-02 16:00:54,378 - root - INFO -   Epoch 9/100	 Time: 5.611	 Loss: 0.01711491
2025-06-02 16:01:00,114 - root - INFO -   Epoch 10/100	 Time: 5.735	 Loss: 0.01661074
2025-06-02 16:01:05,752 - root - INFO -   Epoch 11/100	 Time: 5.638	 Loss: 0.01623323
2025-06-02 16:01:11,375 - root - INFO -   Epoch 12/100	 Time: 5.623	 Loss: 0.01592636
2025-06-02 16:01:16,974 - root - INFO -   Epoch 13/100	 Time: 5.598	 Loss: 0.01558490
2025-06-02 16:01:22,608 - root - INFO -   Epoch 14/100	 Time: 5.634	 Loss: 0.01523501
2025-06-02 16:01:28,212 - root - INFO -   Epoch 15/100	 Time: 5.604	 Loss: 0.01497241
2025-06-02 16:01:33,801 - root - INFO -   Epoch 16/100	 Time: 5.589	 Loss: 0.01476988
2025-06-02 16:01:39,361 - root - INFO -   Epoch 17/100	 Time: 5.560	 Loss: 0.01458962
2025-06-02 16:01:44,966 - root - INFO -   Epoch 18/100	 Time: 5.605	 Loss: 0.01446511
2025-06-02 16:01:50,596 - root - INFO -   Epoch 19/100	 Time: 5.629	 Loss: 0.01432407
2025-06-02 16:01:56,254 - root - INFO -   Epoch 20/100	 Time: 5.658	 Loss: 0.01416195
2025-06-02 16:02:01,965 - root - INFO -   Epoch 21/100	 Time: 5.711	 Loss: 0.01399256
2025-06-02 16:02:07,565 - root - INFO -   Epoch 22/100	 Time: 5.599	 Loss: 0.01387258
2025-06-02 16:02:13,226 - root - INFO -   Epoch 23/100	 Time: 5.661	 Loss: 0.01375892
2025-06-02 16:02:20,812 - root - INFO -   Epoch 24/100	 Time: 7.585	 Loss: 0.01365700
2025-06-02 16:02:27,265 - root - INFO -   Epoch 25/100	 Time: 6.452	 Loss: 0.01354921
2025-06-02 16:02:33,379 - root - INFO -   Epoch 26/100	 Time: 6.114	 Loss: 0.01344301
2025-06-02 16:02:39,189 - root - INFO -   Epoch 27/100	 Time: 5.809	 Loss: 0.01332961
2025-06-02 16:02:44,815 - root - INFO -   Epoch 28/100	 Time: 5.627	 Loss: 0.01324189
2025-06-02 16:02:50,403 - root - INFO -   Epoch 29/100	 Time: 5.588	 Loss: 0.01316493
2025-06-02 16:02:56,026 - root - INFO -   Epoch 30/100	 Time: 5.622	 Loss: 0.01312937
2025-06-02 16:03:01,715 - root - INFO -   Epoch 31/100	 Time: 5.689	 Loss: 0.01306175
2025-06-02 16:03:07,354 - root - INFO -   Epoch 32/100	 Time: 5.637	 Loss: 0.01300391
2025-06-02 16:03:13,117 - root - INFO -   Epoch 33/100	 Time: 5.763	 Loss: 0.01294968
2025-06-02 16:03:18,759 - root - INFO -   Epoch 34/100	 Time: 5.642	 Loss: 0.01288998
2025-06-02 16:03:24,712 - root - INFO -   Epoch 35/100	 Time: 5.952	 Loss: 0.01284355
2025-06-02 16:03:30,960 - root - INFO -   Epoch 36/100	 Time: 6.247	 Loss: 0.01277906
2025-06-02 16:03:38,160 - root - INFO -   Epoch 37/100	 Time: 7.201	 Loss: 0.01274016
2025-06-02 16:03:44,266 - root - INFO -   Epoch 38/100	 Time: 6.105	 Loss: 0.01268032
2025-06-02 16:03:50,510 - root - INFO -   Epoch 39/100	 Time: 6.244	 Loss: 0.01262684
2025-06-02 16:03:56,385 - root - INFO -   Epoch 40/100	 Time: 5.875	 Loss: 0.01256540
2025-06-02 16:04:02,228 - root - INFO -   Epoch 41/100	 Time: 5.843	 Loss: 0.01250090
2025-06-02 16:04:08,260 - root - INFO -   Epoch 42/100	 Time: 6.032	 Loss: 0.01245210
2025-06-02 16:04:14,384 - root - INFO -   Epoch 43/100	 Time: 6.123	 Loss: 0.01242844
2025-06-02 16:04:20,501 - root - INFO -   Epoch 44/100	 Time: 6.117	 Loss: 0.01238905
2025-06-02 16:04:26,405 - root - INFO -   Epoch 45/100	 Time: 5.905	 Loss: 0.01235843
2025-06-02 16:04:32,520 - root - INFO -   Epoch 46/100	 Time: 6.114	 Loss: 0.01232153
2025-06-02 16:04:38,761 - root - INFO -   Epoch 47/100	 Time: 6.241	 Loss: 0.01229390
2025-06-02 16:04:44,629 - root - INFO -   Epoch 48/100	 Time: 5.867	 Loss: 0.01227474
2025-06-02 16:04:50,535 - root - INFO -   Epoch 49/100	 Time: 5.906	 Loss: 0.01223037
2025-06-02 16:04:56,300 - root - INFO -   Epoch 50/100	 Time: 5.765	 Loss: 0.01220231
2025-06-02 16:05:02,248 - root - INFO -   Epoch 51/100	 Time: 5.948	 Loss: 0.01216425
2025-06-02 16:05:08,116 - root - INFO -   Epoch 52/100	 Time: 5.869	 Loss: 0.01212175
2025-06-02 16:05:14,159 - root - INFO -   Epoch 53/100	 Time: 6.042	 Loss: 0.01209864
2025-06-02 16:05:20,042 - root - INFO -   Epoch 54/100	 Time: 5.883	 Loss: 0.01205555
2025-06-02 16:05:25,849 - root - INFO -   Epoch 55/100	 Time: 5.806	 Loss: 0.01203420
2025-06-02 16:05:31,717 - root - INFO -   Epoch 56/100	 Time: 5.868	 Loss: 0.01201962
2025-06-02 16:05:37,480 - root - INFO -   Epoch 57/100	 Time: 5.763	 Loss: 0.01199244
2025-06-02 16:05:43,220 - root - INFO -   Epoch 58/100	 Time: 5.740	 Loss: 0.01198972
2025-06-02 16:05:48,812 - root - INFO -   Epoch 59/100	 Time: 5.592	 Loss: 0.01197244
2025-06-02 16:05:54,569 - root - INFO -   Epoch 60/100	 Time: 5.756	 Loss: 0.01194871
2025-06-02 16:06:00,242 - root - INFO -   Epoch 61/100	 Time: 5.673	 Loss: 0.01194190
2025-06-02 16:06:05,883 - root - INFO -   Epoch 62/100	 Time: 5.640	 Loss: 0.01193837
2025-06-02 16:06:11,790 - root - INFO -   Epoch 63/100	 Time: 5.907	 Loss: 0.01192545
2025-06-02 16:06:17,810 - root - INFO -   Epoch 64/100	 Time: 6.019	 Loss: 0.01191534
2025-06-02 16:06:23,982 - root - INFO -   Epoch 65/100	 Time: 6.172	 Loss: 0.01190549
2025-06-02 16:06:29,852 - root - INFO -   Epoch 66/100	 Time: 5.869	 Loss: 0.01189557
2025-06-02 16:06:35,811 - root - INFO -   Epoch 67/100	 Time: 5.959	 Loss: 0.01187588
2025-06-02 16:06:41,994 - root - INFO -   Epoch 68/100	 Time: 6.183	 Loss: 0.01185920
2025-06-02 16:06:48,576 - root - INFO -   Epoch 69/100	 Time: 6.581	 Loss: 0.01185205
2025-06-02 16:06:55,159 - root - INFO -   Epoch 70/100	 Time: 6.583	 Loss: 0.01185524
2025-06-02 16:07:01,831 - root - INFO -   Epoch 71/100	 Time: 6.672	 Loss: 0.01184398
2025-06-02 16:07:08,172 - root - INFO -   Epoch 72/100	 Time: 6.341	 Loss: 0.01182969
2025-06-02 16:07:14,416 - root - INFO -   Epoch 73/100	 Time: 6.244	 Loss: 0.01181161
2025-06-02 16:07:20,639 - root - INFO -   Epoch 74/100	 Time: 6.223	 Loss: 0.01180816
2025-06-02 16:07:26,952 - root - INFO -   Epoch 75/100	 Time: 6.313	 Loss: 0.01179269
2025-06-02 16:07:33,189 - root - INFO -   Epoch 76/100	 Time: 6.237	 Loss: 0.01177716
2025-06-02 16:07:39,134 - root - INFO -   Epoch 77/100	 Time: 5.945	 Loss: 0.01175614
2025-06-02 16:07:45,136 - root - INFO -   Epoch 78/100	 Time: 6.002	 Loss: 0.01174204
2025-06-02 16:07:51,181 - root - INFO -   Epoch 79/100	 Time: 6.044	 Loss: 0.01171359
2025-06-02 16:07:56,944 - root - INFO -   Epoch 80/100	 Time: 5.764	 Loss: 0.01169700
2025-06-02 16:08:02,794 - root - INFO -   Epoch 81/100	 Time: 5.850	 Loss: 0.01168207
2025-06-02 16:08:08,606 - root - INFO -   Epoch 82/100	 Time: 5.811	 Loss: 0.01166891
2025-06-02 16:08:14,429 - root - INFO -   Epoch 83/100	 Time: 5.823	 Loss: 0.01167255
2025-06-02 16:08:20,410 - root - INFO -   Epoch 84/100	 Time: 5.981	 Loss: 0.01166316
2025-06-02 16:08:26,395 - root - INFO -   Epoch 85/100	 Time: 5.985	 Loss: 0.01165330
2025-06-02 16:08:32,333 - root - INFO -   Epoch 86/100	 Time: 5.938	 Loss: 0.01164145
2025-06-02 16:08:38,190 - root - INFO -   Epoch 87/100	 Time: 5.855	 Loss: 0.01163154
2025-06-02 16:08:44,052 - root - INFO -   Epoch 88/100	 Time: 5.862	 Loss: 0.01163443
2025-06-02 16:08:49,961 - root - INFO -   Epoch 89/100	 Time: 5.908	 Loss: 0.01162501
2025-06-02 16:08:55,861 - root - INFO -   Epoch 90/100	 Time: 5.899	 Loss: 0.01161443
2025-06-02 16:09:01,929 - root - INFO -   Epoch 91/100	 Time: 6.067	 Loss: 0.01161243
2025-06-02 16:09:07,929 - root - INFO -   Epoch 92/100	 Time: 5.999	 Loss: 0.01159690
2025-06-02 16:09:13,801 - root - INFO -   Epoch 93/100	 Time: 5.871	 Loss: 0.01159324
2025-06-02 16:09:19,679 - root - INFO -   Epoch 94/100	 Time: 5.878	 Loss: 0.01158976
2025-06-02 16:09:25,286 - root - INFO -   Epoch 95/100	 Time: 5.607	 Loss: 0.01157677
2025-06-02 16:09:31,004 - root - INFO -   Epoch 96/100	 Time: 5.718	 Loss: 0.01157037
2025-06-02 16:09:36,727 - root - INFO -   Epoch 97/100	 Time: 5.723	 Loss: 0.01157547
2025-06-02 16:09:42,491 - root - INFO -   Epoch 98/100	 Time: 5.764	 Loss: 0.01155911
2025-06-02 16:09:48,335 - root - INFO -   Epoch 99/100	 Time: 5.843	 Loss: 0.01155601
2025-06-02 16:09:54,225 - root - INFO -   Epoch 100/100	 Time: 5.890	 Loss: 0.01153810
2025-06-02 16:09:54,225 - root - INFO - Pretraining time: 593.094
2025-06-02 16:09:54,225 - root - INFO - Finished pretraining.
2025-06-02 16:09:54,227 - root - INFO - Testing autoencoder...
2025-06-02 16:09:54,417 - root - INFO - Test set Loss: 0.01858999
2025-06-02 16:09:54,432 - root - INFO - Test set AUC: 93.55%
2025-06-02 16:09:54,433 - root - INFO - Autoencoder testing time: 0.206
2025-06-02 16:09:54,433 - root - INFO - Finished testing autoencoder.
2025-06-02 16:09:54,434 - root - INFO - Training optimizer: adam
2025-06-02 16:09:54,434 - root - INFO - Training learning rate: 0.001
2025-06-02 16:09:54,435 - root - INFO - Training epochs: 50
2025-06-02 16:09:54,435 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-02 16:09:54,435 - root - INFO - Training batch size: 128
2025-06-02 16:09:54,435 - root - INFO - Training weight decay: 1e-06
2025-06-02 16:09:54,436 - root - INFO - Initializing center c...
2025-06-02 16:14:46,302 - root - INFO - Log file is ../log/log.txt.
2025-06-02 16:14:46,302 - root - INFO - Data path is ../data.
2025-06-02 16:14:46,302 - root - INFO - Export path is ../log.
2025-06-02 16:14:46,302 - root - INFO - Dataset: visu
2025-06-02 16:14:46,303 - root - INFO - Normal class: 0
2025-06-02 16:14:46,303 - root - INFO - Network: mlp
2025-06-02 16:14:46,303 - root - INFO - Deep SVDD objective: one-class
2025-06-02 16:14:46,303 - root - INFO - Nu-paramerter: 0.10
2025-06-02 16:14:46,304 - root - INFO - Computation device: cuda
2025-06-02 16:14:46,304 - root - INFO - Number of dataloader workers: 0
2025-06-02 16:14:46,511 - root - INFO - Pretraining: True
2025-06-02 16:14:46,511 - root - INFO - Pretraining optimizer: adam
2025-06-02 16:14:46,511 - root - INFO - Pretraining learning rate: 0.001
2025-06-02 16:14:46,512 - root - INFO - Pretraining epochs: 100
2025-06-02 16:14:46,512 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-02 16:14:46,513 - root - INFO - Pretraining batch size: 128
2025-06-02 16:14:46,513 - root - INFO - Pretraining weight decay: 1e-06
2025-06-02 16:14:46,669 - root - INFO - Starting pretraining...
2025-06-02 16:14:54,652 - root - INFO -   Epoch 1/100	 Time: 7.975	 Loss: 0.04708282
2025-06-02 16:15:00,462 - root - INFO -   Epoch 2/100	 Time: 5.809	 Loss: 0.02959460
2025-06-02 16:15:06,204 - root - INFO -   Epoch 3/100	 Time: 5.742	 Loss: 0.02476828
2025-06-02 16:15:12,211 - root - INFO -   Epoch 4/100	 Time: 6.006	 Loss: 0.02215629
2025-06-02 16:15:17,989 - root - INFO -   Epoch 5/100	 Time: 5.777	 Loss: 0.02057059
2025-06-02 16:15:23,741 - root - INFO -   Epoch 6/100	 Time: 5.752	 Loss: 0.01958952
2025-06-02 16:15:29,430 - root - INFO -   Epoch 7/100	 Time: 5.687	 Loss: 0.01885869
2025-06-02 16:15:35,240 - root - INFO -   Epoch 8/100	 Time: 5.809	 Loss: 0.01821387
2025-06-02 16:15:40,900 - root - INFO -   Epoch 9/100	 Time: 5.660	 Loss: 0.01762732
2025-06-02 16:15:46,694 - root - INFO -   Epoch 10/100	 Time: 5.794	 Loss: 0.01717120
2025-06-02 16:15:52,391 - root - INFO -   Epoch 11/100	 Time: 5.698	 Loss: 0.01675728
2025-06-02 16:15:58,208 - root - INFO -   Epoch 12/100	 Time: 5.816	 Loss: 0.01633044
2025-06-02 16:16:03,995 - root - INFO -   Epoch 13/100	 Time: 5.787	 Loss: 0.01598245
2025-06-02 16:16:09,869 - root - INFO -   Epoch 14/100	 Time: 5.874	 Loss: 0.01564625
2025-06-02 16:16:15,650 - root - INFO -   Epoch 15/100	 Time: 5.780	 Loss: 0.01532463
2025-06-02 16:16:21,694 - root - INFO -   Epoch 16/100	 Time: 6.044	 Loss: 0.01508332
2025-06-02 16:16:27,407 - root - INFO -   Epoch 17/100	 Time: 5.712	 Loss: 0.01489458
2025-06-02 16:16:33,232 - root - INFO -   Epoch 18/100	 Time: 5.825	 Loss: 0.01473856
2025-06-02 16:16:38,954 - root - INFO -   Epoch 19/100	 Time: 5.720	 Loss: 0.01455315
2025-06-02 16:16:45,267 - root - INFO -   Epoch 20/100	 Time: 6.312	 Loss: 0.01437615
2025-06-02 16:16:51,099 - root - INFO -   Epoch 21/100	 Time: 5.832	 Loss: 0.01420768
2025-06-02 16:16:56,947 - root - INFO -   Epoch 22/100	 Time: 5.846	 Loss: 0.01402819
2025-06-02 16:17:02,984 - root - INFO -   Epoch 23/100	 Time: 6.037	 Loss: 0.01385609
2025-06-02 16:17:08,728 - root - INFO -   Epoch 24/100	 Time: 5.743	 Loss: 0.01370261
2025-06-02 16:17:14,630 - root - INFO -   Epoch 25/100	 Time: 5.902	 Loss: 0.01359229
2025-06-02 16:17:20,373 - root - INFO -   Epoch 26/100	 Time: 5.743	 Loss: 0.01349224
2025-06-02 16:17:26,155 - root - INFO -   Epoch 27/100	 Time: 5.782	 Loss: 0.01337688
2025-06-02 16:17:31,942 - root - INFO -   Epoch 28/100	 Time: 5.787	 Loss: 0.01328417
2025-06-02 16:17:37,748 - root - INFO -   Epoch 29/100	 Time: 5.804	 Loss: 0.01318165
2025-06-02 16:17:43,444 - root - INFO -   Epoch 30/100	 Time: 5.697	 Loss: 0.01311659
2025-06-02 16:17:49,216 - root - INFO -   Epoch 31/100	 Time: 5.772	 Loss: 0.01301897
2025-06-02 16:17:54,977 - root - INFO -   Epoch 32/100	 Time: 5.760	 Loss: 0.01293256
2025-06-02 16:18:00,716 - root - INFO -   Epoch 33/100	 Time: 5.739	 Loss: 0.01286643
2025-06-02 16:18:06,516 - root - INFO -   Epoch 34/100	 Time: 5.798	 Loss: 0.01281300
2025-06-02 16:18:12,406 - root - INFO -   Epoch 35/100	 Time: 5.891	 Loss: 0.01276950
2025-06-02 16:18:18,342 - root - INFO -   Epoch 36/100	 Time: 5.935	 Loss: 0.01273072
2025-06-02 16:18:24,080 - root - INFO -   Epoch 37/100	 Time: 5.737	 Loss: 0.01269248
2025-06-02 16:18:29,892 - root - INFO -   Epoch 38/100	 Time: 5.812	 Loss: 0.01265468
2025-06-02 16:18:35,696 - root - INFO -   Epoch 39/100	 Time: 5.803	 Loss: 0.01263406
2025-06-02 16:18:41,394 - root - INFO -   Epoch 40/100	 Time: 5.697	 Loss: 0.01257363
2025-06-02 16:18:47,246 - root - INFO -   Epoch 41/100	 Time: 5.852	 Loss: 0.01253586
2025-06-02 16:18:53,028 - root - INFO -   Epoch 42/100	 Time: 5.783	 Loss: 0.01249605
2025-06-02 16:18:58,914 - root - INFO -   Epoch 43/100	 Time: 5.886	 Loss: 0.01246411
2025-06-02 16:19:04,796 - root - INFO -   Epoch 44/100	 Time: 5.881	 Loss: 0.01242351
2025-06-02 16:19:10,676 - root - INFO -   Epoch 45/100	 Time: 5.880	 Loss: 0.01238727
2025-06-02 16:19:16,539 - root - INFO -   Epoch 46/100	 Time: 5.862	 Loss: 0.01235493
2025-06-02 16:19:22,422 - root - INFO -   Epoch 47/100	 Time: 5.883	 Loss: 0.01232783
2025-06-02 16:19:28,228 - root - INFO -   Epoch 48/100	 Time: 5.806	 Loss: 0.01230571
2025-06-02 16:19:34,044 - root - INFO -   Epoch 49/100	 Time: 5.816	 Loss: 0.01227610
2025-06-02 16:19:39,977 - root - INFO -   Epoch 50/100	 Time: 5.932	 Loss: 0.01224875
2025-06-02 16:19:45,811 - root - INFO -   Epoch 51/100	 Time: 5.834	 Loss: 0.01220758
2025-06-02 16:19:51,524 - root - INFO -   Epoch 52/100	 Time: 5.712	 Loss: 0.01215639
2025-06-02 16:19:57,376 - root - INFO -   Epoch 53/100	 Time: 5.852	 Loss: 0.01212969
2025-06-02 16:20:03,297 - root - INFO -   Epoch 54/100	 Time: 5.921	 Loss: 0.01210840
2025-06-02 16:20:09,116 - root - INFO -   Epoch 55/100	 Time: 5.818	 Loss: 0.01208180
2025-06-02 16:20:14,893 - root - INFO -   Epoch 56/100	 Time: 5.777	 Loss: 0.01206329
2025-06-02 16:20:20,716 - root - INFO -   Epoch 57/100	 Time: 5.823	 Loss: 0.01204753
2025-06-02 16:20:26,514 - root - INFO -   Epoch 58/100	 Time: 5.797	 Loss: 0.01203614
2025-06-02 16:20:32,309 - root - INFO -   Epoch 59/100	 Time: 5.795	 Loss: 0.01202033
2025-06-02 16:20:38,135 - root - INFO -   Epoch 60/100	 Time: 5.825	 Loss: 0.01199390
2025-06-02 16:20:44,931 - root - INFO -   Epoch 61/100	 Time: 6.796	 Loss: 0.01198630
2025-06-02 16:20:51,145 - root - INFO -   Epoch 62/100	 Time: 6.213	 Loss: 0.01196359
2025-06-02 16:20:56,849 - root - INFO -   Epoch 63/100	 Time: 5.705	 Loss: 0.01194430
2025-06-02 16:21:02,679 - root - INFO -   Epoch 64/100	 Time: 5.830	 Loss: 0.01191797
2025-06-02 16:21:08,524 - root - INFO -   Epoch 65/100	 Time: 5.844	 Loss: 0.01187956
2025-06-02 16:21:14,427 - root - INFO -   Epoch 66/100	 Time: 5.902	 Loss: 0.01185892
2025-06-02 16:21:20,255 - root - INFO -   Epoch 67/100	 Time: 5.828	 Loss: 0.01183598
2025-06-02 16:21:25,959 - root - INFO -   Epoch 68/100	 Time: 5.704	 Loss: 0.01182228
2025-06-02 16:21:31,611 - root - INFO -   Epoch 69/100	 Time: 5.652	 Loss: 0.01179838
2025-06-02 16:21:37,397 - root - INFO -   Epoch 70/100	 Time: 5.785	 Loss: 0.01180149
2025-06-02 16:21:43,303 - root - INFO -   Epoch 71/100	 Time: 5.905	 Loss: 0.01177892
2025-06-02 16:21:49,203 - root - INFO -   Epoch 72/100	 Time: 5.900	 Loss: 0.01177283
2025-06-02 16:21:55,084 - root - INFO -   Epoch 73/100	 Time: 5.881	 Loss: 0.01175704
2025-06-02 16:22:00,999 - root - INFO -   Epoch 74/100	 Time: 5.915	 Loss: 0.01174312
2025-06-02 16:22:06,785 - root - INFO -   Epoch 75/100	 Time: 5.787	 Loss: 0.01174218
2025-06-02 16:22:12,797 - root - INFO -   Epoch 76/100	 Time: 6.012	 Loss: 0.01172652
2025-06-02 16:22:18,615 - root - INFO -   Epoch 77/100	 Time: 5.816	 Loss: 0.01172726
2025-06-02 16:22:24,431 - root - INFO -   Epoch 78/100	 Time: 5.816	 Loss: 0.01170961
2025-06-02 16:22:30,167 - root - INFO -   Epoch 79/100	 Time: 5.737	 Loss: 0.01170377
2025-06-02 16:22:35,908 - root - INFO -   Epoch 80/100	 Time: 5.740	 Loss: 0.01168254
2025-06-02 16:22:41,781 - root - INFO -   Epoch 81/100	 Time: 5.873	 Loss: 0.01167910
2025-06-02 16:22:47,570 - root - INFO -   Epoch 82/100	 Time: 5.788	 Loss: 0.01166859
2025-06-02 16:22:53,518 - root - INFO -   Epoch 83/100	 Time: 5.947	 Loss: 0.01166417
2025-06-02 16:22:59,307 - root - INFO -   Epoch 84/100	 Time: 5.789	 Loss: 0.01166113
2025-06-02 16:23:05,142 - root - INFO -   Epoch 85/100	 Time: 5.835	 Loss: 0.01165133
2025-06-02 16:23:10,952 - root - INFO -   Epoch 86/100	 Time: 5.808	 Loss: 0.01165031
2025-06-02 16:23:16,965 - root - INFO -   Epoch 87/100	 Time: 6.013	 Loss: 0.01164842
2025-06-02 16:23:22,757 - root - INFO -   Epoch 88/100	 Time: 5.790	 Loss: 0.01162659
2025-06-02 16:23:28,531 - root - INFO -   Epoch 89/100	 Time: 5.774	 Loss: 0.01162108
2025-06-02 16:23:34,319 - root - INFO -   Epoch 90/100	 Time: 5.788	 Loss: 0.01162077
2025-06-02 16:23:40,068 - root - INFO -   Epoch 91/100	 Time: 5.749	 Loss: 0.01159759
2025-06-02 16:23:45,888 - root - INFO -   Epoch 92/100	 Time: 5.820	 Loss: 0.01158120
2025-06-02 16:23:51,665 - root - INFO -   Epoch 93/100	 Time: 5.776	 Loss: 0.01154939
2025-06-02 16:23:57,548 - root - INFO -   Epoch 94/100	 Time: 5.883	 Loss: 0.01153352
2025-06-02 16:24:03,503 - root - INFO -   Epoch 95/100	 Time: 5.955	 Loss: 0.01151226
2025-06-02 16:24:09,235 - root - INFO -   Epoch 96/100	 Time: 5.732	 Loss: 0.01151258
2025-06-02 16:24:15,131 - root - INFO -   Epoch 97/100	 Time: 5.896	 Loss: 0.01148403
2025-06-02 16:24:21,640 - root - INFO -   Epoch 98/100	 Time: 6.509	 Loss: 0.01149139
2025-06-02 16:24:27,570 - root - INFO -   Epoch 99/100	 Time: 5.929	 Loss: 0.01148317
2025-06-02 16:24:33,567 - root - INFO -   Epoch 100/100	 Time: 5.996	 Loss: 0.01147045
2025-06-02 16:24:33,567 - root - INFO - Pretraining time: 586.897
2025-06-02 16:24:33,567 - root - INFO - Finished pretraining.
2025-06-02 16:24:33,568 - root - INFO - Testing autoencoder...
2025-06-02 16:24:33,756 - root - INFO - Test set Loss: 0.01839691
2025-06-02 16:24:33,764 - root - INFO - Test set AUC: 93.37%
2025-06-02 16:24:33,764 - root - INFO - Autoencoder testing time: 0.197
2025-06-02 16:24:33,764 - root - INFO - Finished testing autoencoder.
2025-06-02 16:24:33,766 - root - INFO - Training optimizer: adam
2025-06-02 16:24:33,766 - root - INFO - Training learning rate: 0.001
2025-06-02 16:24:33,766 - root - INFO - Training epochs: 50
2025-06-02 16:24:33,766 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-02 16:24:33,766 - root - INFO - Training batch size: 128
2025-06-02 16:24:33,766 - root - INFO - Training weight decay: 1e-06
2025-06-02 16:24:33,768 - root - INFO - Initializing center c...
2025-06-02 16:24:35,361 - root - INFO - Center c initialized.
2025-06-02 16:24:35,362 - root - INFO - Starting training...
2025-06-02 16:24:39,624 - root - INFO -   Epoch 1/50	 Time: 4.261	 Loss: 0.00175379
2025-06-02 16:24:43,774 - root - INFO -   Epoch 2/50	 Time: 4.150	 Loss: 0.00006115
2025-06-02 16:24:47,957 - root - INFO -   Epoch 3/50	 Time: 4.183	 Loss: 0.00005262
2025-06-02 16:24:52,177 - root - INFO -   Epoch 4/50	 Time: 4.219	 Loss: 0.00005092
2025-06-02 16:24:56,323 - root - INFO -   Epoch 5/50	 Time: 4.146	 Loss: 0.00004556
2025-06-02 16:25:00,646 - root - INFO -   Epoch 6/50	 Time: 4.324	 Loss: 0.00004357
2025-06-02 16:25:04,796 - root - INFO -   Epoch 7/50	 Time: 4.150	 Loss: 0.00003878
2025-06-02 16:25:09,026 - root - INFO -   Epoch 8/50	 Time: 4.230	 Loss: 0.00003774
2025-06-02 16:25:13,204 - root - INFO -   Epoch 9/50	 Time: 4.178	 Loss: 0.00003448
2025-06-02 16:25:17,396 - root - INFO -   Epoch 10/50	 Time: 4.191	 Loss: 0.00003417
2025-06-02 16:25:21,650 - root - INFO -   Epoch 11/50	 Time: 4.254	 Loss: 0.00003171
2025-06-02 16:25:26,011 - root - INFO -   Epoch 12/50	 Time: 4.362	 Loss: 0.00003223
2025-06-02 16:25:30,346 - root - INFO -   Epoch 13/50	 Time: 4.335	 Loss: 0.00002959
2025-06-02 16:25:34,587 - root - INFO -   Epoch 14/50	 Time: 4.240	 Loss: 0.00002828
2025-06-02 16:25:38,751 - root - INFO -   Epoch 15/50	 Time: 4.164	 Loss: 0.00002806
2025-06-02 16:25:42,964 - root - INFO -   Epoch 16/50	 Time: 4.213	 Loss: 0.00002623
2025-06-02 16:25:47,132 - root - INFO -   Epoch 17/50	 Time: 4.168	 Loss: 0.00002692
2025-06-02 16:25:51,363 - root - INFO -   Epoch 18/50	 Time: 4.231	 Loss: 0.00002573
2025-06-02 16:25:55,553 - root - INFO -   Epoch 19/50	 Time: 4.189	 Loss: 0.00002592
2025-06-02 16:25:59,815 - root - INFO -   Epoch 20/50	 Time: 4.262	 Loss: 0.00002442
2025-06-02 16:26:04,223 - root - INFO -   Epoch 21/50	 Time: 4.408	 Loss: 0.00002526
2025-06-02 16:26:08,515 - root - INFO -   Epoch 22/50	 Time: 4.291	 Loss: 0.00002258
2025-06-02 16:26:12,878 - root - INFO -   Epoch 23/50	 Time: 4.362	 Loss: 0.00002160
2025-06-02 16:26:17,301 - root - INFO -   Epoch 24/50	 Time: 4.423	 Loss: 0.00002352
2025-06-02 16:26:21,841 - root - INFO -   Epoch 25/50	 Time: 4.541	 Loss: 0.00002157
2025-06-02 16:26:26,269 - root - INFO -   Epoch 26/50	 Time: 4.427	 Loss: 0.00002122
2025-06-02 16:26:30,804 - root - INFO -   Epoch 27/50	 Time: 4.535	 Loss: 0.00002164
2025-06-02 16:26:35,295 - root - INFO -   Epoch 28/50	 Time: 4.491	 Loss: 0.00002010
2025-06-02 16:26:39,653 - root - INFO -   Epoch 29/50	 Time: 4.358	 Loss: 0.00002031
2025-06-02 16:26:44,222 - root - INFO -   Epoch 30/50	 Time: 4.568	 Loss: 0.00002004
2025-06-02 16:26:48,725 - root - INFO -   Epoch 31/50	 Time: 4.504	 Loss: 0.00002007
2025-06-02 16:26:53,137 - root - INFO -   Epoch 32/50	 Time: 4.412	 Loss: 0.00001991
2025-06-02 16:26:58,299 - root - INFO -   Epoch 33/50	 Time: 5.162	 Loss: 0.00001914
2025-06-02 16:27:02,949 - root - INFO -   Epoch 34/50	 Time: 4.650	 Loss: 0.00001857
2025-06-02 16:27:07,129 - root - INFO -   Epoch 35/50	 Time: 4.181	 Loss: 0.00001966
2025-06-02 16:27:11,327 - root - INFO -   Epoch 36/50	 Time: 4.198	 Loss: 0.00001876
2025-06-02 16:27:15,621 - root - INFO -   Epoch 37/50	 Time: 4.294	 Loss: 0.00001832
2025-06-02 16:27:20,074 - root - INFO -   Epoch 38/50	 Time: 4.452	 Loss: 0.00001838
2025-06-02 16:27:24,255 - root - INFO -   Epoch 39/50	 Time: 4.181	 Loss: 0.00001848
2025-06-02 16:27:28,484 - root - INFO -   Epoch 40/50	 Time: 4.229	 Loss: 0.00001872
2025-06-02 16:27:32,663 - root - INFO -   Epoch 41/50	 Time: 4.178	 Loss: 0.00001748
2025-06-02 16:27:36,877 - root - INFO -   Epoch 42/50	 Time: 4.214	 Loss: 0.00001861
2025-06-02 16:27:41,074 - root - INFO -   Epoch 43/50	 Time: 4.197	 Loss: 0.00001778
2025-06-02 16:27:45,306 - root - INFO -   Epoch 44/50	 Time: 4.231	 Loss: 0.00001696
2025-06-02 16:27:49,415 - root - INFO -   Epoch 45/50	 Time: 4.108	 Loss: 0.00001772
2025-06-02 16:27:53,643 - root - INFO -   Epoch 46/50	 Time: 4.228	 Loss: 0.00001769
2025-06-02 16:27:57,865 - root - INFO -   Epoch 47/50	 Time: 4.221	 Loss: 0.00001699
2025-06-02 16:28:02,168 - root - INFO -   Epoch 48/50	 Time: 4.303	 Loss: 0.00001841
2025-06-02 16:28:06,274 - root - INFO -   Epoch 49/50	 Time: 4.106	 Loss: 0.00001669
2025-06-02 16:28:10,502 - root - INFO -   Epoch 50/50	 Time: 4.228	 Loss: 0.00001754
2025-06-02 16:28:10,502 - root - INFO - Training time: 215.140
2025-06-02 16:28:10,503 - root - INFO - Finished training.
2025-06-02 16:28:10,503 - root - INFO - Starting testing...
2025-06-02 16:28:10,648 - root - INFO - Testing time: 0.143
2025-06-02 16:28:10,653 - root - INFO - Test set AUC: 90.85%
2025-06-02 16:28:10,653 - root - INFO - Finished testing.
2025-06-02 16:43:02,750 - root - INFO - Log file is ../log/log.txt.
2025-06-02 16:43:02,750 - root - INFO - Data path is ../data.
2025-06-02 16:43:02,751 - root - INFO - Export path is ../log.
2025-06-02 16:43:02,751 - root - INFO - Dataset: visu
2025-06-02 16:43:02,751 - root - INFO - Normal class: 0
2025-06-02 16:43:02,752 - root - INFO - Network: mlp
2025-06-02 16:43:02,752 - root - INFO - Deep SVDD objective: one-class
2025-06-02 16:43:02,752 - root - INFO - Nu-paramerter: 0.10
2025-06-02 16:43:02,752 - root - INFO - Computation device: cuda
2025-06-02 16:43:02,753 - root - INFO - Number of dataloader workers: 0
2025-06-02 16:43:03,314 - root - INFO - Loading model from C:\Users\Asus\PycharmProjects\Deep-SVDD-PyTorch\log\model.tar.
2025-06-02 16:43:03,314 - root - INFO - Pretraining: False
2025-06-02 16:43:03,315 - root - INFO - Training optimizer: adam
2025-06-02 16:43:03,315 - root - INFO - Training learning rate: 0.001
2025-06-02 16:43:03,315 - root - INFO - Training epochs: 50
2025-06-02 16:43:03,315 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-02 16:43:03,315 - root - INFO - Training batch size: 128
2025-06-02 16:43:03,315 - root - INFO - Training weight decay: 1e-06
2025-06-02 16:43:03,317 - root - INFO - Starting training...
2025-06-02 16:43:09,557 - root - INFO -   Epoch 1/50	 Time: 6.239	 Loss: 0.00002421
2025-06-02 16:43:13,654 - root - INFO -   Epoch 2/50	 Time: 4.096	 Loss: 0.00001662
2025-06-02 16:43:18,031 - root - INFO -   Epoch 3/50	 Time: 4.376	 Loss: 0.00001756
2025-06-02 16:43:22,401 - root - INFO -   Epoch 4/50	 Time: 4.370	 Loss: 0.00001668
2025-06-02 16:43:27,191 - root - INFO -   Epoch 5/50	 Time: 4.790	 Loss: 0.00001717
2025-06-02 16:43:31,771 - root - INFO -   Epoch 6/50	 Time: 4.580	 Loss: 0.00001610
2025-06-02 16:43:36,180 - root - INFO -   Epoch 7/50	 Time: 4.409	 Loss: 0.00001628
2025-06-02 16:43:40,685 - root - INFO -   Epoch 8/50	 Time: 4.505	 Loss: 0.00001528
2025-06-02 16:43:45,111 - root - INFO -   Epoch 9/50	 Time: 4.426	 Loss: 0.00001689
2025-06-02 16:43:49,497 - root - INFO -   Epoch 10/50	 Time: 4.386	 Loss: 0.00001467
2025-06-02 16:43:54,053 - root - INFO -   Epoch 11/50	 Time: 4.556	 Loss: 0.00001644
2025-06-02 16:43:58,713 - root - INFO -   Epoch 12/50	 Time: 4.660	 Loss: 0.00001470
2025-06-02 16:44:03,321 - root - INFO -   Epoch 13/50	 Time: 4.608	 Loss: 0.00001645
2025-06-02 16:44:07,676 - root - INFO -   Epoch 14/50	 Time: 4.355	 Loss: 0.00001483
2025-06-02 16:44:12,040 - root - INFO -   Epoch 15/50	 Time: 4.363	 Loss: 0.00001550
2025-06-02 16:44:16,505 - root - INFO -   Epoch 16/50	 Time: 4.464	 Loss: 0.00001493
2025-06-02 16:44:20,945 - root - INFO -   Epoch 17/50	 Time: 4.440	 Loss: 0.00001539
2025-06-02 16:44:25,407 - root - INFO -   Epoch 18/50	 Time: 4.461	 Loss: 0.00001508
2025-06-02 16:44:29,813 - root - INFO -   Epoch 19/50	 Time: 4.406	 Loss: 0.00001473
2025-06-02 16:44:34,170 - root - INFO -   Epoch 20/50	 Time: 4.357	 Loss: 0.00001514
2025-06-02 16:44:38,613 - root - INFO -   Epoch 21/50	 Time: 4.443	 Loss: 0.00001459
2025-06-02 16:44:43,010 - root - INFO -   Epoch 22/50	 Time: 4.397	 Loss: 0.00001501
2025-06-02 16:44:47,253 - root - INFO -   Epoch 23/50	 Time: 4.243	 Loss: 0.00001512
2025-06-02 16:44:51,635 - root - INFO -   Epoch 24/50	 Time: 4.383	 Loss: 0.00001431
2025-06-02 16:44:55,835 - root - INFO -   Epoch 25/50	 Time: 4.200	 Loss: 0.00001458
2025-06-02 16:45:00,198 - root - INFO -   Epoch 26/50	 Time: 4.362	 Loss: 0.00001486
2025-06-02 16:45:04,512 - root - INFO -   Epoch 27/50	 Time: 4.314	 Loss: 0.00001418
2025-06-02 16:45:08,782 - root - INFO -   Epoch 28/50	 Time: 4.270	 Loss: 0.00001472
2025-06-02 16:45:12,986 - root - INFO -   Epoch 29/50	 Time: 4.203	 Loss: 0.00001474
2025-06-02 16:45:17,316 - root - INFO -   Epoch 30/50	 Time: 4.330	 Loss: 0.00001379
2025-06-02 16:45:21,493 - root - INFO -   Epoch 31/50	 Time: 4.177	 Loss: 0.00001428
2025-06-02 16:45:25,734 - root - INFO -   Epoch 32/50	 Time: 4.241	 Loss: 0.00001473
2025-06-02 16:45:29,950 - root - INFO -   Epoch 33/50	 Time: 4.217	 Loss: 0.00001447
2025-06-02 16:45:34,163 - root - INFO -   Epoch 34/50	 Time: 4.211	 Loss: 0.00001454
2025-06-02 16:45:38,577 - root - INFO -   Epoch 35/50	 Time: 4.414	 Loss: 0.00001510
2025-06-02 16:45:42,952 - root - INFO -   Epoch 36/50	 Time: 4.374	 Loss: 0.00001383
2025-06-02 16:45:47,913 - root - INFO -   Epoch 37/50	 Time: 4.962	 Loss: 0.00001386
2025-06-02 16:45:52,438 - root - INFO -   Epoch 38/50	 Time: 4.523	 Loss: 0.00001436
2025-06-02 16:45:56,975 - root - INFO -   Epoch 39/50	 Time: 4.537	 Loss: 0.00001453
2025-06-02 16:46:01,328 - root - INFO -   Epoch 40/50	 Time: 4.353	 Loss: 0.00001363
2025-06-02 16:46:05,748 - root - INFO -   Epoch 41/50	 Time: 4.420	 Loss: 0.00001374
2025-06-02 16:46:10,057 - root - INFO -   Epoch 42/50	 Time: 4.309	 Loss: 0.00001373
2025-06-02 16:46:14,535 - root - INFO -   Epoch 43/50	 Time: 4.478	 Loss: 0.00001355
2025-06-02 16:46:19,030 - root - INFO -   Epoch 44/50	 Time: 4.494	 Loss: 0.00001348
2025-06-02 16:46:23,310 - root - INFO -   Epoch 45/50	 Time: 4.280	 Loss: 0.00001347
2025-06-02 16:46:27,770 - root - INFO -   Epoch 46/50	 Time: 4.460	 Loss: 0.00001367
2025-06-02 16:46:32,925 - root - INFO -   Epoch 47/50	 Time: 5.155	 Loss: 0.00001345
2025-06-02 16:46:37,721 - root - INFO -   Epoch 48/50	 Time: 4.795	 Loss: 0.00001321
2025-06-02 16:46:42,649 - root - INFO -   Epoch 49/50	 Time: 4.929	 Loss: 0.00001327
2025-06-02 16:46:47,245 - root - INFO -   Epoch 50/50	 Time: 4.596	 Loss: 0.00001314
2025-06-02 16:46:47,245 - root - INFO - Training time: 223.928
2025-06-02 16:46:47,245 - root - INFO - Finished training.
2025-06-02 16:46:47,246 - root - INFO - Starting testing...
2025-06-02 16:46:47,392 - root - INFO - Testing time: 0.145
2025-06-02 16:46:47,399 - root - INFO - Test set AUC: 84.04%
2025-06-02 16:46:47,399 - root - INFO - Finished testing.
2025-06-02 16:53:12,838 - root - INFO - Log file is ../log/log.txt.
2025-06-02 16:53:12,838 - root - INFO - Data path is ../data.
2025-06-02 16:53:12,838 - root - INFO - Export path is ../log.
2025-06-02 16:53:12,838 - root - INFO - Dataset: visu
2025-06-02 16:53:12,838 - root - INFO - Normal class: 0
2025-06-02 16:53:12,838 - root - INFO - Network: mlp
2025-06-02 16:53:12,840 - root - INFO - Deep SVDD objective: one-class
2025-06-02 16:53:12,840 - root - INFO - Nu-paramerter: 0.10
2025-06-02 16:53:12,840 - root - INFO - Computation device: cuda
2025-06-02 16:53:12,840 - root - INFO - Number of dataloader workers: 0
2025-06-02 16:53:13,180 - root - INFO - Loading model from C:\Users\Asus\PycharmProjects\Deep-SVDD-PyTorch\log\model.tar.
2025-06-02 16:53:13,180 - root - INFO - Pretraining: False
2025-06-02 16:53:13,181 - root - INFO - Training optimizer: adam
2025-06-02 16:53:13,181 - root - INFO - Training learning rate: 0.001
2025-06-02 16:53:13,181 - root - INFO - Training epochs: 50
2025-06-02 16:53:13,181 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-02 16:53:13,181 - root - INFO - Training batch size: 128
2025-06-02 16:53:13,181 - root - INFO - Training weight decay: 1e-06
2025-06-02 16:53:13,184 - root - INFO - Starting training...
2025-06-02 16:53:18,877 - root - INFO -   Epoch 1/50	 Time: 5.693	 Loss: 0.00002651
2025-06-02 16:53:23,117 - root - INFO -   Epoch 2/50	 Time: 4.240	 Loss: 0.00001590
2025-06-02 16:53:27,481 - root - INFO -   Epoch 3/50	 Time: 4.363	 Loss: 0.00001598
2025-06-02 16:53:31,755 - root - INFO -   Epoch 4/50	 Time: 4.274	 Loss: 0.00001693
2025-06-02 16:53:36,038 - root - INFO -   Epoch 5/50	 Time: 4.282	 Loss: 0.00001627
2025-06-02 16:53:40,393 - root - INFO -   Epoch 6/50	 Time: 4.354	 Loss: 0.00001629
2025-06-02 16:53:44,700 - root - INFO -   Epoch 7/50	 Time: 4.306	 Loss: 0.00001657
2025-06-02 16:53:49,094 - root - INFO -   Epoch 8/50	 Time: 4.395	 Loss: 0.00001549
2025-06-02 16:53:53,310 - root - INFO -   Epoch 9/50	 Time: 4.216	 Loss: 0.00001546
2025-06-02 16:53:57,612 - root - INFO -   Epoch 10/50	 Time: 4.301	 Loss: 0.00001603
2025-06-02 16:54:01,951 - root - INFO -   Epoch 11/50	 Time: 4.338	 Loss: 0.00001631
2025-06-02 16:54:06,249 - root - INFO -   Epoch 12/50	 Time: 4.297	 Loss: 0.00001540
2025-06-02 16:54:10,569 - root - INFO -   Epoch 13/50	 Time: 4.320	 Loss: 0.00001536
2025-06-02 16:54:14,908 - root - INFO -   Epoch 14/50	 Time: 4.338	 Loss: 0.00001562
2025-06-02 16:54:19,175 - root - INFO -   Epoch 15/50	 Time: 4.267	 Loss: 0.00001561
2025-06-02 16:54:23,550 - root - INFO -   Epoch 16/50	 Time: 4.375	 Loss: 0.00001501
2025-06-02 16:54:27,760 - root - INFO -   Epoch 17/50	 Time: 4.207	 Loss: 0.00001477
2025-06-02 16:54:32,126 - root - INFO -   Epoch 18/50	 Time: 4.366	 Loss: 0.00001524
2025-06-02 16:54:36,356 - root - INFO -   Epoch 19/50	 Time: 4.230	 Loss: 0.00001499
2025-06-02 16:54:40,724 - root - INFO -   Epoch 20/50	 Time: 4.367	 Loss: 0.00001505
2025-06-02 16:54:44,937 - root - INFO -   Epoch 21/50	 Time: 4.212	 Loss: 0.00001525
2025-06-02 16:54:49,253 - root - INFO -   Epoch 22/50	 Time: 4.316	 Loss: 0.00001493
2025-06-02 16:54:53,535 - root - INFO -   Epoch 23/50	 Time: 4.281	 Loss: 0.00001470
2025-06-02 16:54:57,836 - root - INFO -   Epoch 24/50	 Time: 4.299	 Loss: 0.00001463
2025-06-02 16:55:02,212 - root - INFO -   Epoch 25/50	 Time: 4.376	 Loss: 0.00001565
2025-06-02 16:55:06,505 - root - INFO -   Epoch 26/50	 Time: 4.293	 Loss: 0.00001500
2025-06-02 16:55:10,770 - root - INFO -   Epoch 27/50	 Time: 4.265	 Loss: 0.00001470
2025-06-02 16:55:15,129 - root - INFO -   Epoch 28/50	 Time: 4.359	 Loss: 0.00001419
2025-06-02 16:55:19,409 - root - INFO -   Epoch 29/50	 Time: 4.279	 Loss: 0.00001442
2025-06-02 16:55:23,700 - root - INFO -   Epoch 30/50	 Time: 4.291	 Loss: 0.00001370
2025-06-02 16:55:27,910 - root - INFO -   Epoch 31/50	 Time: 4.209	 Loss: 0.00001477
2025-06-02 16:55:32,249 - root - INFO -   Epoch 32/50	 Time: 4.339	 Loss: 0.00001455
2025-06-02 16:55:36,448 - root - INFO -   Epoch 33/50	 Time: 4.199	 Loss: 0.00001434
2025-06-02 16:55:40,854 - root - INFO -   Epoch 34/50	 Time: 4.406	 Loss: 0.00001455
2025-06-02 16:55:45,096 - root - INFO -   Epoch 35/50	 Time: 4.241	 Loss: 0.00001412
2025-06-02 16:55:49,426 - root - INFO -   Epoch 36/50	 Time: 4.330	 Loss: 0.00001419
2025-06-02 16:55:53,735 - root - INFO -   Epoch 37/50	 Time: 4.308	 Loss: 0.00001443
2025-06-02 16:55:58,043 - root - INFO -   Epoch 38/50	 Time: 4.308	 Loss: 0.00001423
2025-06-02 16:56:02,396 - root - INFO -   Epoch 39/50	 Time: 4.352	 Loss: 0.00001406
2025-06-02 16:56:06,697 - root - INFO -   Epoch 40/50	 Time: 4.299	 Loss: 0.00001383
2025-06-02 16:56:10,952 - root - INFO -   Epoch 41/50	 Time: 4.255	 Loss: 0.00001412
2025-06-02 16:56:15,310 - root - INFO -   Epoch 42/50	 Time: 4.357	 Loss: 0.00001411
2025-06-02 16:56:19,545 - root - INFO -   Epoch 43/50	 Time: 4.234	 Loss: 0.00001400
2025-06-02 16:56:23,880 - root - INFO -   Epoch 44/50	 Time: 4.334	 Loss: 0.00001386
2025-06-02 16:56:28,349 - root - INFO -   Epoch 45/50	 Time: 4.469	 Loss: 0.00001329
2025-06-02 16:56:33,194 - root - INFO -   Epoch 46/50	 Time: 4.845	 Loss: 0.00001338
2025-06-02 16:56:37,653 - root - INFO -   Epoch 47/50	 Time: 4.459	 Loss: 0.00001366
2025-06-02 16:56:42,247 - root - INFO -   Epoch 48/50	 Time: 4.594	 Loss: 0.00001285
2025-06-02 16:56:47,002 - root - INFO -   Epoch 49/50	 Time: 4.753	 Loss: 0.00001344
2025-06-02 16:56:51,377 - root - INFO -   Epoch 50/50	 Time: 4.375	 Loss: 0.00001284
2025-06-02 16:56:51,377 - root - INFO - Training time: 218.193
2025-06-02 16:56:51,377 - root - INFO - Finished training.
2025-06-02 16:56:51,378 - root - INFO - Starting testing...
2025-06-02 16:56:51,533 - root - INFO - Testing time: 0.155
2025-06-02 16:56:51,539 - root - INFO - Test set AUC: 88.68%
2025-06-02 16:56:51,539 - root - INFO - Finished testing.
2025-06-03 15:07:20,354 - root - INFO - Log file is ../log/log.txt.
2025-06-03 15:07:20,355 - root - INFO - Data path is ../data.
2025-06-03 15:07:20,356 - root - INFO - Export path is ../log.
2025-06-03 15:07:20,356 - root - INFO - Dataset: visu
2025-06-03 15:07:20,356 - root - INFO - Normal class: 0
2025-06-03 15:07:20,356 - root - INFO - Network: mlp
2025-06-03 15:07:20,356 - root - INFO - Deep SVDD objective: one-class
2025-06-03 15:07:20,357 - root - INFO - Nu-paramerter: 0.10
2025-06-03 15:07:20,357 - root - INFO - Computation device: cuda
2025-06-03 15:07:20,357 - root - INFO - Number of dataloader workers: 0
2025-06-03 15:15:00,204 - root - INFO - Log file is ../log/log.txt.
2025-06-03 15:15:00,205 - root - INFO - Data path is ../data.
2025-06-03 15:15:00,205 - root - INFO - Export path is ../log.
2025-06-03 15:15:00,205 - root - INFO - Dataset: visu
2025-06-03 15:15:00,205 - root - INFO - Normal class: 0
2025-06-03 15:15:00,205 - root - INFO - Network: mlp
2025-06-03 15:15:00,206 - root - INFO - Deep SVDD objective: one-class
2025-06-03 15:15:00,206 - root - INFO - Nu-paramerter: 0.10
2025-06-03 15:15:00,206 - root - INFO - Computation device: cuda
2025-06-03 15:15:00,206 - root - INFO - Number of dataloader workers: 0
2025-06-03 15:15:33,804 - root - INFO - Log file is ../log/log.txt.
2025-06-03 15:15:33,805 - root - INFO - Data path is ../data.
2025-06-03 15:15:33,805 - root - INFO - Export path is ../log.
2025-06-03 15:15:33,805 - root - INFO - Dataset: visu
2025-06-03 15:15:33,805 - root - INFO - Normal class: 0
2025-06-03 15:15:33,806 - root - INFO - Network: mlp
2025-06-03 15:15:33,806 - root - INFO - Deep SVDD objective: one-class
2025-06-03 15:15:33,806 - root - INFO - Nu-paramerter: 0.10
2025-06-03 15:15:33,807 - root - INFO - Computation device: cuda
2025-06-03 15:15:33,807 - root - INFO - Number of dataloader workers: 0
2025-06-03 15:15:34,048 - root - INFO - Pretraining: True
2025-06-03 15:15:34,048 - root - INFO - Pretraining optimizer: adam
2025-06-03 15:15:34,048 - root - INFO - Pretraining learning rate: 0.001
2025-06-03 15:15:34,048 - root - INFO - Pretraining epochs: 100
2025-06-03 15:15:34,049 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-03 15:15:34,049 - root - INFO - Pretraining batch size: 128
2025-06-03 15:15:34,049 - root - INFO - Pretraining weight decay: 1e-06
2025-06-03 15:15:34,338 - root - INFO - Starting pretraining...
2025-06-03 15:15:44,004 - root - INFO -   Epoch 1/100	 Time: 9.656	 Loss: 0.04314395
2025-06-03 15:15:49,680 - root - INFO -   Epoch 2/100	 Time: 5.670	 Loss: 0.02700462
2025-06-03 15:15:55,590 - root - INFO -   Epoch 3/100	 Time: 5.910	 Loss: 0.02261667
2025-06-03 15:16:01,405 - root - INFO -   Epoch 4/100	 Time: 5.815	 Loss: 0.02012049
2025-06-03 15:16:07,047 - root - INFO -   Epoch 5/100	 Time: 5.642	 Loss: 0.01866400
2025-06-03 15:16:12,792 - root - INFO -   Epoch 6/100	 Time: 5.744	 Loss: 0.01767003
2025-06-03 15:16:18,505 - root - INFO -   Epoch 7/100	 Time: 5.712	 Loss: 0.01683086
2025-06-03 15:16:24,214 - root - INFO -   Epoch 8/100	 Time: 5.709	 Loss: 0.01608525
2025-06-03 15:16:29,941 - root - INFO -   Epoch 9/100	 Time: 5.727	 Loss: 0.01552263
2025-06-03 15:16:35,616 - root - INFO -   Epoch 10/100	 Time: 5.675	 Loss: 0.01514953
2025-06-03 15:16:41,455 - root - INFO -   Epoch 11/100	 Time: 5.839	 Loss: 0.01488346
2025-06-03 15:16:47,135 - root - INFO -   Epoch 12/100	 Time: 5.679	 Loss: 0.01463984
2025-06-03 15:16:52,760 - root - INFO -   Epoch 13/100	 Time: 5.625	 Loss: 0.01441139
2025-06-03 15:16:58,449 - root - INFO -   Epoch 14/100	 Time: 5.688	 Loss: 0.01420689
2025-06-03 15:17:04,299 - root - INFO -   Epoch 15/100	 Time: 5.851	 Loss: 0.01401029
2025-06-03 15:17:09,944 - root - INFO -   Epoch 16/100	 Time: 5.645	 Loss: 0.01384227
2025-06-03 15:17:15,558 - root - INFO -   Epoch 17/100	 Time: 5.614	 Loss: 0.01368884
2025-06-03 15:17:21,324 - root - INFO -   Epoch 18/100	 Time: 5.765	 Loss: 0.01353019
2025-06-03 15:17:26,956 - root - INFO -   Epoch 19/100	 Time: 5.630	 Loss: 0.01338002
2025-06-03 15:17:32,617 - root - INFO -   Epoch 20/100	 Time: 5.661	 Loss: 0.01326547
2025-06-03 15:17:38,263 - root - INFO -   Epoch 21/100	 Time: 5.647	 Loss: 0.01318305
2025-06-03 15:17:43,862 - root - INFO -   Epoch 22/100	 Time: 5.598	 Loss: 0.01310569
2025-06-03 15:17:49,600 - root - INFO -   Epoch 23/100	 Time: 5.738	 Loss: 0.01303049
2025-06-03 15:17:55,341 - root - INFO -   Epoch 24/100	 Time: 5.741	 Loss: 0.01296165
2025-06-03 15:18:01,278 - root - INFO -   Epoch 25/100	 Time: 5.935	 Loss: 0.01289133
2025-06-03 15:18:07,016 - root - INFO -   Epoch 26/100	 Time: 5.739	 Loss: 0.01278445
2025-06-03 15:18:12,655 - root - INFO -   Epoch 27/100	 Time: 5.638	 Loss: 0.01268544
2025-06-03 15:18:18,376 - root - INFO -   Epoch 28/100	 Time: 5.720	 Loss: 0.01260363
2025-06-03 15:18:24,027 - root - INFO -   Epoch 29/100	 Time: 5.651	 Loss: 0.01252366
2025-06-03 15:18:29,813 - root - INFO -   Epoch 30/100	 Time: 5.786	 Loss: 0.01246299
2025-06-03 15:18:35,494 - root - INFO -   Epoch 31/100	 Time: 5.681	 Loss: 0.01239765
2025-06-03 15:18:41,290 - root - INFO -   Epoch 32/100	 Time: 5.794	 Loss: 0.01234081
2025-06-03 15:18:47,070 - root - INFO -   Epoch 33/100	 Time: 5.779	 Loss: 0.01229408
2025-06-03 15:18:52,733 - root - INFO -   Epoch 34/100	 Time: 5.662	 Loss: 0.01222089
2025-06-03 15:18:58,353 - root - INFO -   Epoch 35/100	 Time: 5.620	 Loss: 0.01216203
2025-06-03 15:19:04,110 - root - INFO -   Epoch 36/100	 Time: 5.757	 Loss: 0.01210381
2025-06-03 15:19:09,873 - root - INFO -   Epoch 37/100	 Time: 5.763	 Loss: 0.01205237
2025-06-03 15:19:15,421 - root - INFO -   Epoch 38/100	 Time: 5.549	 Loss: 0.01201337
2025-06-03 15:19:21,101 - root - INFO -   Epoch 39/100	 Time: 5.678	 Loss: 0.01197787
2025-06-03 15:19:26,685 - root - INFO -   Epoch 40/100	 Time: 5.584	 Loss: 0.01192980
2025-06-03 15:19:32,416 - root - INFO -   Epoch 41/100	 Time: 5.731	 Loss: 0.01190644
2025-06-03 15:19:38,120 - root - INFO -   Epoch 42/100	 Time: 5.705	 Loss: 0.01186142
2025-06-03 15:19:43,812 - root - INFO -   Epoch 43/100	 Time: 5.692	 Loss: 0.01185332
2025-06-03 15:19:49,465 - root - INFO -   Epoch 44/100	 Time: 5.652	 Loss: 0.01180148
2025-06-03 15:19:55,088 - root - INFO -   Epoch 45/100	 Time: 5.623	 Loss: 0.01176272
2025-06-03 15:20:00,874 - root - INFO -   Epoch 46/100	 Time: 5.786	 Loss: 0.01172150
2025-06-03 15:20:07,406 - root - INFO -   Epoch 47/100	 Time: 6.531	 Loss: 0.01166997
2025-06-03 15:20:13,684 - root - INFO -   Epoch 48/100	 Time: 6.276	 Loss: 0.01163076
2025-06-03 15:20:19,428 - root - INFO -   Epoch 49/100	 Time: 5.744	 Loss: 0.01160228
2025-06-03 15:20:25,121 - root - INFO -   Epoch 50/100	 Time: 5.692	 Loss: 0.01155172
2025-06-03 15:20:31,099 - root - INFO -   Epoch 51/100	 Time: 5.978	 Loss: 0.01151767
2025-06-03 15:20:37,451 - root - INFO -   Epoch 52/100	 Time: 6.351	 Loss: 0.01148429
2025-06-03 15:20:43,106 - root - INFO -   Epoch 53/100	 Time: 5.654	 Loss: 0.01144852
2025-06-03 15:20:48,852 - root - INFO -   Epoch 54/100	 Time: 5.747	 Loss: 0.01141793
2025-06-03 15:20:54,533 - root - INFO -   Epoch 55/100	 Time: 5.680	 Loss: 0.01138544
2025-06-03 15:21:00,419 - root - INFO -   Epoch 56/100	 Time: 5.885	 Loss: 0.01138442
2025-06-03 15:21:06,193 - root - INFO -   Epoch 57/100	 Time: 5.773	 Loss: 0.01136537
2025-06-03 15:21:11,927 - root - INFO -   Epoch 58/100	 Time: 5.734	 Loss: 0.01134820
2025-06-03 15:21:17,628 - root - INFO -   Epoch 59/100	 Time: 5.700	 Loss: 0.01133952
2025-06-03 15:21:23,401 - root - INFO -   Epoch 60/100	 Time: 5.774	 Loss: 0.01131237
2025-06-03 15:21:29,078 - root - INFO -   Epoch 61/100	 Time: 5.677	 Loss: 0.01130819
2025-06-03 15:21:34,724 - root - INFO -   Epoch 62/100	 Time: 5.646	 Loss: 0.01129537
2025-06-03 15:21:40,364 - root - INFO -   Epoch 63/100	 Time: 5.640	 Loss: 0.01128918
2025-06-03 15:21:46,276 - root - INFO -   Epoch 64/100	 Time: 5.912	 Loss: 0.01127369
2025-06-03 15:21:52,335 - root - INFO -   Epoch 65/100	 Time: 6.058	 Loss: 0.01126045
2025-06-03 15:21:58,050 - root - INFO -   Epoch 66/100	 Time: 5.714	 Loss: 0.01124460
2025-06-03 15:22:03,837 - root - INFO -   Epoch 67/100	 Time: 5.787	 Loss: 0.01124011
2025-06-03 15:22:09,628 - root - INFO -   Epoch 68/100	 Time: 5.790	 Loss: 0.01120983
2025-06-03 15:22:15,348 - root - INFO -   Epoch 69/100	 Time: 5.719	 Loss: 0.01121082
2025-06-03 15:22:20,997 - root - INFO -   Epoch 70/100	 Time: 5.650	 Loss: 0.01120397
2025-06-03 15:22:26,669 - root - INFO -   Epoch 71/100	 Time: 5.672	 Loss: 0.01120640
2025-06-03 15:22:32,304 - root - INFO -   Epoch 72/100	 Time: 5.635	 Loss: 0.01119507
2025-06-03 15:22:37,957 - root - INFO -   Epoch 73/100	 Time: 5.653	 Loss: 0.01120063
2025-06-03 15:22:43,642 - root - INFO -   Epoch 74/100	 Time: 5.683	 Loss: 0.01117829
2025-06-03 15:22:49,354 - root - INFO -   Epoch 75/100	 Time: 5.712	 Loss: 0.01117751
2025-06-03 15:22:55,009 - root - INFO -   Epoch 76/100	 Time: 5.656	 Loss: 0.01117162
2025-06-03 15:23:00,755 - root - INFO -   Epoch 77/100	 Time: 5.745	 Loss: 0.01116447
2025-06-03 15:23:06,378 - root - INFO -   Epoch 78/100	 Time: 5.623	 Loss: 0.01116642
2025-06-03 15:23:11,982 - root - INFO -   Epoch 79/100	 Time: 5.604	 Loss: 0.01114459
2025-06-03 15:23:17,587 - root - INFO -   Epoch 80/100	 Time: 5.605	 Loss: 0.01113901
2025-06-03 15:23:23,212 - root - INFO -   Epoch 81/100	 Time: 5.625	 Loss: 0.01112897
2025-06-03 15:23:28,879 - root - INFO -   Epoch 82/100	 Time: 5.667	 Loss: 0.01112991
2025-06-03 15:23:34,579 - root - INFO -   Epoch 83/100	 Time: 5.699	 Loss: 0.01112496
2025-06-03 15:23:40,303 - root - INFO -   Epoch 84/100	 Time: 5.724	 Loss: 0.01111292
2025-06-03 15:23:46,073 - root - INFO -   Epoch 85/100	 Time: 5.769	 Loss: 0.01111747
2025-06-03 15:23:51,927 - root - INFO -   Epoch 86/100	 Time: 5.854	 Loss: 0.01111109
2025-06-03 15:23:57,638 - root - INFO -   Epoch 87/100	 Time: 5.711	 Loss: 0.01109578
2025-06-03 15:24:03,533 - root - INFO -   Epoch 88/100	 Time: 5.895	 Loss: 0.01110198
2025-06-03 15:24:09,429 - root - INFO -   Epoch 89/100	 Time: 5.895	 Loss: 0.01108683
2025-06-03 15:24:15,130 - root - INFO -   Epoch 90/100	 Time: 5.701	 Loss: 0.01109192
2025-06-03 15:24:20,868 - root - INFO -   Epoch 91/100	 Time: 5.738	 Loss: 0.01108528
2025-06-03 15:24:26,579 - root - INFO -   Epoch 92/100	 Time: 5.711	 Loss: 0.01107627
2025-06-03 15:24:32,210 - root - INFO -   Epoch 93/100	 Time: 5.631	 Loss: 0.01106737
2025-06-03 15:24:38,025 - root - INFO -   Epoch 94/100	 Time: 5.815	 Loss: 0.01106588
2025-06-03 15:24:43,767 - root - INFO -   Epoch 95/100	 Time: 5.741	 Loss: 0.01105461
2025-06-03 15:24:49,521 - root - INFO -   Epoch 96/100	 Time: 5.753	 Loss: 0.01104582
2025-06-03 15:24:55,274 - root - INFO -   Epoch 97/100	 Time: 5.753	 Loss: 0.01105244
2025-06-03 15:25:01,141 - root - INFO -   Epoch 98/100	 Time: 5.867	 Loss: 0.01104262
2025-06-03 15:25:06,810 - root - INFO -   Epoch 99/100	 Time: 5.669	 Loss: 0.01104336
2025-06-03 15:25:12,641 - root - INFO -   Epoch 100/100	 Time: 5.831	 Loss: 0.01102599
2025-06-03 15:25:12,641 - root - INFO - Pretraining time: 578.303
2025-06-03 15:25:12,642 - root - INFO - Finished pretraining.
2025-06-03 15:25:12,643 - root - INFO - Testing autoencoder...
2025-06-03 15:25:12,844 - root - INFO - Test set Loss: 0.01734363
2025-06-03 15:25:12,857 - root - INFO - Test set AUC: 92.59%
2025-06-03 15:25:12,858 - root - INFO - Autoencoder testing time: 0.214
2025-06-03 15:25:12,858 - root - INFO - Finished testing autoencoder.
2025-06-03 15:25:12,860 - root - INFO - Training optimizer: adam
2025-06-03 15:25:12,860 - root - INFO - Training learning rate: 0.001
2025-06-03 15:25:12,860 - root - INFO - Training epochs: 50
2025-06-03 15:25:12,860 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-03 15:25:12,860 - root - INFO - Training batch size: 128
2025-06-03 15:25:12,861 - root - INFO - Training weight decay: 1e-06
2025-06-03 15:25:12,862 - root - INFO - Initializing center c...
2025-06-03 15:25:14,293 - root - INFO - Center c initialized.
2025-06-03 15:25:14,294 - root - INFO - Starting training...
2025-06-03 15:25:18,627 - root - INFO -   Epoch 1/50	 Time: 4.331	 Loss: 0.00178475
2025-06-03 15:25:22,903 - root - INFO -   Epoch 2/50	 Time: 4.276	 Loss: 0.00002680
2025-06-03 15:25:27,087 - root - INFO -   Epoch 3/50	 Time: 4.184	 Loss: 0.00002867
2025-06-03 15:25:31,332 - root - INFO -   Epoch 4/50	 Time: 4.245	 Loss: 0.00003281
2025-06-03 15:25:35,658 - root - INFO -   Epoch 5/50	 Time: 4.326	 Loss: 0.00003140
2025-06-03 15:25:39,836 - root - INFO -   Epoch 6/50	 Time: 4.178	 Loss: 0.00002648
2025-06-03 15:25:44,111 - root - INFO -   Epoch 7/50	 Time: 4.275	 Loss: 0.00002547
2025-06-03 15:25:48,324 - root - INFO -   Epoch 8/50	 Time: 4.213	 Loss: 0.00002499
2025-06-03 15:25:52,617 - root - INFO -   Epoch 9/50	 Time: 4.292	 Loss: 0.00002064
2025-06-03 15:25:56,883 - root - INFO -   Epoch 10/50	 Time: 4.266	 Loss: 0.00002139
2025-06-03 15:26:01,194 - root - INFO -   Epoch 11/50	 Time: 4.311	 Loss: 0.00001953
2025-06-03 15:26:05,433 - root - INFO -   Epoch 12/50	 Time: 4.239	 Loss: 0.00001895
2025-06-03 15:26:09,662 - root - INFO -   Epoch 13/50	 Time: 4.229	 Loss: 0.00001889
2025-06-03 15:26:13,842 - root - INFO -   Epoch 14/50	 Time: 4.179	 Loss: 0.00001660
2025-06-03 15:26:18,089 - root - INFO -   Epoch 15/50	 Time: 4.247	 Loss: 0.00001674
2025-06-03 15:26:22,289 - root - INFO -   Epoch 16/50	 Time: 4.200	 Loss: 0.00001637
2025-06-03 15:26:26,508 - root - INFO -   Epoch 17/50	 Time: 4.219	 Loss: 0.00001539
2025-06-03 15:26:30,772 - root - INFO -   Epoch 18/50	 Time: 4.263	 Loss: 0.00001492
2025-06-03 15:26:34,927 - root - INFO -   Epoch 19/50	 Time: 4.155	 Loss: 0.00001498
2025-06-03 15:26:39,173 - root - INFO -   Epoch 20/50	 Time: 4.246	 Loss: 0.00001455
2025-06-03 15:26:43,420 - root - INFO -   Epoch 21/50	 Time: 4.246	 Loss: 0.00001397
2025-06-03 15:26:47,790 - root - INFO -   Epoch 22/50	 Time: 4.370	 Loss: 0.00001393
2025-06-03 15:26:52,002 - root - INFO -   Epoch 23/50	 Time: 4.212	 Loss: 0.00001422
2025-06-03 15:26:56,216 - root - INFO -   Epoch 24/50	 Time: 4.214	 Loss: 0.00001409
2025-06-03 15:27:00,557 - root - INFO -   Epoch 25/50	 Time: 4.341	 Loss: 0.00001317
2025-06-03 15:27:05,296 - root - INFO -   Epoch 26/50	 Time: 4.739	 Loss: 0.00001364
2025-06-03 15:27:09,500 - root - INFO -   Epoch 27/50	 Time: 4.203	 Loss: 0.00001240
2025-06-03 15:27:13,735 - root - INFO -   Epoch 28/50	 Time: 4.235	 Loss: 0.00001273
2025-06-03 15:27:17,935 - root - INFO -   Epoch 29/50	 Time: 4.201	 Loss: 0.00001311
2025-06-03 15:27:22,156 - root - INFO -   Epoch 30/50	 Time: 4.220	 Loss: 0.00001203
2025-06-03 15:27:26,540 - root - INFO -   Epoch 31/50	 Time: 4.384	 Loss: 0.00001218
2025-06-03 15:27:30,712 - root - INFO -   Epoch 32/50	 Time: 4.173	 Loss: 0.00001214
2025-06-03 15:27:34,946 - root - INFO -   Epoch 33/50	 Time: 4.233	 Loss: 0.00001205
2025-06-03 15:27:39,166 - root - INFO -   Epoch 34/50	 Time: 4.220	 Loss: 0.00001198
2025-06-03 15:27:43,463 - root - INFO -   Epoch 35/50	 Time: 4.297	 Loss: 0.00001231
2025-06-03 15:27:47,671 - root - INFO -   Epoch 36/50	 Time: 4.207	 Loss: 0.00001211
2025-06-03 15:27:51,926 - root - INFO -   Epoch 37/50	 Time: 4.255	 Loss: 0.00001211
2025-06-03 15:27:56,197 - root - INFO -   Epoch 38/50	 Time: 4.272	 Loss: 0.00001168
2025-06-03 15:28:00,506 - root - INFO -   Epoch 39/50	 Time: 4.309	 Loss: 0.00001180
2025-06-03 15:28:04,793 - root - INFO -   Epoch 40/50	 Time: 4.286	 Loss: 0.00001161
2025-06-03 15:28:08,998 - root - INFO -   Epoch 41/50	 Time: 4.204	 Loss: 0.00001173
2025-06-03 15:28:13,283 - root - INFO -   Epoch 42/50	 Time: 4.285	 Loss: 0.00001133
2025-06-03 15:28:17,471 - root - INFO -   Epoch 43/50	 Time: 4.187	 Loss: 0.00001147
2025-06-03 15:28:21,699 - root - INFO -   Epoch 44/50	 Time: 4.228	 Loss: 0.00001153
2025-06-03 15:28:25,928 - root - INFO -   Epoch 45/50	 Time: 4.229	 Loss: 0.00001130
2025-06-03 15:28:30,154 - root - INFO -   Epoch 46/50	 Time: 4.226	 Loss: 0.00001075
2025-06-03 15:28:34,330 - root - INFO -   Epoch 47/50	 Time: 4.176	 Loss: 0.00001175
2025-06-03 15:28:38,577 - root - INFO -   Epoch 48/50	 Time: 4.246	 Loss: 0.00001111
2025-06-03 15:28:42,797 - root - INFO -   Epoch 49/50	 Time: 4.220	 Loss: 0.00001125
2025-06-03 15:28:47,064 - root - INFO -   Epoch 50/50	 Time: 4.267	 Loss: 0.00001144
2025-06-03 15:28:47,064 - root - INFO - Training time: 212.770
2025-06-03 15:28:47,065 - root - INFO - Finished training.
2025-06-03 15:28:47,065 - root - INFO - Starting testing...
2025-06-03 15:28:47,219 - root - INFO - Testing time: 0.154
2025-06-03 15:28:47,223 - root - INFO - Test set AUC: 93.00%
2025-06-03 15:28:47,223 - root - INFO - Finished testing.
2025-06-03 15:46:55,847 - root - INFO - Log file is ../log/log.txt.
2025-06-03 15:46:55,847 - root - INFO - Data path is ../data.
2025-06-03 15:46:55,847 - root - INFO - Export path is ../log.
2025-06-03 15:46:55,848 - root - INFO - Dataset: visu
2025-06-03 15:46:55,848 - root - INFO - Normal class: 0
2025-06-03 15:46:55,848 - root - INFO - Network: mlp
2025-06-03 15:46:55,849 - root - INFO - Deep SVDD objective: one-class
2025-06-03 15:46:55,849 - root - INFO - Nu-paramerter: 0.10
2025-06-03 15:46:55,849 - root - INFO - Computation device: cuda
2025-06-03 15:46:55,850 - root - INFO - Number of dataloader workers: 0
2025-06-03 15:46:57,173 - root - INFO - Loading model from C:\Users\Asus\PycharmProjects\Deep-SVDD-PyTorch\log\model.tar.
2025-06-03 15:46:57,173 - root - INFO - Pretraining: False
2025-06-03 15:46:57,173 - root - INFO - Training optimizer: adam
2025-06-03 15:46:57,173 - root - INFO - Training learning rate: 0.001
2025-06-03 15:46:57,174 - root - INFO - Training epochs: 50
2025-06-03 15:46:57,174 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-03 15:46:57,174 - root - INFO - Training batch size: 128
2025-06-03 15:46:57,174 - root - INFO - Training weight decay: 1e-06
2025-06-03 15:46:57,176 - root - INFO - Starting training...
2025-06-03 15:47:03,499 - root - INFO -   Epoch 1/50	 Time: 6.321	 Loss: 0.00001168
2025-06-03 15:47:07,809 - root - INFO -   Epoch 2/50	 Time: 4.309	 Loss: 0.00001110
2025-06-03 15:47:12,127 - root - INFO -   Epoch 3/50	 Time: 4.316	 Loss: 0.00001090
2025-06-03 15:47:16,412 - root - INFO -   Epoch 4/50	 Time: 4.286	 Loss: 0.00001102
2025-06-03 15:47:20,666 - root - INFO -   Epoch 5/50	 Time: 4.254	 Loss: 0.00001093
2025-06-03 15:47:25,120 - root - INFO -   Epoch 6/50	 Time: 4.454	 Loss: 0.00001133
2025-06-03 15:47:29,326 - root - INFO -   Epoch 7/50	 Time: 4.206	 Loss: 0.00001106
2025-06-03 15:47:33,724 - root - INFO -   Epoch 8/50	 Time: 4.397	 Loss: 0.00001116
2025-06-03 15:47:38,032 - root - INFO -   Epoch 9/50	 Time: 4.309	 Loss: 0.00001105
2025-06-03 15:47:42,299 - root - INFO -   Epoch 10/50	 Time: 4.267	 Loss: 0.00001116
2025-06-03 15:47:46,551 - root - INFO -   Epoch 11/50	 Time: 4.252	 Loss: 0.00001109
2025-06-03 15:47:50,848 - root - INFO -   Epoch 12/50	 Time: 4.296	 Loss: 0.00001092
2025-06-03 15:47:55,208 - root - INFO -   Epoch 13/50	 Time: 4.359	 Loss: 0.00001099
2025-06-03 15:47:59,500 - root - INFO -   Epoch 14/50	 Time: 4.293	 Loss: 0.00001018
2025-06-03 15:48:04,000 - root - INFO -   Epoch 15/50	 Time: 4.500	 Loss: 0.00001091
2025-06-03 15:48:08,468 - root - INFO -   Epoch 16/50	 Time: 4.468	 Loss: 0.00001051
2025-06-03 15:48:12,741 - root - INFO -   Epoch 17/50	 Time: 4.272	 Loss: 0.00001132
2025-06-03 15:48:17,007 - root - INFO -   Epoch 18/50	 Time: 4.266	 Loss: 0.00001095
2025-06-03 15:48:21,285 - root - INFO -   Epoch 19/50	 Time: 4.276	 Loss: 0.00001076
2025-06-03 15:48:25,696 - root - INFO -   Epoch 20/50	 Time: 4.410	 Loss: 0.00001047
2025-06-03 15:48:29,913 - root - INFO -   Epoch 21/50	 Time: 4.218	 Loss: 0.00001061
2025-06-03 15:48:34,325 - root - INFO -   Epoch 22/50	 Time: 4.412	 Loss: 0.00001074
2025-06-03 15:48:38,628 - root - INFO -   Epoch 23/50	 Time: 4.303	 Loss: 0.00001068
2025-06-03 15:48:42,929 - root - INFO -   Epoch 24/50	 Time: 4.301	 Loss: 0.00001060
2025-06-03 15:48:47,159 - root - INFO -   Epoch 25/50	 Time: 4.231	 Loss: 0.00001048
2025-06-03 15:48:51,538 - root - INFO -   Epoch 26/50	 Time: 4.378	 Loss: 0.00001046
2025-06-03 15:48:55,819 - root - INFO -   Epoch 27/50	 Time: 4.279	 Loss: 0.00001056
2025-06-03 15:49:00,077 - root - INFO -   Epoch 28/50	 Time: 4.259	 Loss: 0.00001093
2025-06-03 15:49:04,505 - root - INFO -   Epoch 29/50	 Time: 4.428	 Loss: 0.00001064
2025-06-03 15:49:08,909 - root - INFO -   Epoch 30/50	 Time: 4.404	 Loss: 0.00001079
2025-06-03 15:49:13,256 - root - INFO -   Epoch 31/50	 Time: 4.346	 Loss: 0.00001039
2025-06-03 15:49:17,434 - root - INFO -   Epoch 32/50	 Time: 4.178	 Loss: 0.00001016
2025-06-03 15:49:21,728 - root - INFO -   Epoch 33/50	 Time: 4.293	 Loss: 0.00001024
2025-06-03 15:49:26,041 - root - INFO -   Epoch 34/50	 Time: 4.314	 Loss: 0.00001076
2025-06-03 15:49:30,338 - root - INFO -   Epoch 35/50	 Time: 4.297	 Loss: 0.00001046
2025-06-03 15:49:34,713 - root - INFO -   Epoch 36/50	 Time: 4.375	 Loss: 0.00001067
2025-06-03 15:49:39,063 - root - INFO -   Epoch 37/50	 Time: 4.350	 Loss: 0.00001054
2025-06-03 15:49:43,313 - root - INFO -   Epoch 38/50	 Time: 4.251	 Loss: 0.00001066
2025-06-03 15:49:47,588 - root - INFO -   Epoch 39/50	 Time: 4.275	 Loss: 0.00001065
2025-06-03 15:49:51,886 - root - INFO -   Epoch 40/50	 Time: 4.297	 Loss: 0.00001012
2025-06-03 15:49:56,130 - root - INFO -   Epoch 41/50	 Time: 4.244	 Loss: 0.00001020
2025-06-03 15:50:00,527 - root - INFO -   Epoch 42/50	 Time: 4.397	 Loss: 0.00001058
2025-06-03 15:50:04,921 - root - INFO -   Epoch 43/50	 Time: 4.395	 Loss: 0.00001028
2025-06-03 15:50:09,314 - root - INFO -   Epoch 44/50	 Time: 4.391	 Loss: 0.00001034
2025-06-03 15:50:13,551 - root - INFO -   Epoch 45/50	 Time: 4.237	 Loss: 0.00001039
2025-06-03 15:50:17,793 - root - INFO -   Epoch 46/50	 Time: 4.242	 Loss: 0.00001025
2025-06-03 15:50:22,138 - root - INFO -   Epoch 47/50	 Time: 4.344	 Loss: 0.00001033
2025-06-03 15:50:26,425 - root - INFO -   Epoch 48/50	 Time: 4.286	 Loss: 0.00001011
2025-06-03 15:50:30,810 - root - INFO -   Epoch 49/50	 Time: 4.384	 Loss: 0.00001035
2025-06-03 15:50:35,254 - root - INFO -   Epoch 50/50	 Time: 4.444	 Loss: 0.00001055
2025-06-03 15:50:35,255 - root - INFO - Training time: 218.079
2025-06-03 15:50:35,255 - root - INFO - Finished training.
2025-06-03 15:50:35,255 - root - INFO - Starting testing...
2025-06-03 15:50:35,402 - root - INFO - Testing time: 0.146
2025-06-03 15:50:35,408 - root - INFO - Test set AUC: 82.83%
2025-06-03 15:50:35,408 - root - INFO - Finished testing.
2025-06-03 15:58:36,509 - root - INFO - Log file is ../log/log.txt.
2025-06-03 15:58:36,509 - root - INFO - Data path is ../data.
2025-06-03 15:58:36,510 - root - INFO - Export path is ../log.
2025-06-03 15:58:36,510 - root - INFO - Dataset: visu
2025-06-03 15:58:36,510 - root - INFO - Normal class: 0
2025-06-03 15:58:36,510 - root - INFO - Network: mlp
2025-06-03 15:58:36,511 - root - INFO - Deep SVDD objective: one-class
2025-06-03 15:58:36,511 - root - INFO - Nu-paramerter: 0.10
2025-06-03 15:59:28,353 - root - INFO - Log file is ../log/log.txt.
2025-06-03 15:59:28,353 - root - INFO - Data path is ../data.
2025-06-03 15:59:28,353 - root - INFO - Export path is ../log.
2025-06-03 15:59:28,353 - root - INFO - Dataset: visu
2025-06-03 15:59:28,353 - root - INFO - Normal class: 0
2025-06-03 15:59:28,353 - root - INFO - Network: mlp
2025-06-03 15:59:28,354 - root - INFO - Deep SVDD objective: one-class
2025-06-03 15:59:28,354 - root - INFO - Nu-paramerter: 0.10
2025-06-03 15:59:28,354 - root - INFO - Computation device: cuda
2025-06-03 15:59:28,354 - root - INFO - Number of dataloader workers: 0
2025-06-03 15:59:28,705 - root - INFO - Loading model from C:\Users\Asus\PycharmProjects\Deep-SVDD-PyTorch\log\model.tar.
2025-06-03 15:59:28,705 - root - INFO - Pretraining: False
2025-06-03 15:59:28,705 - root - INFO - Training optimizer: adam
2025-06-03 15:59:28,706 - root - INFO - Training learning rate: 0.001
2025-06-03 15:59:28,706 - root - INFO - Training epochs: 50
2025-06-03 15:59:28,706 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-03 15:59:28,706 - root - INFO - Training batch size: 128
2025-06-03 15:59:28,706 - root - INFO - Training weight decay: 1e-06
2025-06-03 15:59:28,709 - root - INFO - Starting training...
2025-06-03 15:59:35,275 - root - INFO -   Epoch 1/50	 Time: 6.565	 Loss: 0.00001203
2025-06-03 15:59:40,289 - root - INFO -   Epoch 2/50	 Time: 5.013	 Loss: 0.00001018
2025-06-03 15:59:45,628 - root - INFO -   Epoch 3/50	 Time: 5.338	 Loss: 0.00001019
2025-06-03 15:59:50,327 - root - INFO -   Epoch 4/50	 Time: 4.699	 Loss: 0.00001040
2025-06-03 15:59:55,608 - root - INFO -   Epoch 5/50	 Time: 5.280	 Loss: 0.00001021
2025-06-03 16:00:00,730 - root - INFO -   Epoch 6/50	 Time: 5.123	 Loss: 0.00001018
2025-06-03 16:00:05,832 - root - INFO -   Epoch 7/50	 Time: 5.101	 Loss: 0.00001008
2025-06-03 16:00:10,610 - root - INFO -   Epoch 8/50	 Time: 4.779	 Loss: 0.00001081
2025-06-03 16:00:15,258 - root - INFO -   Epoch 9/50	 Time: 4.647	 Loss: 0.00001030
2025-06-03 16:00:19,973 - root - INFO -   Epoch 10/50	 Time: 4.713	 Loss: 0.00000977
2025-06-03 16:00:24,607 - root - INFO -   Epoch 11/50	 Time: 4.634	 Loss: 0.00001058
2025-06-03 16:00:29,167 - root - INFO -   Epoch 12/50	 Time: 4.560	 Loss: 0.00001048
2025-06-03 16:00:33,973 - root - INFO -   Epoch 13/50	 Time: 4.805	 Loss: 0.00001034
2025-06-03 16:00:38,571 - root - INFO -   Epoch 14/50	 Time: 4.598	 Loss: 0.00000990
2025-06-03 16:00:43,097 - root - INFO -   Epoch 15/50	 Time: 4.526	 Loss: 0.00001051
2025-06-03 16:00:47,621 - root - INFO -   Epoch 16/50	 Time: 4.524	 Loss: 0.00000996
2025-06-03 16:00:52,216 - root - INFO -   Epoch 17/50	 Time: 4.595	 Loss: 0.00001038
2025-06-03 16:00:56,731 - root - INFO -   Epoch 18/50	 Time: 4.515	 Loss: 0.00001016
2025-06-03 16:01:01,347 - root - INFO -   Epoch 19/50	 Time: 4.615	 Loss: 0.00000998
2025-06-03 16:01:05,978 - root - INFO -   Epoch 20/50	 Time: 4.631	 Loss: 0.00001054
2025-06-03 16:01:10,628 - root - INFO -   Epoch 21/50	 Time: 4.651	 Loss: 0.00000987
2025-06-03 16:01:15,143 - root - INFO -   Epoch 22/50	 Time: 4.515	 Loss: 0.00000975
2025-06-03 16:01:19,667 - root - INFO -   Epoch 23/50	 Time: 4.524	 Loss: 0.00000982
2025-06-03 16:01:24,258 - root - INFO -   Epoch 24/50	 Time: 4.592	 Loss: 0.00001017
2025-06-03 16:01:28,814 - root - INFO -   Epoch 25/50	 Time: 4.556	 Loss: 0.00000994
2025-06-03 16:01:33,374 - root - INFO -   Epoch 26/50	 Time: 4.560	 Loss: 0.00001043
2025-06-03 16:01:38,089 - root - INFO -   Epoch 27/50	 Time: 4.716	 Loss: 0.00000975
2025-06-03 16:01:42,613 - root - INFO -   Epoch 28/50	 Time: 4.524	 Loss: 0.00001005
2025-06-03 16:01:47,226 - root - INFO -   Epoch 29/50	 Time: 4.611	 Loss: 0.00001017
2025-06-03 16:01:51,911 - root - INFO -   Epoch 30/50	 Time: 4.685	 Loss: 0.00001014
2025-06-03 16:01:56,414 - root - INFO -   Epoch 31/50	 Time: 4.502	 Loss: 0.00000988
2025-06-03 16:02:01,075 - root - INFO -   Epoch 32/50	 Time: 4.661	 Loss: 0.00000979
2025-06-03 16:02:05,653 - root - INFO -   Epoch 33/50	 Time: 4.577	 Loss: 0.00000998
2025-06-03 16:02:10,298 - root - INFO -   Epoch 34/50	 Time: 4.643	 Loss: 0.00001017
2025-06-03 16:02:14,834 - root - INFO -   Epoch 35/50	 Time: 4.537	 Loss: 0.00000990
2025-06-03 16:02:19,373 - root - INFO -   Epoch 36/50	 Time: 4.539	 Loss: 0.00001008
2025-06-03 16:02:23,967 - root - INFO -   Epoch 37/50	 Time: 4.594	 Loss: 0.00001020
2025-06-03 16:02:28,507 - root - INFO -   Epoch 38/50	 Time: 4.540	 Loss: 0.00001017
2025-06-03 16:02:32,990 - root - INFO -   Epoch 39/50	 Time: 4.483	 Loss: 0.00000973
2025-06-03 16:02:37,709 - root - INFO -   Epoch 40/50	 Time: 4.718	 Loss: 0.00001014
2025-06-03 16:02:42,212 - root - INFO -   Epoch 41/50	 Time: 4.504	 Loss: 0.00001020
2025-06-03 16:02:46,749 - root - INFO -   Epoch 42/50	 Time: 4.536	 Loss: 0.00001004
2025-06-03 16:02:51,327 - root - INFO -   Epoch 43/50	 Time: 4.578	 Loss: 0.00000982
2025-06-03 16:02:55,938 - root - INFO -   Epoch 44/50	 Time: 4.609	 Loss: 0.00000993
2025-06-03 16:03:00,554 - root - INFO -   Epoch 45/50	 Time: 4.615	 Loss: 0.00000985
2025-06-03 16:03:05,184 - root - INFO -   Epoch 46/50	 Time: 4.631	 Loss: 0.00000975
2025-06-03 16:03:09,760 - root - INFO -   Epoch 47/50	 Time: 4.576	 Loss: 0.00000995
2025-06-03 16:03:14,305 - root - INFO -   Epoch 48/50	 Time: 4.545	 Loss: 0.00000985
2025-06-03 16:03:18,883 - root - INFO -   Epoch 49/50	 Time: 4.576	 Loss: 0.00000954
2025-06-03 16:03:23,482 - root - INFO -   Epoch 50/50	 Time: 4.600	 Loss: 0.00001010
2025-06-03 16:03:23,482 - root - INFO - Training time: 234.773
2025-06-03 16:03:23,483 - root - INFO - Finished training.
2025-06-03 16:03:23,491 - root - INFO - Starting testing...
2025-06-03 16:03:23,631 - root - INFO - Testing time: 0.140
2025-06-03 16:03:23,647 - root - INFO - Test set AUC: 90.86%
2025-06-03 16:03:23,647 - root - INFO - Finished testing.
2025-06-03 16:08:50,200 - root - INFO - Log file is ../log/log.txt.
2025-06-03 16:08:50,201 - root - INFO - Data path is ../data.
2025-06-03 16:08:50,201 - root - INFO - Export path is ../log.
2025-06-03 16:08:50,201 - root - INFO - Dataset: visu
2025-06-03 16:08:50,202 - root - INFO - Normal class: 0
2025-06-03 16:08:50,202 - root - INFO - Network: mlp
2025-06-03 16:08:50,202 - root - INFO - Deep SVDD objective: one-class
2025-06-03 16:08:50,202 - root - INFO - Nu-paramerter: 0.10
2025-06-03 16:08:50,202 - root - INFO - Computation device: cuda
2025-06-03 16:08:50,202 - root - INFO - Number of dataloader workers: 0
2025-06-03 16:08:50,902 - root - INFO - Pretraining: True
2025-06-03 16:08:50,903 - root - INFO - Pretraining optimizer: adam
2025-06-03 16:08:50,904 - root - INFO - Pretraining learning rate: 0.001
2025-06-03 16:08:50,904 - root - INFO - Pretraining epochs: 100
2025-06-03 16:08:50,904 - root - INFO - Pretraining learning rate scheduler milestones: ()
2025-06-03 16:08:50,904 - root - INFO - Pretraining batch size: 128
2025-06-03 16:08:50,904 - root - INFO - Pretraining weight decay: 1e-06
2025-06-03 16:08:51,086 - root - INFO - Starting pretraining...
2025-06-03 16:08:58,820 - root - INFO -   Epoch 1/100	 Time: 7.731	 Loss: 0.04646395
2025-06-03 16:09:04,890 - root - INFO -   Epoch 2/100	 Time: 6.069	 Loss: 0.02841538
2025-06-03 16:09:11,080 - root - INFO -   Epoch 3/100	 Time: 6.190	 Loss: 0.02367085
2025-06-03 16:09:17,088 - root - INFO -   Epoch 4/100	 Time: 6.008	 Loss: 0.02109591
2025-06-03 16:09:23,219 - root - INFO -   Epoch 5/100	 Time: 6.130	 Loss: 0.01941666
2025-06-03 16:09:29,028 - root - INFO -   Epoch 6/100	 Time: 5.810	 Loss: 0.01826829
2025-06-03 16:09:35,070 - root - INFO -   Epoch 7/100	 Time: 6.042	 Loss: 0.01744050
2025-06-03 16:09:41,176 - root - INFO -   Epoch 8/100	 Time: 6.106	 Loss: 0.01676593
2025-06-03 16:09:47,278 - root - INFO -   Epoch 9/100	 Time: 6.102	 Loss: 0.01616038
2025-06-03 16:09:53,334 - root - INFO -   Epoch 10/100	 Time: 6.055	 Loss: 0.01569670
2025-06-03 16:09:59,128 - root - INFO -   Epoch 11/100	 Time: 5.795	 Loss: 0.01538219
2025-06-03 16:10:05,344 - root - INFO -   Epoch 12/100	 Time: 6.216	 Loss: 0.01511924
2025-06-03 16:10:11,452 - root - INFO -   Epoch 13/100	 Time: 6.107	 Loss: 0.01490443
2025-06-03 16:10:17,457 - root - INFO -   Epoch 14/100	 Time: 6.004	 Loss: 0.01464939
2025-06-03 16:10:23,509 - root - INFO -   Epoch 15/100	 Time: 6.050	 Loss: 0.01447862
2025-06-03 16:10:29,594 - root - INFO -   Epoch 16/100	 Time: 6.085	 Loss: 0.01432772
2025-06-03 16:10:36,014 - root - INFO -   Epoch 17/100	 Time: 6.420	 Loss: 0.01421403
2025-06-03 16:10:42,152 - root - INFO -   Epoch 18/100	 Time: 6.139	 Loss: 0.01409860
2025-06-03 16:10:48,235 - root - INFO -   Epoch 19/100	 Time: 6.082	 Loss: 0.01396760
2025-06-03 16:10:54,218 - root - INFO -   Epoch 20/100	 Time: 5.983	 Loss: 0.01382621
2025-06-03 16:11:00,269 - root - INFO -   Epoch 21/100	 Time: 6.051	 Loss: 0.01366021
2025-06-03 16:11:06,444 - root - INFO -   Epoch 22/100	 Time: 6.174	 Loss: 0.01352499
2025-06-03 16:11:12,638 - root - INFO -   Epoch 23/100	 Time: 6.194	 Loss: 0.01342778
2025-06-03 16:11:18,569 - root - INFO -   Epoch 24/100	 Time: 5.931	 Loss: 0.01333446
2025-06-03 16:11:24,705 - root - INFO -   Epoch 25/100	 Time: 6.134	 Loss: 0.01325319
2025-06-03 16:11:30,650 - root - INFO -   Epoch 26/100	 Time: 5.944	 Loss: 0.01315531
2025-06-03 16:11:37,098 - root - INFO -   Epoch 27/100	 Time: 6.448	 Loss: 0.01307524
2025-06-03 16:11:43,331 - root - INFO -   Epoch 28/100	 Time: 6.233	 Loss: 0.01298684
2025-06-03 16:11:49,580 - root - INFO -   Epoch 29/100	 Time: 6.248	 Loss: 0.01290233
2025-06-03 16:11:55,901 - root - INFO -   Epoch 30/100	 Time: 6.322	 Loss: 0.01284987
2025-06-03 16:12:01,937 - root - INFO -   Epoch 31/100	 Time: 6.036	 Loss: 0.01280055
2025-06-03 16:12:08,070 - root - INFO -   Epoch 32/100	 Time: 6.133	 Loss: 0.01276713
2025-06-03 16:12:14,146 - root - INFO -   Epoch 33/100	 Time: 6.075	 Loss: 0.01272395
2025-06-03 16:12:20,015 - root - INFO -   Epoch 34/100	 Time: 5.869	 Loss: 0.01268581
2025-06-03 16:12:26,221 - root - INFO -   Epoch 35/100	 Time: 6.205	 Loss: 0.01264279
2025-06-03 16:12:32,214 - root - INFO -   Epoch 36/100	 Time: 5.993	 Loss: 0.01261709
2025-06-03 16:12:38,556 - root - INFO -   Epoch 37/100	 Time: 6.342	 Loss: 0.01258932
2025-06-03 16:12:44,482 - root - INFO -   Epoch 38/100	 Time: 5.925	 Loss: 0.01254260
2025-06-03 16:12:50,423 - root - INFO -   Epoch 39/100	 Time: 5.941	 Loss: 0.01249785
2025-06-03 16:12:56,508 - root - INFO -   Epoch 40/100	 Time: 6.085	 Loss: 0.01242750
2025-06-03 16:13:02,780 - root - INFO -   Epoch 41/100	 Time: 6.271	 Loss: 0.01236907
2025-06-03 16:13:08,861 - root - INFO -   Epoch 42/100	 Time: 6.081	 Loss: 0.01233449
2025-06-03 16:13:14,862 - root - INFO -   Epoch 43/100	 Time: 6.002	 Loss: 0.01230902
2025-06-03 16:13:20,715 - root - INFO -   Epoch 44/100	 Time: 5.853	 Loss: 0.01225642
2025-06-03 16:13:27,057 - root - INFO -   Epoch 45/100	 Time: 6.340	 Loss: 0.01222031
2025-06-03 16:13:33,845 - root - INFO -   Epoch 46/100	 Time: 6.788	 Loss: 0.01216544
2025-06-03 16:13:40,591 - root - INFO -   Epoch 47/100	 Time: 6.746	 Loss: 0.01211427
2025-06-03 16:13:46,535 - root - INFO -   Epoch 48/100	 Time: 5.943	 Loss: 0.01208282
2025-06-03 16:13:52,737 - root - INFO -   Epoch 49/100	 Time: 6.201	 Loss: 0.01204934
2025-06-03 16:13:59,756 - root - INFO -   Epoch 50/100	 Time: 7.019	 Loss: 0.01201431
2025-06-03 16:14:07,643 - root - INFO -   Epoch 51/100	 Time: 7.886	 Loss: 0.01198937
2025-06-03 16:14:15,229 - root - INFO -   Epoch 52/100	 Time: 7.586	 Loss: 0.01197182
2025-06-03 16:14:22,738 - root - INFO -   Epoch 53/100	 Time: 7.509	 Loss: 0.01194469
2025-06-03 16:14:30,173 - root - INFO -   Epoch 54/100	 Time: 7.434	 Loss: 0.01192400
2025-06-03 16:14:37,655 - root - INFO -   Epoch 55/100	 Time: 7.483	 Loss: 0.01190481
2025-06-03 16:14:43,637 - root - INFO -   Epoch 56/100	 Time: 5.982	 Loss: 0.01190826
2025-06-03 16:14:49,588 - root - INFO -   Epoch 57/100	 Time: 5.950	 Loss: 0.01188794
2025-06-03 16:14:55,660 - root - INFO -   Epoch 58/100	 Time: 6.072	 Loss: 0.01186536
2025-06-03 16:15:02,421 - root - INFO -   Epoch 59/100	 Time: 6.760	 Loss: 0.01184928
2025-06-03 16:15:08,438 - root - INFO -   Epoch 60/100	 Time: 6.018	 Loss: 0.01185599
2025-06-03 16:15:14,401 - root - INFO -   Epoch 61/100	 Time: 5.962	 Loss: 0.01184711
2025-06-03 16:15:20,242 - root - INFO -   Epoch 62/100	 Time: 5.840	 Loss: 0.01183985
2025-06-03 16:15:26,291 - root - INFO -   Epoch 63/100	 Time: 6.048	 Loss: 0.01181635
2025-06-03 16:15:32,187 - root - INFO -   Epoch 64/100	 Time: 5.896	 Loss: 0.01181494
2025-06-03 16:15:38,320 - root - INFO -   Epoch 65/100	 Time: 6.131	 Loss: 0.01180438
2025-06-03 16:15:44,158 - root - INFO -   Epoch 66/100	 Time: 5.839	 Loss: 0.01179332
2025-06-03 16:15:50,139 - root - INFO -   Epoch 67/100	 Time: 5.980	 Loss: 0.01175653
2025-06-03 16:15:56,219 - root - INFO -   Epoch 68/100	 Time: 6.080	 Loss: 0.01173510
2025-06-03 16:16:02,502 - root - INFO -   Epoch 69/100	 Time: 6.282	 Loss: 0.01170987
2025-06-03 16:16:08,545 - root - INFO -   Epoch 70/100	 Time: 6.043	 Loss: 0.01168248
2025-06-03 16:16:14,491 - root - INFO -   Epoch 71/100	 Time: 5.946	 Loss: 0.01166141
2025-06-03 16:16:20,403 - root - INFO -   Epoch 72/100	 Time: 5.912	 Loss: 0.01164131
2025-06-03 16:16:26,389 - root - INFO -   Epoch 73/100	 Time: 5.985	 Loss: 0.01163081
2025-06-03 16:16:32,230 - root - INFO -   Epoch 74/100	 Time: 5.839	 Loss: 0.01162448
2025-06-03 16:16:38,435 - root - INFO -   Epoch 75/100	 Time: 6.206	 Loss: 0.01160607
2025-06-03 16:16:44,379 - root - INFO -   Epoch 76/100	 Time: 5.944	 Loss: 0.01158944
2025-06-03 16:16:50,376 - root - INFO -   Epoch 77/100	 Time: 5.997	 Loss: 0.01158267
2025-06-03 16:16:56,688 - root - INFO -   Epoch 78/100	 Time: 6.312	 Loss: 0.01158069
2025-06-03 16:17:02,808 - root - INFO -   Epoch 79/100	 Time: 6.120	 Loss: 0.01156715
2025-06-03 16:17:08,806 - root - INFO -   Epoch 80/100	 Time: 5.998	 Loss: 0.01155546
2025-06-03 16:17:14,787 - root - INFO -   Epoch 81/100	 Time: 5.981	 Loss: 0.01154589
2025-06-03 16:17:20,715 - root - INFO -   Epoch 82/100	 Time: 5.927	 Loss: 0.01153608
2025-06-03 16:17:26,718 - root - INFO -   Epoch 83/100	 Time: 6.003	 Loss: 0.01152870
2025-06-03 16:17:32,658 - root - INFO -   Epoch 84/100	 Time: 5.939	 Loss: 0.01152877
2025-06-03 16:17:38,834 - root - INFO -   Epoch 85/100	 Time: 6.176	 Loss: 0.01151903
2025-06-03 16:17:44,632 - root - INFO -   Epoch 86/100	 Time: 5.798	 Loss: 0.01151667
2025-06-03 16:17:50,484 - root - INFO -   Epoch 87/100	 Time: 5.852	 Loss: 0.01150638
2025-06-03 16:17:56,583 - root - INFO -   Epoch 88/100	 Time: 6.099	 Loss: 0.01150420
2025-06-03 16:18:02,815 - root - INFO -   Epoch 89/100	 Time: 6.231	 Loss: 0.01148895
2025-06-03 16:18:08,969 - root - INFO -   Epoch 90/100	 Time: 6.153	 Loss: 0.01148525
2025-06-03 16:18:14,945 - root - INFO -   Epoch 91/100	 Time: 5.976	 Loss: 0.01145667
2025-06-03 16:18:20,925 - root - INFO -   Epoch 92/100	 Time: 5.980	 Loss: 0.01145060
2025-06-03 16:18:26,979 - root - INFO -   Epoch 93/100	 Time: 6.054	 Loss: 0.01143000
2025-06-03 16:18:32,952 - root - INFO -   Epoch 94/100	 Time: 5.972	 Loss: 0.01140591
2025-06-03 16:18:39,196 - root - INFO -   Epoch 95/100	 Time: 6.243	 Loss: 0.01139004
2025-06-03 16:18:45,069 - root - INFO -   Epoch 96/100	 Time: 5.874	 Loss: 0.01138796
2025-06-03 16:18:51,010 - root - INFO -   Epoch 97/100	 Time: 5.940	 Loss: 0.01138687
2025-06-03 16:18:57,045 - root - INFO -   Epoch 98/100	 Time: 6.035	 Loss: 0.01137029
2025-06-03 16:19:03,443 - root - INFO -   Epoch 99/100	 Time: 6.397	 Loss: 0.01135717
2025-06-03 16:19:09,642 - root - INFO -   Epoch 100/100	 Time: 6.199	 Loss: 0.01135995
2025-06-03 16:19:09,642 - root - INFO - Pretraining time: 618.555
2025-06-03 16:19:09,642 - root - INFO - Finished pretraining.
2025-06-03 16:19:09,644 - root - INFO - Testing autoencoder...
2025-06-03 16:19:09,831 - root - INFO - Test set Loss: 0.01850325
2025-06-03 16:19:09,847 - root - INFO - Test set AUC: 93.60%
2025-06-03 16:19:09,847 - root - INFO - Autoencoder testing time: 0.203
2025-06-03 16:19:09,848 - root - INFO - Finished testing autoencoder.
2025-06-03 16:19:09,850 - root - INFO - Training optimizer: adam
2025-06-03 16:19:09,850 - root - INFO - Training learning rate: 0.001
2025-06-03 16:19:09,851 - root - INFO - Training epochs: 50
2025-06-03 16:19:09,851 - root - INFO - Training learning rate scheduler milestones: ()
2025-06-03 16:19:09,851 - root - INFO - Training batch size: 128
2025-06-03 16:19:09,851 - root - INFO - Training weight decay: 1e-06
2025-06-03 16:19:09,852 - root - INFO - Initializing center c...
2025-06-03 16:19:11,429 - root - INFO - Center c initialized.
2025-06-03 16:19:11,430 - root - INFO - Starting training...
2025-06-03 16:19:15,908 - root - INFO -   Epoch 1/50	 Time: 4.478	 Loss: 0.00186729
2025-06-03 16:19:20,255 - root - INFO -   Epoch 2/50	 Time: 4.347	 Loss: 0.00006100
2025-06-03 16:19:24,744 - root - INFO -   Epoch 3/50	 Time: 4.488	 Loss: 0.00005248
2025-06-03 16:19:29,095 - root - INFO -   Epoch 4/50	 Time: 4.352	 Loss: 0.00004922
2025-06-03 16:19:33,427 - root - INFO -   Epoch 5/50	 Time: 4.331	 Loss: 0.00004831
2025-06-03 16:19:37,986 - root - INFO -   Epoch 6/50	 Time: 4.559	 Loss: 0.00004061
2025-06-03 16:19:42,257 - root - INFO -   Epoch 7/50	 Time: 4.270	 Loss: 0.00003821
2025-06-03 16:19:46,676 - root - INFO -   Epoch 8/50	 Time: 4.418	 Loss: 0.00003749
2025-06-03 16:19:51,136 - root - INFO -   Epoch 9/50	 Time: 4.459	 Loss: 0.00003348
2025-06-03 16:19:55,661 - root - INFO -   Epoch 10/50	 Time: 4.525	 Loss: 0.00003215
2025-06-03 16:20:00,025 - root - INFO -   Epoch 11/50	 Time: 4.364	 Loss: 0.00003077
2025-06-03 16:20:04,667 - root - INFO -   Epoch 12/50	 Time: 4.641	 Loss: 0.00002982
2025-06-03 16:20:09,305 - root - INFO -   Epoch 13/50	 Time: 4.638	 Loss: 0.00002916
2025-06-03 16:20:13,739 - root - INFO -   Epoch 14/50	 Time: 4.432	 Loss: 0.00002941
2025-06-03 16:20:18,195 - root - INFO -   Epoch 15/50	 Time: 4.457	 Loss: 0.00002801
2025-06-03 16:20:22,860 - root - INFO -   Epoch 16/50	 Time: 4.664	 Loss: 0.00002697
2025-06-03 16:20:27,236 - root - INFO -   Epoch 17/50	 Time: 4.375	 Loss: 0.00002677
2025-06-03 16:20:31,893 - root - INFO -   Epoch 18/50	 Time: 4.657	 Loss: 0.00002634
2025-06-03 16:20:36,363 - root - INFO -   Epoch 19/50	 Time: 4.470	 Loss: 0.00002473
2025-06-03 16:20:40,867 - root - INFO -   Epoch 20/50	 Time: 4.502	 Loss: 0.00002399
2025-06-03 16:20:45,388 - root - INFO -   Epoch 21/50	 Time: 4.521	 Loss: 0.00002493
2025-06-03 16:20:49,819 - root - INFO -   Epoch 22/50	 Time: 4.429	 Loss: 0.00002424
2025-06-03 16:20:54,520 - root - INFO -   Epoch 23/50	 Time: 4.701	 Loss: 0.00002372
2025-06-03 16:20:58,944 - root - INFO -   Epoch 24/50	 Time: 4.424	 Loss: 0.00002354
2025-06-03 16:21:03,555 - root - INFO -   Epoch 25/50	 Time: 4.612	 Loss: 0.00002273
2025-06-03 16:21:08,088 - root - INFO -   Epoch 26/50	 Time: 4.532	 Loss: 0.00002165
2025-06-03 16:21:12,418 - root - INFO -   Epoch 27/50	 Time: 4.330	 Loss: 0.00002307
2025-06-03 16:21:16,847 - root - INFO -   Epoch 28/50	 Time: 4.429	 Loss: 0.00002144
2025-06-03 16:21:21,162 - root - INFO -   Epoch 29/50	 Time: 4.315	 Loss: 0.00002181
2025-06-03 16:21:25,708 - root - INFO -   Epoch 30/50	 Time: 4.546	 Loss: 0.00001997
2025-06-03 16:21:30,074 - root - INFO -   Epoch 31/50	 Time: 4.366	 Loss: 0.00002171
2025-06-03 16:21:34,499 - root - INFO -   Epoch 32/50	 Time: 4.424	 Loss: 0.00002021
2025-06-03 16:21:39,248 - root - INFO -   Epoch 33/50	 Time: 4.748	 Loss: 0.00001967
2025-06-03 16:21:44,043 - root - INFO -   Epoch 34/50	 Time: 4.795	 Loss: 0.00002233
2025-06-03 16:21:48,409 - root - INFO -   Epoch 35/50	 Time: 4.367	 Loss: 0.00002001
2025-06-03 16:21:53,283 - root - INFO -   Epoch 36/50	 Time: 4.874	 Loss: 0.00001910
2025-06-03 16:21:57,713 - root - INFO -   Epoch 37/50	 Time: 4.430	 Loss: 0.00001948
2025-06-03 16:22:02,463 - root - INFO -   Epoch 38/50	 Time: 4.750	 Loss: 0.00001935
2025-06-03 16:22:07,043 - root - INFO -   Epoch 39/50	 Time: 4.580	 Loss: 0.00001937
2025-06-03 16:22:11,434 - root - INFO -   Epoch 40/50	 Time: 4.389	 Loss: 0.00001968
2025-06-03 16:22:15,858 - root - INFO -   Epoch 41/50	 Time: 4.424	 Loss: 0.00001816
2025-06-03 16:22:20,294 - root - INFO -   Epoch 42/50	 Time: 4.437	 Loss: 0.00001813
2025-06-03 16:22:24,891 - root - INFO -   Epoch 43/50	 Time: 4.597	 Loss: 0.00001910
2025-06-03 16:22:29,371 - root - INFO -   Epoch 44/50	 Time: 4.480	 Loss: 0.00001783
2025-06-03 16:22:33,830 - root - INFO -   Epoch 45/50	 Time: 4.459	 Loss: 0.00001872
2025-06-03 16:22:38,388 - root - INFO -   Epoch 46/50	 Time: 4.558	 Loss: 0.00001797
2025-06-03 16:22:42,828 - root - INFO -   Epoch 47/50	 Time: 4.438	 Loss: 0.00001753
2025-06-03 16:22:47,409 - root - INFO -   Epoch 48/50	 Time: 4.580	 Loss: 0.00001692
2025-06-03 16:22:51,982 - root - INFO -   Epoch 49/50	 Time: 4.574	 Loss: 0.00001702
2025-06-03 16:22:56,350 - root - INFO -   Epoch 50/50	 Time: 4.367	 Loss: 0.00001736
2025-06-03 16:22:56,351 - root - INFO - Training time: 224.921
2025-06-03 16:22:56,351 - root - INFO - Finished training.
2025-06-03 16:22:56,352 - root - INFO - Starting testing...
2025-06-03 16:22:56,505 - root - INFO - Testing time: 0.154
2025-06-03 16:22:56,510 - root - INFO - Test set AUC: 92.92%
2025-06-03 16:22:56,510 - root - INFO - Finished testing.
