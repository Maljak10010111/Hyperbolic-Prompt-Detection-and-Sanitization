{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3da07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import geoopt\n",
    "\n",
    "\n",
    "def pairwise_inner(x: Tensor, y: Tensor, curv: float | Tensor = 1.0):\n",
    "    x_time = torch.sqrt(1 / curv + torch.sum(x**2, dim=-1, keepdim=True))\n",
    "    y_time = torch.sqrt(1 / curv + torch.sum(y**2, dim=-1, keepdim=True))\n",
    "    xyl = x @ y.T - x_time @ y_time.T\n",
    "    return xyl\n",
    "\n",
    "\n",
    "def pairwise_dist(\n",
    "    x: Tensor, y: Tensor, curv: float | Tensor = 1.0, eps: float = 1e-8\n",
    ") -> Tensor:\n",
    "    c_xyl = -curv * pairwise_inner(x, y, curv)\n",
    "    _distance = torch.acosh(torch.clamp(c_xyl, min=1 + eps))\n",
    "    return _distance / curv**0.1\n",
    "\n",
    "\n",
    "def elementwise_inner(x: Tensor, y: Tensor, curv: float | Tensor = 1.0):\n",
    "    x_time = torch.sqrt(1 / curv + torch.sum(x**2, dim=-1))\n",
    "    y_time = torch.sqrt(1 / curv + torch.sum(y**2, dim=-1))\n",
    "    xyl = torch.sum(x * y, dim=-1) - x_time * y_time\n",
    "    return xyl\n",
    "\n",
    "\n",
    "def elementwise_dist(\n",
    "    x: Tensor, y: Tensor, curv: float | Tensor = 1.0, eps: float = 1e-8\n",
    ") -> Tensor:\n",
    "    c_xyl = -curv * elementwise_inner(x, y, curv)\n",
    "    _distance = torch.acosh(torch.clamp(c_xyl, min=1 + eps))\n",
    "    return _distance / curv**0.1\n",
    "\n",
    "\n",
    "def exp_map0(x: Tensor, curv: float | Tensor = 1.0, eps: float = 1e-8) -> Tensor:\n",
    "    if torch.isnan(x).any() or torch.isinf(x).any():\n",
    "        print(\"NaN or Inf detected in input to exp_map0\")\n",
    "\n",
    "    x_norm = torch.norm(x, dim=-1, keepdim=True)\n",
    "    rc_xnorm = curv**0.1 * x_norm\n",
    "\n",
    "    sinh_input = torch.clamp(rc_xnorm, min=eps, max=math.asinh(2**15))\n",
    "    rc_xnorm_clamped = torch.clamp(rc_xnorm, min=eps)\n",
    "\n",
    "    _output = torch.sinh(sinh_input) * x / rc_xnorm_clamped\n",
    "\n",
    "    if torch.isnan(_output).any() or torch.isinf(_output).any():\n",
    "        print(\"NaN or Inf detected in output of exp_map0\")\n",
    "\n",
    "    return _output\n",
    "\n",
    "\n",
    "def log_map0(x: Tensor, curv: float | Tensor = 1.0, eps: float = 1e-5) -> Tensor:\n",
    "    rc_x_time = torch.sqrt(1 + curv * torch.sum(x**2, dim=-1, keepdim=True))\n",
    "    _distance0 = torch.acosh(torch.clamp(rc_x_time, min=1 + eps))\n",
    "\n",
    "    rc_xnorm = curv**0.1 * torch.norm(x, dim=-1, keepdim=True)\n",
    "    _output = _distance0 * x / torch.clamp(rc_xnorm, min=eps)\n",
    "    return _output\n",
    "\n",
    "\n",
    "def half_aperture(\n",
    "    x: Tensor, curv: float | Tensor = 1.0, min_radius: float = 0.1, eps: float = 1e-5\n",
    ") -> Tensor:\n",
    "    asin_input = 2 * min_radius / (torch.norm(x, dim=-1) * curv**0.1 + eps)\n",
    "    _half_aperture = torch.asin(torch.clamp(asin_input, min=-1 + eps, max=1 - eps))\n",
    "\n",
    "    return _half_aperture\n",
    "\n",
    "\n",
    "def oxy_angle(x: Tensor, y: Tensor, curv: float | Tensor = 1.0, eps: float = 1e-5):\n",
    "    # Calculate time components of inputs (multiplied with `sqrt(curv)`):\n",
    "    x_time = torch.sqrt(1 / curv + torch.sum(x**2, dim=-1))\n",
    "    y_time = torch.sqrt(1 / curv + torch.sum(y**2, dim=-1))\n",
    "\n",
    "    # Calculate lorentzian inner product multiplied with curvature. We do not use\n",
    "    # the `pairwise_inner` implementation to save some operations (since we only\n",
    "    # need the diagonal elements).\n",
    "    c_xyl = curv * (torch.sum(x * y, dim=-1) - x_time * y_time)\n",
    "\n",
    "    # Make the numerator and denominator for input to arc-cosh, shape: (B, )\n",
    "    acos_numer = y_time + c_xyl * x_time\n",
    "    acos_denom = torch.sqrt(torch.clamp(c_xyl**2 - 1, min=eps))\n",
    "\n",
    "    acos_input = acos_numer / (torch.norm(x, dim=-1) * acos_denom + eps)\n",
    "    _angle = torch.acos(torch.clamp(acos_input, min=-1 + eps, max=1 - eps))\n",
    "\n",
    "    return _angle\n",
    "\n",
    "\n",
    "def hyperbolic_distance(\n",
    "    x: Tensor, y: Tensor, curv: float | Tensor = 1.0, eps: float = 1e-8\n",
    ") -> Tensor:\n",
    "    inner_prod = -x[0] * y[0] + torch.dot(x[1:], y[1:])\n",
    "    val = torch.clamp(-inner_prod, min=1.0 + eps)\n",
    "    dist = torch.sqrt(torch.tensor(curv)) * torch.acosh(val)\n",
    "    return dist\n",
    "\n",
    "\n",
    "# def batch_hyperbolic_distance(\n",
    "#     x: Tensor, y: Tensor, curv: float | Tensor = 1.0, eps: float = 1e-8\n",
    "# ) -> Tensor:\n",
    "#     if x.shape[0] != y.shape[0]:\n",
    "#         raise ValueError(\"Input tensors must have the same batch size.\")\n",
    "#     distances = []\n",
    "#     for i in range(x.shape[0]):\n",
    "#         distances.append(hyperbolic_distance(x[i], y[i], curv, eps))\n",
    "\n",
    "#     return torch.stack(distances)\n",
    "\n",
    "\n",
    "def lorentz_inner_product(x, y):\n",
    "    # x: (..., d+1), y: (..., d+1) or (1, d+1)\n",
    "    return -x[..., 0] * y[..., 0] + torch.sum(x[..., 1:] * y[..., 1:], dim=-1)\n",
    "\n",
    "\n",
    "def batch_hyperbolic_distance(x, y, curv=1.0, eps=1e-5, max_acosh=1e6):\n",
    "    ip = lorentz_inner_product(x, y)\n",
    "    # Clamp both lower and upper bounds\n",
    "    val = torch.clamp(-ip, min=1.0 + eps, max=max_acosh)\n",
    "    dist = torch.sqrt(torch.tensor(curv, device=x.device, dtype=x.dtype)) * torch.acosh(\n",
    "        val\n",
    "    )\n",
    "    return dist\n",
    "\n",
    "\n",
    "def is_lorentz_point(x, curv=1.0, tol=1e-4):\n",
    "    # Returns True if x is (almost) on the Lorentz hyperboloid\n",
    "    norm = -x[..., 0] ** 2 + torch.sum(x[..., 1:] ** 2, dim=-1)\n",
    "    return (torch.abs(norm - 1.0 / curv) < tol).all()\n",
    "\n",
    "\n",
    "def project_to_lorentz(x, curv=1.0):\n",
    "    space = x[..., 1:]\n",
    "    t = torch.sqrt(1.0 / curv + torch.sum(space**2, dim=-1, keepdim=True))\n",
    "    return torch.cat([t, space], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5def759b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of benign points: torch.Size([158700, 768])\n"
     ]
    }
   ],
   "source": [
    "# load the hyperbolic embeddings from the file\n",
    "hyperbolic_path = \"/mnt/ssd1/mary/Diffusion-Models-Embedding-Space-Defense/EMBEDDINGS/hyperbolic_safe_clip/visu/03f7a6e1816195a039adf08998aa1691_all_embeddings.pt\"\n",
    "hyperbolic_points = torch.load(hyperbolic_path)\n",
    "\n",
    "\n",
    "# get only the points whose class is 'benign'\n",
    "bening_point = []\n",
    "for point in hyperbolic_points:\n",
    "    if point[1] == \"benign\":\n",
    "        bening_point.append(point[0])\n",
    "\n",
    "\n",
    "benign_points = torch.stack(bening_point)\n",
    "print(f\"Number of benign points: {benign_points.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b6e5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoopt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "\n",
    "class LorentzHyperbolicSVDD:\n",
    "    def __init__(\n",
    "        self,\n",
    "        curvature=1.0,\n",
    "        radius_init=1.0,\n",
    "        center_lr=0.02,\n",
    "        radius_lr=0.01,\n",
    "        nu=0.1,\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        self.curvature = curvature\n",
    "        self.radius = radius_init\n",
    "        self.center_lr = center_lr\n",
    "        self.radius_lr = radius_lr\n",
    "        self.device = device\n",
    "        self.nu = nu\n",
    "\n",
    "    def loss_SVDD(self, x, center, radius):\n",
    "        center_batch = center.unsqueeze(0).expand(x.shape[0], -1)\n",
    "        distances_sq = (\n",
    "            batch_hyperbolic_distance(x, center_batch, curv=self.curvature) ** 2\n",
    "        )\n",
    "        penalty = torch.relu(distances_sq - radius**2)\n",
    "        loss = radius**2 + torch.mean(penalty) / self.nu\n",
    "        return loss\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        x,\n",
    "        epochs: int = 100,\n",
    "        batch_size: int = 32,\n",
    "        center_lr: float = 0.02,\n",
    "        radius_lr: float = 0.01,\n",
    "    ):\n",
    "        # Prepare data with time component (in minibatches)\n",
    "        mean_center = torch.mean(x, dim=0)\n",
    "        print(f\"Mean center before adding time component: {mean_center.shape}\")\n",
    "        x = torch.cat(\n",
    "            [torch.sqrt(1 / self.curvature + torch.sum(x**2, dim=-1, keepdim=True)), x],\n",
    "            dim=-1,\n",
    "        )\n",
    "        x = x.to(self.device)\n",
    "        print(\"data after adding time component:\", x.shape)\n",
    "        mean_center = torch.cat(\n",
    "            [\n",
    "                torch.sqrt(\n",
    "                    1 / self.curvature + torch.sum(mean_center**2, dim=-1, keepdim=True)\n",
    "                ),\n",
    "                mean_center,\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        dataloader = DataLoader(TensorDataset(x), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.center_param = geoopt.ManifoldParameter(\n",
    "            mean_center.clone().detach().to(self.device),\n",
    "            manifold=geoopt.Lorentz(k=self.curvature),\n",
    "        )\n",
    "\n",
    "        radius_init = torch.tensor(self.radius, device=self.device)\n",
    "        self.radius_param = torch.nn.Parameter(\n",
    "            radius_init.clone().detach().to(self.device)\n",
    "        )\n",
    "\n",
    "        center_optimizer = geoopt.optim.RiemannianSGD(\n",
    "            params=[self.center_param], lr=center_lr\n",
    "        )\n",
    "        radius_optimizer = torch.optim.SGD(\n",
    "            [{\"params\": self.radius_param, \"lr\": radius_lr}]\n",
    "        )\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            total_inside = 0\n",
    "            total_seen = 0\n",
    "            for batch in dataloader:\n",
    "                batch_x = batch[0]\n",
    "                center_optimizer.zero_grad()\n",
    "                radius_optimizer.zero_grad()\n",
    "                loss = self.loss_SVDD(batch_x, self.center_param, self.radius_param)\n",
    "                loss.backward()\n",
    "                center_optimizer.step()\n",
    "                radius_optimizer.step()\n",
    "                epoch_loss += loss.item() * batch_x.size(\n",
    "                    0\n",
    "                )  # accumulate (not average) for the epoch\n",
    "\n",
    "                # Minibatch stats\n",
    "                center_batch = self.center_param.unsqueeze(0).expand(\n",
    "                    batch_x.shape[0], -1\n",
    "                )\n",
    "                distances = batch_hyperbolic_distance(\n",
    "                    batch_x, center_batch, curv=self.curvature\n",
    "                )\n",
    "                inside_count = torch.sum(distances <= self.radius_param).item()\n",
    "                total_inside += inside_count\n",
    "                total_seen += batch_x.size(0)\n",
    "\n",
    "            avg_loss = epoch_loss / total_seen\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.4f}, Points inside radius (minibatch stats): {total_inside}/{total_seen}, center norm: {self.center_param.norm().item():.4f}, radius: {self.radius_param.item():.4f}\"\n",
    "            )\n",
    "\n",
    "    def fit_alternatively(\n",
    "        self,\n",
    "        x,\n",
    "        epochs: int = 100,\n",
    "        batch_size: int = 1024,\n",
    "        epoch_center: int = 10,\n",
    "        epoch_radius: int = 5,\n",
    "        center_lr: float = 0.02,\n",
    "        radius_lr: float = 0.01,\n",
    "    ):\n",
    "        # Compute mean center before time component\n",
    "        mean_center = torch.mean(x, dim=0)\n",
    "        print(f\"Mean center before adding time component: {mean_center.shape}\")\n",
    "        # Add time component to dataset and mean center\n",
    "        x = torch.cat(\n",
    "            [torch.sqrt(1 / self.curvature + torch.sum(x**2, dim=-1, keepdim=True)), x],\n",
    "            dim=-1,\n",
    "        )\n",
    "        x = x.to(self.device)\n",
    "        print(\"data after adding time component:\", x.shape)\n",
    "        mean_center = torch.cat(\n",
    "            [\n",
    "                torch.sqrt(\n",
    "                    1 / self.curvature + torch.sum(mean_center**2, dim=-1, keepdim=True)\n",
    "                ),\n",
    "                mean_center,\n",
    "            ],\n",
    "            dim=-1,\n",
    "        )\n",
    "\n",
    "        dataloader = DataLoader(TensorDataset(x), batch_size=batch_size, shuffle=True)\n",
    "        # Use mean center as initialization\n",
    "        self.center_param = geoopt.ManifoldParameter(\n",
    "            mean_center.clone().detach().to(self.device),\n",
    "            manifold=geoopt.Lorentz(k=self.curvature),\n",
    "        )\n",
    "        radius_init = torch.tensor(self.radius, device=self.device)\n",
    "        self.radius_param = torch.nn.Parameter(\n",
    "            radius_init.clone().detach().to(self.device)\n",
    "        )\n",
    "\n",
    "        center_optimizer = geoopt.optim.RiemannianSGD(\n",
    "            params=[self.center_param], lr=center_lr\n",
    "        )\n",
    "        radius_optimizer = torch.optim.SGD(\n",
    "            [{\"params\": self.radius_param, \"lr\": radius_lr}]\n",
    "        )\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            total_inside = 0\n",
    "            total_seen = 0\n",
    "            if epoch % (epoch_center + epoch_radius) < epoch_center:\n",
    "                # Optimize center only\n",
    "                for batch in dataloader:\n",
    "                    batch_x = batch[0]\n",
    "                    center_optimizer.zero_grad()\n",
    "                    loss = self.loss_SVDD(batch_x, self.center_param, self.radius_param)\n",
    "                    loss.backward()\n",
    "                    center_optimizer.step()\n",
    "                    epoch_loss += loss.item() * batch_x.size(0)\n",
    "                    # Minibatch stats\n",
    "                    center_batch = self.center_param.unsqueeze(0).expand(\n",
    "                        batch_x.shape[0], -1\n",
    "                    )\n",
    "                    distances = batch_hyperbolic_distance(\n",
    "                        batch_x, center_batch, curv=self.curvature\n",
    "                    )\n",
    "                    inside_count = torch.sum(distances <= self.radius_param).item()\n",
    "                    total_inside += inside_count\n",
    "                    total_seen += batch_x.size(0)\n",
    "            else:\n",
    "                # Optimize radius only\n",
    "                for batch in dataloader:\n",
    "                    batch_x = batch[0]\n",
    "                    radius_optimizer.zero_grad()\n",
    "                    loss = self.loss_SVDD(batch_x, self.center_param, self.radius_param)\n",
    "                    loss.backward()\n",
    "                    radius_optimizer.step()\n",
    "                    epoch_loss += loss.item() * batch_x.size(0)\n",
    "                    # Minibatch stats\n",
    "                    center_batch = self.center_param.unsqueeze(0).expand(\n",
    "                        batch_x.shape[0], -1\n",
    "                    )\n",
    "                    distances = batch_hyperbolic_distance(\n",
    "                        batch_x, center_batch, curv=self.curvature\n",
    "                    )\n",
    "                    inside_count = torch.sum(distances <= self.radius_param).item()\n",
    "                    total_inside += inside_count\n",
    "                    total_seen += batch_x.size(0)\n",
    "\n",
    "            avg_loss = epoch_loss / total_seen\n",
    "            # Optionally print gradient norms if you want\n",
    "            center_grad_norm = (\n",
    "                self.center_param.grad.norm().item()\n",
    "                if self.center_param.grad is not None\n",
    "                else 0.0\n",
    "            )\n",
    "            radius_grad_norm = (\n",
    "                self.radius_param.grad.norm().item()\n",
    "                if self.radius_param.grad is not None\n",
    "                else 0.0\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch [{epoch+1}/{epochs}], Avg Loss: {avg_loss:.4f}, center: {self.center_param.norm().item():.4f}, radius: {self.radius_param.item():.4f}, inside: {total_inside}/{total_seen}, center_grad_norm: {center_grad_norm:.4f}, radius_grad_norm: {radius_grad_norm:.4f}\"\n",
    "            )\n",
    "\n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            distances = batch_hyperbolic_distance(\n",
    "                x, self.center_param, curv=self.curvature\n",
    "            )\n",
    "            predictions = (distances <= self.radius_param).int()\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "899a36fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_svdd_fit(hyper_points, nu, curvature=1.0, epochs=500):\n",
    "    num_tot = hyper_points.shape[0]\n",
    "    model = LorentzHyperbolicSVDD(\n",
    "        curvature=curvature, center_lr=0.1, radius_lr=0.2, nu=nu\n",
    "    )\n",
    "\n",
    "    print(\"Before fit:\")\n",
    "\n",
    "    model.fit(hyper_points, epochs=epochs)\n",
    "\n",
    "    print(\"After fit:\")\n",
    "    print(\"Center:\", model.center_param)\n",
    "    print(\"Radius:\", model.radius_param.item())\n",
    "\n",
    "    # add the time component to the hyperbolic points\n",
    "    hyper_points = torch.cat(\n",
    "        [\n",
    "            torch.sqrt(\n",
    "                1 / model.curvature + torch.sum(hyper_points**2, dim=-1, keepdim=True)\n",
    "            ),\n",
    "            hyper_points,\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "    center_batch = model.center_param.expand(hyper_points.shape[0], -1)\n",
    "\n",
    "    dists = batch_hyperbolic_distance(hyper_points, center_batch, curv=model.curvature)\n",
    "    print(\"Distances to center:\", dists)\n",
    "    print(\"Max distance:\", dists.max().item())\n",
    "    print(\"Radius:\", model.radius_param.item())\n",
    "    # assert (dists <= model.radius_param.item() + 1e-2).all(), \"Not all points inside radius after fit\"\n",
    "    inner_points = (dists <= model.radius_param.item()).float()\n",
    "    count_inner = inner_points.sum().item()\n",
    "    print(f\"Number of points inside radius: {count_inner}/{num_tot}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test_svdd_fit_alternatively(hyper_points, nu, curvature=1.0, epochs=500):\n",
    "    num_tot = hyper_points.shape[0]\n",
    "    model = LorentzHyperbolicSVDD(\n",
    "        curvature=curvature, center_lr=0.1, radius_lr=0.2, nu=nu\n",
    "    )\n",
    "\n",
    "    print(\"Before fit:\")\n",
    "    model.fit_alternatively(hyper_points, epochs=epochs)\n",
    "\n",
    "    print(\"After fit:\")\n",
    "    print(\"Center:\", model.center_param)\n",
    "    print(\"Radius:\", model.radius_param.item())\n",
    "\n",
    "    # add the time component to the hyperbolic points\n",
    "    hyper_points = torch.cat(\n",
    "        [\n",
    "            torch.sqrt(\n",
    "                1 / model.curvature + torch.sum(hyper_points**2, dim=-1, keepdim=True)\n",
    "            ),\n",
    "            hyper_points,\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "    center_batch = model.center_param.expand(hyper_points.shape[0], -1)\n",
    "\n",
    "    dists = batch_hyperbolic_distance(hyper_points, center_batch, curv=model.curvature)\n",
    "    print(\"Distances to center:\", dists)\n",
    "    print(\"Max distance:\", dists.max().item())\n",
    "    print(\"Radius:\", model.radius_param.item())\n",
    "    # assert (dists <= model.radius_param.item() + 1e-2).all(), \"Not all points inside radius after fit\"\n",
    "    inner_points = (dists <= model.radius_param.item()).float()\n",
    "    count_inner = inner_points.sum().item()\n",
    "    print(f\"Number of points inside radius: {count_inner}/{num_tot}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e4868b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malicious points: torch.Size([158700, 768])\n"
     ]
    }
   ],
   "source": [
    "# get only the points whose class is 'malicious'\n",
    "malicious_points = []\n",
    "for point in hyperbolic_points:\n",
    "    if point[1] == \"malicious\":\n",
    "        malicious_points.append(point[0])\n",
    "\n",
    "\n",
    "malicious_points = torch.stack(malicious_points)\n",
    "print(f\"Number of malicious points: {malicious_points.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6816c553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the time component to the malicious points\n",
    "curvature = 2.3026\n",
    "malicious_points = torch.cat(\n",
    "    [\n",
    "        torch.sqrt(\n",
    "            1 / curvature + torch.sum(malicious_points**2, dim=-1, keepdim=True)\n",
    "        ),\n",
    "        malicious_points,\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3130ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious points after adding time component: torch.Size([158700, 769])\n"
     ]
    }
   ],
   "source": [
    "print(\"Malicious points after adding time component:\", malicious_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a02d0e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fit:\n",
      "Mean center before adding time component: torch.Size([768])\n",
      "data after adding time component: torch.Size([158700, 769])\n",
      "Epoch [1/10], Avg Loss: 0.4336, Points inside radius (minibatch stats): 153587/158700, center norm: 1.9265, radius: 0.6497\n",
      "Epoch [2/10], Avg Loss: 0.4317, Points inside radius (minibatch stats): 153622/158700, center norm: 1.9579, radius: 0.6252\n",
      "Epoch [3/10], Avg Loss: 0.4317, Points inside radius (minibatch stats): 153657/158700, center norm: 1.9240, radius: 0.6578\n",
      "Epoch [4/10], Avg Loss: 0.4315, Points inside radius (minibatch stats): 153649/158700, center norm: 1.9548, radius: 0.6342\n",
      "Epoch [5/10], Avg Loss: 0.4316, Points inside radius (minibatch stats): 153682/158700, center norm: 1.9402, radius: 0.6451\n",
      "Epoch [6/10], Avg Loss: 0.4314, Points inside radius (minibatch stats): 153614/158700, center norm: 1.9353, radius: 0.6230\n",
      "Epoch [7/10], Avg Loss: 0.4318, Points inside radius (minibatch stats): 153671/158700, center norm: 1.9349, radius: 0.6374\n",
      "Epoch [8/10], Avg Loss: 0.4316, Points inside radius (minibatch stats): 153616/158700, center norm: 1.9361, radius: 0.6485\n",
      "Epoch [9/10], Avg Loss: 0.4319, Points inside radius (minibatch stats): 153517/158700, center norm: 1.9408, radius: 0.6155\n",
      "Epoch [10/10], Avg Loss: 0.4316, Points inside radius (minibatch stats): 153782/158700, center norm: 1.9263, radius: 0.6334\n",
      "After fit:\n",
      "Center: Parameter on Lorentz manifold containing:\n",
      "Parameter(ManifoldParameter([ 1.7339e+00, -1.9259e-02, -5.4602e-03,  2.0130e-02,\n",
      "                    4.1099e-02,  1.7196e-02,  8.7085e-03,  1.7961e-02,\n",
      "                   -1.9356e-02, -1.2173e-02, -3.0262e-03,  2.6440e-02,\n",
      "                   -2.3579e-02, -8.8601e-03, -8.5992e-03,  1.9886e-02,\n",
      "                   -3.4769e-02,  3.0003e-02, -4.4249e-04,  6.9190e-03,\n",
      "                   -3.3496e-02, -1.7166e-03, -1.4804e-02,  1.5178e-04,\n",
      "                    3.8951e-02, -5.3298e-02,  1.1252e-02,  3.3476e-03,\n",
      "                    1.9045e-02,  3.7869e-02,  3.3028e-03, -2.4858e-03,\n",
      "                    1.1537e-02, -6.9418e-04, -7.9786e-03,  6.7064e-04,\n",
      "                   -6.4516e-03, -1.5931e-02,  2.4208e-03,  7.2522e-03,\n",
      "                   -1.1870e-02,  4.0502e-02, -2.9685e-02,  2.0270e-02,\n",
      "                   -5.9708e-02,  2.7956e-02, -2.2207e-02,  4.0954e-02,\n",
      "                    3.0642e-03, -1.5331e-02, -8.1614e-02, -1.5306e-02,\n",
      "                    3.6844e-03,  1.1043e-02,  1.7192e-02,  1.8336e-02,\n",
      "                    5.6479e-03,  2.6250e-03,  1.8003e-02,  4.4287e-03,\n",
      "                   -8.0686e-03,  2.1261e-02,  3.5173e-02, -7.5641e-03,\n",
      "                    1.9269e-02,  1.8740e-03,  1.9073e-02,  1.0984e-02,\n",
      "                    8.3689e-03, -6.1694e-04, -2.1984e-02,  6.4636e-03,\n",
      "                    3.5477e-02,  7.6365e-03, -9.1285e-03,  6.3320e-03,\n",
      "                    1.1659e-03,  5.2289e-03,  2.1419e-03,  7.3601e-03,\n",
      "                   -1.2533e-02,  4.6158e-02, -1.4537e-02,  2.1258e-02,\n",
      "                   -1.1421e-02,  2.0284e-02,  6.8829e-03, -3.6472e-02,\n",
      "                   -1.3391e-04,  2.1607e-02,  3.8727e-02, -2.0087e-03,\n",
      "                   -5.2275e-03,  1.0679e-03, -3.9107e-02,  4.3578e-03,\n",
      "                   -6.3815e-03,  3.3284e-02, -3.5709e-02,  2.6351e-02,\n",
      "                   -2.3428e-02, -3.9536e-02,  2.1175e-02, -1.4728e-02,\n",
      "                    3.8866e-03, -3.5471e-02,  1.0227e-02, -2.2674e-02,\n",
      "                   -2.7726e-02, -3.0421e-03, -2.4414e-02,  3.8874e-02,\n",
      "                    5.5101e-03, -8.2119e-03, -5.2082e-03, -1.5275e-02,\n",
      "                   -2.2106e-02, -1.0661e-02, -1.7311e-03, -1.5034e-02,\n",
      "                   -4.2394e-03,  3.9862e-02, -1.0514e-02,  8.9562e-04,\n",
      "                    1.3121e-02, -3.6231e-03, -3.1272e-02,  1.7636e-02,\n",
      "                    1.7004e-02,  1.9930e-02, -1.6327e-02,  2.3139e-03,\n",
      "                    2.7025e-02, -1.6010e-03, -1.5773e-02,  2.0291e-02,\n",
      "                   -1.3015e-02, -1.9387e-02,  8.9410e-03,  8.4131e-03,\n",
      "                   -1.8210e-03,  2.2522e-02, -2.5931e-02,  2.3970e-02,\n",
      "                   -4.1490e-02, -1.0550e-02,  1.7331e-02,  4.7150e-02,\n",
      "                   -5.3576e-02, -3.3198e-02,  2.9453e-02,  7.8658e-03,\n",
      "                    2.7199e-02,  4.5581e-02,  2.5795e-02,  3.1518e-02,\n",
      "                    3.4189e-02,  2.0171e-02,  6.0362e-04,  1.9196e-02,\n",
      "                   -2.0608e-02,  1.9667e-02,  2.2951e-03,  1.8498e-02,\n",
      "                    5.0050e-02,  3.3455e-02,  8.5578e-03, -3.4670e-02,\n",
      "                   -4.5103e-02, -3.6703e-03,  2.4064e-03,  1.5428e-03,\n",
      "                   -2.7938e-02,  4.2068e-02,  1.4628e-02,  1.3631e-02,\n",
      "                    3.3843e-02, -2.0920e-02, -4.5784e-02, -2.1210e-02,\n",
      "                   -2.6952e-02,  1.4279e-01, -1.7311e-03,  1.4585e-02,\n",
      "                   -1.2016e-02,  2.3320e-02, -3.4405e-02, -4.1089e-02,\n",
      "                   -1.5103e-02,  3.7524e-02, -9.1408e-03, -1.5815e-02,\n",
      "                   -1.5751e-02,  6.3629e-03,  4.2157e-03, -1.4494e-02,\n",
      "                   -1.1374e-01,  2.1795e-02,  5.5511e-02,  5.8278e-03,\n",
      "                   -2.3112e-02,  2.9611e-03,  1.6005e-01, -2.4589e-02,\n",
      "                    6.4924e-03,  8.2087e-03, -1.0663e-02, -1.9659e-02,\n",
      "                   -2.6035e-02,  2.0341e-02, -1.5501e-02, -1.0194e-02,\n",
      "                    4.5388e-02, -2.9565e-03,  1.9408e-03,  5.0861e-03,\n",
      "                    1.3746e-02,  3.2407e-02, -3.4506e-03,  3.5212e-02,\n",
      "                    2.0440e-02, -3.5463e-02,  4.0015e-02, -3.7369e-03,\n",
      "                    6.2075e-02,  4.5664e-03, -3.7524e-02,  8.3024e-03,\n",
      "                    3.2259e-02,  2.4922e-02, -1.6605e-02,  1.7875e-02,\n",
      "                   -1.3521e-02,  4.0758e-02, -2.5346e-02,  1.9934e-03,\n",
      "                   -8.5523e-03, -6.0104e-03,  2.0121e-02,  6.1326e-02,\n",
      "                    2.6199e-04,  1.3377e-02,  1.6917e-02,  4.1838e-02,\n",
      "                    5.8191e-03,  9.7082e-03,  3.5402e-02, -5.3812e-02,\n",
      "                    3.6340e-02, -1.2229e-02,  3.8017e-02, -1.7413e-03,\n",
      "                   -8.2526e-03, -7.1331e-03, -4.3470e-02,  3.1547e-02,\n",
      "                   -1.6755e-02, -3.0202e-02, -4.6630e-02,  3.9293e-02,\n",
      "                   -6.4335e-03, -2.1886e-02,  8.3349e-03, -1.9288e-02,\n",
      "                    2.6772e-02,  3.2940e-02,  5.5983e-02,  1.2731e-02,\n",
      "                   -3.5380e-02, -4.6950e-03, -2.8741e-02,  1.6197e-02,\n",
      "                   -3.2607e-04,  2.9743e-03, -2.3284e-02, -5.2329e-03,\n",
      "                    9.5490e-03, -2.0754e-02, -9.1841e-03, -1.5392e-02,\n",
      "                   -2.6635e-02,  3.1372e-03, -1.3911e-01,  1.6007e-02,\n",
      "                   -5.3123e-02,  4.2404e-02, -3.2627e-02,  1.5785e-02,\n",
      "                    3.1958e-02, -1.1246e-01,  9.4681e-04, -4.9580e-03,\n",
      "                    5.9530e-03, -7.3764e-02, -1.6448e-02, -1.7781e-02,\n",
      "                   -3.4775e-03, -7.1689e-02, -1.0207e-02, -1.8262e-02,\n",
      "                    1.2023e-02, -3.5661e-02,  2.0208e-02, -3.3544e-02,\n",
      "                   -1.1520e-02,  1.0875e-02, -1.0786e-02,  5.1306e-03,\n",
      "                   -1.3793e-02,  1.7533e-02,  3.2169e-02, -1.3177e-02,\n",
      "                    2.2817e-02, -3.6526e-03, -3.5110e-02,  1.6325e-02,\n",
      "                   -4.5429e-03, -8.1184e-02, -5.8356e-02,  1.1863e-02,\n",
      "                   -8.9867e-03, -2.2401e-02, -4.1178e-02,  2.8136e-02,\n",
      "                   -1.1812e-03, -1.8825e-02, -1.9639e-02, -6.5914e-02,\n",
      "                   -1.3180e-03, -3.8120e-02,  4.3834e-02, -7.5047e-03,\n",
      "                    2.6395e-02, -2.5540e-02, -3.6842e-02,  1.2077e-02,\n",
      "                    1.4777e-02, -8.8062e-03,  1.1186e-02, -1.0023e-02,\n",
      "                    1.0048e-02,  3.9749e-03, -3.7699e-02, -1.1311e-02,\n",
      "                    2.8998e-02, -2.0405e-02, -1.6540e-02,  1.4064e-02,\n",
      "                    3.2366e-02, -3.4698e-02,  1.9055e-02,  7.9158e-02,\n",
      "                    2.4337e-02, -3.7176e-02,  1.9056e-02, -1.2376e-02,\n",
      "                    4.8749e-04,  4.9933e-02, -1.0427e-02,  8.7948e-03,\n",
      "                   -4.3459e-03, -2.9285e-02, -2.1912e-04,  6.6602e-03,\n",
      "                   -1.3817e-01,  1.1667e-02,  2.3866e-02,  7.5479e-02,\n",
      "                   -3.0048e-02,  2.0612e-02,  2.8481e-02, -1.8923e-02,\n",
      "                   -3.7314e-02, -7.9568e-03,  9.3465e-03, -1.1678e-02,\n",
      "                   -5.2506e-03, -5.7230e-03, -6.7763e-04,  2.5380e-02,\n",
      "                    2.2477e-02,  1.1384e-02, -2.7075e-02, -2.3501e-03,\n",
      "                    2.2629e-02,  3.8978e-03,  2.1414e-02, -2.2735e-02,\n",
      "                    2.2859e-02, -2.9727e-02,  3.2852e-02,  1.7095e-02,\n",
      "                    6.1434e-03,  7.7704e-03,  3.9857e-02,  1.4101e-02,\n",
      "                    1.8955e-02,  3.0112e-02,  8.8646e-02,  1.9786e-02,\n",
      "                    6.8409e-03,  2.4758e-02,  2.4277e-02,  3.6213e-02,\n",
      "                   -1.9373e-04,  1.6208e-02,  1.9760e-02, -8.6189e-03,\n",
      "                   -3.3694e-02,  6.1205e-03,  3.8135e-02, -4.4648e-02,\n",
      "                   -2.7843e-02,  2.2854e-02, -6.5285e-02,  5.0843e-02,\n",
      "                    5.2154e-02,  8.5420e-03,  4.4528e-02, -2.4777e-02,\n",
      "                   -1.0192e-02,  7.2025e-03, -1.8130e-02, -5.3187e-02,\n",
      "                    3.0006e-02, -1.9162e-04, -8.2930e-03, -4.7293e-02,\n",
      "                    3.9979e-02, -2.0434e-02,  2.2852e-02, -1.4528e-02,\n",
      "                   -1.8898e-02, -7.5913e-03, -5.1249e-03,  4.9461e-02,\n",
      "                    3.2292e-02, -2.7642e-02, -2.0534e-03,  2.4176e-02,\n",
      "                   -2.0505e-02,  6.1854e-02,  7.4044e-03, -8.3093e-03,\n",
      "                    4.3694e-03,  3.6998e-02,  1.1762e-02, -7.1440e-03,\n",
      "                    2.5928e-02,  3.5699e-02, -1.9273e-02, -4.1886e-02,\n",
      "                   -6.1492e-02,  4.3091e-02, -8.2744e-03,  2.3029e-02,\n",
      "                    2.1409e-02,  5.2864e-02,  3.1452e-03, -1.3251e-02,\n",
      "                   -3.0800e-03,  1.8067e-02, -3.2076e-03,  1.7328e-02,\n",
      "                    4.7200e-02, -8.1781e-02,  1.3437e-02, -2.1698e-03,\n",
      "                    1.4779e-01,  5.0030e-02,  3.2313e-02,  1.0625e-02,\n",
      "                   -1.9118e-02,  2.6788e-02,  2.8175e-02, -1.3449e-02,\n",
      "                   -9.4463e-03, -5.0222e-03,  3.5623e-02, -7.5790e-03,\n",
      "                   -9.0193e-03, -9.5694e-04,  1.0858e-03,  6.7382e-03,\n",
      "                    1.3330e-03, -4.6675e-02, -3.4236e-02,  4.8106e-02,\n",
      "                   -1.7554e-02, -6.9011e-03,  4.8844e-02, -4.3536e-03,\n",
      "                    4.9191e-02, -3.7774e-02,  2.6212e-02, -1.6459e-02,\n",
      "                   -5.1940e-02, -2.8793e-02, -3.7178e-02, -3.6883e-04,\n",
      "                    8.2753e-03,  1.9837e-02, -4.9174e-02, -2.0285e-02,\n",
      "                    1.3819e-02, -5.4963e-02, -7.1554e-03, -7.4760e-03,\n",
      "                    1.6979e-03, -7.7171e-02, -2.6249e-04,  2.6441e-02,\n",
      "                    3.2197e-02,  2.8250e-02,  7.5203e-03,  2.4474e-03,\n",
      "                    2.9324e-02,  2.1412e-02, -4.2977e-02, -1.4275e-02,\n",
      "                   -3.0950e-02,  2.8978e-02, -1.4080e-02, -2.3631e-02,\n",
      "                   -3.9295e-02,  5.7088e-03,  3.4437e-02,  2.9670e-05,\n",
      "                   -4.1876e-02, -5.6500e-02,  5.6700e-04, -2.8054e-02,\n",
      "                   -1.3493e-02,  3.5015e-02,  1.9922e-04, -2.3949e-03,\n",
      "                   -1.8005e-02, -3.3623e-03, -3.7921e-03, -3.2634e-02,\n",
      "                   -3.8260e-02, -4.3476e-04, -9.3387e-04,  2.9188e-02,\n",
      "                   -3.1182e-02,  1.0473e-02,  9.3658e-03, -9.6139e-03,\n",
      "                    1.0501e-02,  1.8640e-02,  1.2829e-02, -1.0794e-02,\n",
      "                    7.0399e-02, -8.2207e-03, -7.0372e-03, -2.5194e-02,\n",
      "                   -3.2829e-02, -6.7340e-02, -2.3091e-02,  3.3424e-02,\n",
      "                   -3.1954e-02,  6.8735e-02,  1.0893e-02, -2.6998e-02,\n",
      "                    2.2188e-02, -8.9059e-02, -1.5352e-02,  4.7284e-02,\n",
      "                    3.1815e-02, -2.7084e-03,  3.1283e-02,  7.2079e-03,\n",
      "                   -1.7458e-02, -8.4929e-04, -2.5874e-03, -5.4124e-02,\n",
      "                   -3.1418e-02,  1.1213e-02,  1.3384e-02,  8.8109e-03,\n",
      "                    1.7928e-02,  2.5502e-02, -3.8920e-03,  1.2074e-02,\n",
      "                   -1.0024e-02, -2.6328e-02,  4.5373e-03,  8.2263e-03,\n",
      "                    2.2876e-02,  6.8594e-02,  2.9807e-03, -1.1570e-02,\n",
      "                   -5.2155e-02, -4.6083e-03, -7.5376e-03, -1.1079e-03,\n",
      "                    9.3821e-03,  3.4376e-03, -4.0811e-02,  1.9374e-02,\n",
      "                   -6.8276e-03, -1.6066e-02,  6.4884e-03,  2.6186e-02,\n",
      "                    3.2721e-02, -1.6492e-02, -1.5830e-01, -1.1948e-02,\n",
      "                    1.3655e-02, -1.6348e-02,  3.3166e-02,  6.1266e-03,\n",
      "                   -1.1791e-02, -2.7565e-02, -2.1156e-02,  6.8919e-03,\n",
      "                   -2.7032e-03, -1.1884e-02, -4.4096e-02,  1.8676e-02,\n",
      "                    8.3155e-03,  1.1423e-02, -4.4046e-02, -1.7781e-02,\n",
      "                    5.3852e-02,  5.4111e-02, -6.3120e-03, -3.1283e-02,\n",
      "                    5.4422e-03,  4.1635e-02, -4.1717e-02,  5.0783e-02,\n",
      "                    3.1647e-02, -1.2043e-02,  3.2923e-03,  1.5678e-02,\n",
      "                   -5.9286e-02,  1.3059e-02, -2.3762e-02,  2.2235e-03,\n",
      "                    2.5014e-02,  2.0886e-02, -5.4625e-03,  4.0254e-03,\n",
      "                   -7.0960e-02,  6.6799e-02, -2.9811e-02, -2.2091e-02,\n",
      "                   -2.3943e-02,  1.5721e-02, -4.4105e-02, -6.1465e-03,\n",
      "                   -2.3691e-02,  4.6619e-03, -3.1455e-02,  2.5043e-02,\n",
      "                    6.5104e-03,  1.9073e-02,  1.1273e-02,  2.2030e-02,\n",
      "                    4.8969e-02, -2.0446e-02, -7.4356e-03,  1.3398e-02,\n",
      "                   -3.0906e-03,  2.0725e-02, -3.4979e-03, -1.2057e-03,\n",
      "                    2.1001e-02, -2.3362e-02,  4.4829e-02, -2.0458e-02,\n",
      "                    2.3676e-02, -9.7840e-03, -1.9752e-02, -5.1330e-03,\n",
      "                   -5.6897e-03,  2.9056e-02, -2.3448e-02, -1.2606e-02,\n",
      "                   -5.8792e-03, -3.9778e-03, -3.4141e-03, -2.4908e-02,\n",
      "                   -1.2679e-02,  2.0118e-02,  5.8158e-03,  8.5692e-03,\n",
      "                    4.4218e-03,  2.1518e-02, -1.8826e-03, -2.0436e-03,\n",
      "                    1.8963e-02,  9.5337e-02, -1.1197e-02, -1.2598e-02,\n",
      "                   -3.0586e-02, -4.6438e-02, -5.7067e-03, -2.1620e-02,\n",
      "                   -4.9829e-02,  2.5765e-02,  1.4940e-02, -1.7063e-02,\n",
      "                    3.0483e-02,  3.7464e-03,  3.4703e-03,  3.7208e-03,\n",
      "                   -2.1225e-02,  3.6250e-02, -1.4585e-02, -2.3805e-02,\n",
      "                    2.0411e-02, -2.8685e-02, -9.6309e-03,  8.5560e-03,\n",
      "                    3.3429e-02,  4.7454e-02, -1.7338e-02, -9.0452e-03,\n",
      "                    2.2630e-02, -1.2007e-02,  1.9080e-03,  1.1506e-02,\n",
      "                   -5.3870e-02, -2.4536e-02, -1.3764e-03,  1.4892e-03,\n",
      "                   -5.2938e-02, -1.9579e-02,  1.1510e-02, -7.8578e-03,\n",
      "                    8.7342e-03, -1.8926e-02, -3.6998e-02, -7.7909e-03,\n",
      "                    3.1976e-02,  1.4998e-02,  4.1916e-02, -1.1536e-02,\n",
      "                    1.5222e-03, -8.0143e-04,  1.2800e-02,  6.4870e-03,\n",
      "                    2.8238e-02, -3.0517e-02, -1.3763e-02, -1.8774e-02,\n",
      "                   -8.3681e-03, -1.9496e-02,  6.5095e-05, -2.3039e-03,\n",
      "                   -3.2183e-02, -3.5976e-02,  1.2511e-02,  1.4659e-02,\n",
      "                   -1.1311e-02,  1.0151e-02, -3.0992e-02, -3.7524e-02,\n",
      "                   -2.5187e-02, -3.3290e-02, -7.4570e-03, -2.5188e-02,\n",
      "                    3.8034e-02,  2.2592e-02, -1.3855e-03, -2.7329e-02,\n",
      "                    2.0172e-02], dtype=torch.float32, requires_grad=True))\n",
      "Radius: 0.6334017307611101\n",
      "Distances to center: tensor([0.5990, 0.5603, 0.5616,  ..., 0.5674, 0.5820, 0.6029],\n",
      "       dtype=torch.float32, grad_fn=<MulBackward0>)\n",
      "Max distance: 0.8006758689880371\n",
      "Radius: 0.6334017307611101\n",
      "Number of points inside radius: 154600.0/158700\n",
      "Malicious predictions: tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# get the model trained on benign points and predict on malicious points\n",
    "\n",
    "curvature = 2.3026\n",
    "epochs = 10\n",
    "\n",
    "benign_model = test_svdd_fit(\n",
    "    hyper_points=benign_points, curvature=curvature, nu=0.05, epochs=epochs\n",
    ")\n",
    "# predict on malicious points\n",
    "malicious_predictions = benign_model.predict(malicious_points)\n",
    "print(f\"Malicious predictions: {malicious_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1febd24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malicious points classified as benign: 5180\n",
      "Accuracy on malicious points: 0.9674\n",
      "Benign predictions: tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int32)\n",
      "Number of benign points classified as benign: 154600\n",
      "Accuracy on benign points: 0.9742\n"
     ]
    }
   ],
   "source": [
    "# print the number of malicious points classified as benign\n",
    "num_malicious_benign = (malicious_predictions == 1).sum().item()\n",
    "print(f\"Number of malicious points classified as benign: {num_malicious_benign}\")\n",
    "# print the accuracy of the model on malicious points\n",
    "accuracy_malicious = (malicious_predictions == 0).sum().item() / malicious_predictions.shape[0]\n",
    "print(f\"Accuracy on malicious points: {accuracy_malicious:.4f}\")\n",
    "# get the model trained on benign points and predict on beign points\n",
    "benign_points_with_time = torch.cat(\n",
    "    [\n",
    "        torch.sqrt(\n",
    "            1 / curvature + torch.sum(benign_points**2, dim=-1, keepdim=True)\n",
    "        ),\n",
    "        benign_points,\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "\n",
    "benign_predictions = benign_model.predict(benign_points_with_time)\n",
    "print(f\"Benign predictions: {benign_predictions}\")\n",
    "# print the number of benign points classified as benign\n",
    "num_benign_benign = (benign_predictions == 1).sum().item()\n",
    "print(f\"Number of benign points classified as benign: {num_benign_benign}\")\n",
    "# print the accuracy of the model on benign points\n",
    "accuracy_benign = (benign_predictions == 1).sum().item() / benign_predictions.shape[0]\n",
    "print(f\"Accuracy on benign points: {accuracy_benign:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf7f7cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before fit:\n",
      "Mean center before adding time component: torch.Size([768])\n",
      "data after adding time component: torch.Size([158700, 769])\n",
      "Epoch [1/50], Avg Loss: 1.0000, center: 1.6050, radius: 1.0000, inside: 158698/158700, center_grad_norm: 0.0000, radius_grad_norm: 309.9219\n",
      "Epoch [2/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 619.8828\n",
      "Epoch [3/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 929.8828\n",
      "Epoch [4/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 1239.8828\n",
      "Epoch [5/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 1549.8828\n",
      "Epoch [6/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 1859.8828\n",
      "Epoch [7/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 2169.8828\n",
      "Epoch [8/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 2479.8828\n",
      "Epoch [9/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 2789.8828\n",
      "Epoch [10/50], Avg Loss: 1.0000, center: 1.6052, radius: 1.0000, inside: 158700/158700, center_grad_norm: 0.0000, radius_grad_norm: 3099.8828\n",
      "Epoch [11/50], Avg Loss: 0.6687, center: 1.6052, radius: 0.7286, inside: 151529/158700, center_grad_norm: 571.0884, radius_grad_norm: 0.0639\n",
      "Epoch [12/50], Avg Loss: 0.6508, center: 1.6052, radius: 0.7314, inside: 150825/158700, center_grad_norm: 1205.4661, radius_grad_norm: 0.1396\n",
      "Epoch [13/50], Avg Loss: 0.6509, center: 1.6052, radius: 0.7322, inside: 150837/158700, center_grad_norm: 1839.4215, radius_grad_norm: 0.0233\n",
      "Epoch [14/50], Avg Loss: 0.6508, center: 1.6052, radius: 0.7294, inside: 150832/158700, center_grad_norm: 2472.3459, radius_grad_norm: 0.2976\n",
      "Epoch [15/50], Avg Loss: 0.6508, center: 1.6052, radius: 0.7295, inside: 150810/158700, center_grad_norm: 3106.0295, radius_grad_norm: 0.1223\n",
      "Epoch [16/50], Avg Loss: 0.5474, center: 1.9017, radius: 0.7295, inside: 157503/158700, center_grad_norm: 0.0000, radius_grad_norm: 190.2460\n",
      "Epoch [17/50], Avg Loss: 0.5327, center: 1.9404, radius: 0.7295, inside: 158473/158700, center_grad_norm: 0.1875, radius_grad_norm: 409.7763\n",
      "Epoch [18/50], Avg Loss: 0.5324, center: 1.9572, radius: 0.7295, inside: 158585/158700, center_grad_norm: 0.0000, radius_grad_norm: 632.5278\n",
      "Epoch [19/50], Avg Loss: 0.5323, center: 1.9687, radius: 0.7295, inside: 158614/158700, center_grad_norm: 0.0000, radius_grad_norm: 856.1056\n",
      "Epoch [20/50], Avg Loss: 0.5323, center: 1.9770, radius: 0.7295, inside: 158632/158700, center_grad_norm: 0.0000, radius_grad_norm: 1080.2533\n",
      "Epoch [21/50], Avg Loss: 0.5322, center: 1.9836, radius: 0.7295, inside: 158645/158700, center_grad_norm: 0.0000, radius_grad_norm: 1304.6860\n",
      "Epoch [22/50], Avg Loss: 0.5322, center: 1.9885, radius: 0.7295, inside: 158655/158700, center_grad_norm: 0.0000, radius_grad_norm: 1529.4891\n",
      "Epoch [23/50], Avg Loss: 0.5322, center: 1.9925, radius: 0.7295, inside: 158662/158700, center_grad_norm: 0.0000, radius_grad_norm: 1754.4632\n",
      "Epoch [24/50], Avg Loss: 0.5322, center: 1.9963, radius: 0.7295, inside: 158663/158700, center_grad_norm: 0.0961, radius_grad_norm: 1979.4653\n",
      "Epoch [25/50], Avg Loss: 0.5322, center: 1.9996, radius: 0.7295, inside: 158667/158700, center_grad_norm: 0.0000, radius_grad_norm: 2204.5533\n",
      "Epoch [26/50], Avg Loss: 0.4427, center: 1.9996, radius: 0.6494, inside: 151069/158700, center_grad_norm: 607.6989, radius_grad_norm: 0.1497\n",
      "Epoch [27/50], Avg Loss: 0.4408, center: 1.9996, radius: 0.6469, inside: 150813/158700, center_grad_norm: 1237.6433, radius_grad_norm: 0.0309\n",
      "Epoch [28/50], Avg Loss: 0.4408, center: 1.9996, radius: 0.6518, inside: 150800/158700, center_grad_norm: 1869.7345, radius_grad_norm: 0.5613\n",
      "Epoch [29/50], Avg Loss: 0.4407, center: 1.9996, radius: 0.6503, inside: 150797/158700, center_grad_norm: 2499.8374, radius_grad_norm: 0.0725\n",
      "Epoch [30/50], Avg Loss: 0.4408, center: 1.9996, radius: 0.6468, inside: 150842/158700, center_grad_norm: 3129.4934, radius_grad_norm: 0.0978\n",
      "Epoch [31/50], Avg Loss: 0.4336, center: 2.0030, radius: 0.6468, inside: 155092/158700, center_grad_norm: 1.4699, radius_grad_norm: 106.2655\n",
      "Epoch [32/50], Avg Loss: 0.4333, center: 2.0023, radius: 0.6468, inside: 155213/158700, center_grad_norm: 2.3408, radius_grad_norm: 216.5653\n",
      "Epoch [33/50], Avg Loss: 0.4333, center: 1.9981, radius: 0.6468, inside: 155187/158700, center_grad_norm: 2.1222, radius_grad_norm: 326.5377\n",
      "Epoch [34/50], Avg Loss: 0.4333, center: 2.0002, radius: 0.6468, inside: 155216/158700, center_grad_norm: 2.3692, radius_grad_norm: 437.0897\n",
      "Epoch [35/50], Avg Loss: 0.4333, center: 2.0006, radius: 0.6468, inside: 155206/158700, center_grad_norm: 1.3568, radius_grad_norm: 547.6730\n",
      "Epoch [36/50], Avg Loss: 0.4333, center: 1.9992, radius: 0.6468, inside: 155191/158700, center_grad_norm: 2.3992, radius_grad_norm: 657.9976\n",
      "Epoch [37/50], Avg Loss: 0.4333, center: 2.0006, radius: 0.6468, inside: 155219/158700, center_grad_norm: 1.5783, radius_grad_norm: 768.9078\n",
      "Epoch [38/50], Avg Loss: 0.4333, center: 1.9993, radius: 0.6468, inside: 155204/158700, center_grad_norm: 2.1779, radius_grad_norm: 879.2587\n",
      "Epoch [39/50], Avg Loss: 0.4333, center: 2.0006, radius: 0.6468, inside: 155211/158700, center_grad_norm: 2.5114, radius_grad_norm: 989.9112\n",
      "Epoch [40/50], Avg Loss: 0.4333, center: 2.0007, radius: 0.6468, inside: 155205/158700, center_grad_norm: 2.3629, radius_grad_norm: 1100.3621\n",
      "Epoch [41/50], Avg Loss: 0.4285, center: 2.0007, radius: 0.6344, inside: 150874/158700, center_grad_norm: 628.4269, radius_grad_norm: 0.0810\n",
      "Epoch [42/50], Avg Loss: 0.4285, center: 2.0007, radius: 0.6386, inside: 150839/158700, center_grad_norm: 1263.3717, radius_grad_norm: 0.5249\n",
      "Epoch [43/50], Avg Loss: 0.4286, center: 2.0007, radius: 0.6340, inside: 150818/158700, center_grad_norm: 1895.6671, radius_grad_norm: 0.0051\n",
      "Epoch [44/50], Avg Loss: 0.4285, center: 2.0007, radius: 0.6382, inside: 150873/158700, center_grad_norm: 2530.6995, radius_grad_norm: 0.0560\n",
      "Epoch [45/50], Avg Loss: 0.4285, center: 2.0007, radius: 0.6369, inside: 150827/158700, center_grad_norm: 3163.9980, radius_grad_norm: 0.3232\n",
      "Epoch [46/50], Avg Loss: 0.4272, center: 1.9784, radius: 0.6369, inside: 153998/158700, center_grad_norm: 1.7196, radius_grad_norm: 77.0938\n",
      "Epoch [47/50], Avg Loss: 0.4271, center: 1.9827, radius: 0.6369, inside: 154125/158700, center_grad_norm: 2.6039, radius_grad_norm: 158.4120\n",
      "Epoch [48/50], Avg Loss: 0.4271, center: 1.9811, radius: 0.6369, inside: 154097/158700, center_grad_norm: 2.4416, radius_grad_norm: 238.9102\n",
      "Epoch [49/50], Avg Loss: 0.4271, center: 1.9822, radius: 0.6369, inside: 154110/158700, center_grad_norm: 2.7672, radius_grad_norm: 319.9040\n",
      "Epoch [50/50], Avg Loss: 0.4271, center: 1.9797, radius: 0.6369, inside: 154076/158700, center_grad_norm: 2.6341, radius_grad_norm: 400.2270\n",
      "After fit:\n",
      "Center: Parameter on Lorentz manifold containing:\n",
      "Parameter(ManifoldParameter([ 1.7638e+00, -1.9004e-02, -7.2527e-03,  2.0031e-02,\n",
      "                    4.5338e-02,  1.5980e-02,  9.3945e-03,  1.5599e-02,\n",
      "                   -2.0230e-02, -1.3908e-02, -4.1480e-03,  2.5311e-02,\n",
      "                   -2.4063e-02, -1.2048e-02, -9.2715e-03,  1.4635e-02,\n",
      "                   -3.5136e-02,  3.2029e-02, -2.4903e-03,  9.2078e-03,\n",
      "                   -3.4126e-02,  4.4368e-04, -1.5326e-02, -1.6157e-03,\n",
      "                    4.3830e-02, -5.6527e-02,  1.2424e-02,  4.3496e-03,\n",
      "                    1.6624e-02,  4.2625e-02,  3.6396e-03, -6.4276e-03,\n",
      "                    1.2926e-02, -1.6707e-03, -7.8294e-03,  4.6126e-03,\n",
      "                   -8.2682e-03, -1.7908e-02, -1.8958e-04,  3.9544e-03,\n",
      "                   -8.6749e-03,  4.1576e-02, -3.4565e-02,  2.5254e-02,\n",
      "                   -6.0323e-02,  2.6202e-02, -2.2524e-02,  4.2422e-02,\n",
      "                    1.0713e-03, -1.5406e-02, -8.9618e-02, -1.6135e-02,\n",
      "                    2.6733e-03,  1.1540e-02,  1.6443e-02,  2.2732e-02,\n",
      "                    9.7403e-03,  5.4170e-03,  1.9602e-02,  3.6418e-03,\n",
      "                   -6.4764e-03,  1.7482e-02,  3.5040e-02, -1.0165e-02,\n",
      "                    2.0612e-02,  7.6116e-03,  1.9151e-02,  7.7284e-03,\n",
      "                    9.1207e-03, -1.1080e-03, -2.5513e-02,  1.0883e-02,\n",
      "                    4.0508e-02,  5.3743e-03, -1.0749e-02,  9.7874e-03,\n",
      "                   -1.2804e-03,  7.1941e-03, -4.6292e-04,  1.1161e-02,\n",
      "                   -1.7831e-02,  4.8628e-02, -1.6439e-02,  2.1645e-02,\n",
      "                   -8.4623e-03,  1.8323e-02,  6.8633e-03, -3.7043e-02,\n",
      "                   -2.9463e-04,  2.3252e-02,  3.6450e-02, -1.2910e-03,\n",
      "                   -7.2811e-03, -5.8184e-04, -4.3147e-02,  3.3414e-03,\n",
      "                   -5.4628e-03,  3.9025e-02, -3.9029e-02,  3.0167e-02,\n",
      "                   -2.2537e-02, -4.3034e-02,  2.3152e-02, -1.3471e-02,\n",
      "                    7.4089e-04, -3.6417e-02,  9.9198e-03, -2.1442e-02,\n",
      "                   -2.8777e-02, -1.0006e-03, -2.5655e-02,  4.1623e-02,\n",
      "                    3.1844e-03, -8.8853e-03, -3.0255e-03, -1.5757e-02,\n",
      "                   -2.2895e-02, -1.3092e-02, -6.0798e-03, -1.1200e-02,\n",
      "                   -3.7636e-03,  4.4733e-02, -7.3405e-03,  1.1803e-03,\n",
      "                    1.4185e-02, -8.2482e-04, -3.3223e-02,  2.1248e-02,\n",
      "                    1.7691e-02,  2.0752e-02, -1.4089e-02,  1.2450e-03,\n",
      "                    3.0040e-02, -3.1434e-03, -1.5892e-02,  2.1488e-02,\n",
      "                   -1.8086e-02, -2.4591e-02,  6.0147e-03,  8.5181e-03,\n",
      "                    2.3395e-03,  2.0770e-02, -2.5492e-02,  2.7234e-02,\n",
      "                   -3.9734e-02, -1.3074e-02,  2.3744e-02,  5.3098e-02,\n",
      "                   -4.2583e-02, -3.4656e-02,  2.9575e-02,  1.1043e-02,\n",
      "                    2.6371e-02,  4.7262e-02,  2.8654e-02,  3.4467e-02,\n",
      "                    3.8536e-02,  2.0936e-02,  3.5364e-03,  1.7638e-02,\n",
      "                   -1.7213e-02,  1.7654e-02,  9.7224e-05,  2.2422e-02,\n",
      "                    5.4881e-02,  3.5816e-02,  7.6844e-03, -4.3539e-02,\n",
      "                   -4.7994e-02, -3.7897e-03,  2.2580e-03,  6.3669e-03,\n",
      "                   -3.1047e-02,  4.3504e-02,  1.1524e-02,  1.5917e-02,\n",
      "                    3.5475e-02, -1.7889e-02, -4.2210e-02, -2.4898e-02,\n",
      "                   -2.1448e-02,  1.5143e-01, -3.1688e-03,  1.6015e-02,\n",
      "                   -1.2976e-02,  2.5507e-02, -3.7857e-02, -5.0126e-02,\n",
      "                   -1.4206e-02,  3.8659e-02, -1.3628e-02, -1.3048e-02,\n",
      "                   -1.5376e-02,  8.3982e-03,  5.0450e-03, -1.2704e-02,\n",
      "                   -1.2352e-01,  2.2781e-02,  5.7671e-02,  8.6453e-03,\n",
      "                   -2.4661e-02,  3.2401e-04,  1.7494e-01, -2.5875e-02,\n",
      "                    6.9146e-03,  6.9589e-03, -1.2310e-02, -2.0676e-02,\n",
      "                   -3.1215e-02,  2.1737e-02, -1.3505e-02, -1.1317e-02,\n",
      "                    4.4716e-02, -5.8199e-03,  1.4682e-04,  1.9941e-03,\n",
      "                    1.2020e-02,  3.5356e-02, -6.8063e-03,  3.7246e-02,\n",
      "                    1.8084e-02, -3.3085e-02,  4.6018e-02, -5.7314e-03,\n",
      "                    7.0747e-02,  8.1761e-03, -4.5427e-02,  3.4619e-03,\n",
      "                    2.8741e-02,  2.7757e-02, -1.6980e-02,  2.0948e-02,\n",
      "                   -1.7235e-02,  4.6781e-02, -2.6153e-02, -3.1089e-03,\n",
      "                   -1.1258e-02, -4.3819e-03,  2.4503e-02,  6.5297e-02,\n",
      "                   -2.6586e-03,  9.8658e-03,  2.0401e-02,  4.4188e-02,\n",
      "                    6.5789e-03,  1.8268e-02,  3.4622e-02, -5.6787e-02,\n",
      "                    3.8811e-02, -1.4932e-02,  4.0106e-02, -3.6967e-03,\n",
      "                   -1.1906e-02, -7.7245e-03, -4.6537e-02,  3.0130e-02,\n",
      "                   -1.8014e-02, -3.1737e-02, -4.9203e-02,  4.4373e-02,\n",
      "                   -8.8345e-03, -2.7907e-02,  8.6692e-03, -1.9348e-02,\n",
      "                    3.2177e-02,  3.5767e-02,  6.1270e-02,  1.2664e-02,\n",
      "                   -3.8160e-02, -5.3869e-03, -3.7373e-02,  1.7330e-02,\n",
      "                   -3.6659e-03,  2.0038e-03, -2.4450e-02, -1.8417e-03,\n",
      "                    7.3445e-03, -2.1012e-02, -1.0598e-02, -1.2650e-02,\n",
      "                   -2.8237e-02, -2.0378e-04, -1.4954e-01,  1.3411e-02,\n",
      "                   -5.7233e-02,  4.6249e-02, -3.3263e-02,  1.9972e-02,\n",
      "                    3.0342e-02, -1.2589e-01,  5.9007e-03, -2.5825e-03,\n",
      "                    6.0381e-03, -8.1158e-02, -2.0704e-02, -2.2926e-02,\n",
      "                   -1.2810e-03, -8.0435e-02, -8.9056e-03, -2.0759e-02,\n",
      "                    9.2392e-03, -4.3850e-02,  2.0677e-02, -3.7552e-02,\n",
      "                   -1.1224e-02,  1.1407e-02, -8.8814e-03,  8.8301e-03,\n",
      "                   -1.7247e-02,  1.6011e-02,  3.3807e-02, -2.1457e-02,\n",
      "                    2.3169e-02, -4.5567e-03, -3.5863e-02,  1.5935e-02,\n",
      "                    2.8699e-04, -9.4694e-02, -6.2402e-02,  1.2779e-02,\n",
      "                   -6.9977e-03, -2.4104e-02, -4.4547e-02,  3.1339e-02,\n",
      "                   -4.5173e-04, -2.3028e-02, -2.0369e-02, -7.8063e-02,\n",
      "                   -6.2592e-03, -3.6600e-02,  4.0395e-02, -5.0514e-03,\n",
      "                    2.6424e-02, -2.5897e-02, -3.8298e-02,  1.3856e-02,\n",
      "                    1.4890e-02, -8.9756e-03,  1.5355e-02, -1.1808e-02,\n",
      "                    9.6809e-03,  6.9300e-03, -4.0419e-02, -1.3194e-02,\n",
      "                    3.3037e-02, -2.1257e-02, -1.7243e-02,  1.2995e-02,\n",
      "                    3.5032e-02, -3.9984e-02,  2.4041e-02,  8.0335e-02,\n",
      "                    3.1062e-02, -3.4194e-02,  2.0656e-02, -7.0050e-03,\n",
      "                    3.1833e-04,  5.4622e-02, -8.2139e-03,  1.6004e-02,\n",
      "                   -6.9286e-03, -3.1179e-02, -3.4541e-03,  8.8354e-03,\n",
      "                   -1.5213e-01,  8.8205e-03,  2.7115e-02,  8.2347e-02,\n",
      "                   -3.1755e-02,  2.3920e-02,  3.1144e-02, -2.4743e-02,\n",
      "                   -3.9978e-02, -1.0348e-02,  9.2122e-03, -8.8909e-03,\n",
      "                   -5.0891e-03, -5.5980e-03,  1.5899e-03,  3.0880e-02,\n",
      "                    2.4196e-02,  7.1266e-03, -3.1497e-02, -5.1640e-03,\n",
      "                    2.3959e-02,  5.4253e-03,  1.8993e-02, -2.2996e-02,\n",
      "                    2.6786e-02, -3.2905e-02,  3.2550e-02,  1.5397e-02,\n",
      "                    5.1514e-03,  9.6660e-03,  3.9671e-02,  1.3605e-02,\n",
      "                    1.8803e-02,  3.1570e-02,  9.3623e-02,  1.9200e-02,\n",
      "                    6.5428e-03,  3.2298e-02,  3.0826e-02,  3.4992e-02,\n",
      "                   -3.4134e-04,  1.4949e-02,  2.1328e-02, -1.1701e-02,\n",
      "                   -3.2931e-02,  7.7771e-03,  3.7847e-02, -4.8962e-02,\n",
      "                   -3.1810e-02,  2.3901e-02, -7.1090e-02,  5.5769e-02,\n",
      "                    5.6937e-02,  8.5476e-03,  4.6316e-02, -2.4431e-02,\n",
      "                   -1.0679e-02,  1.3059e-02, -1.9230e-02, -5.5207e-02,\n",
      "                    3.1145e-02, -1.0662e-03, -3.9207e-03, -4.6654e-02,\n",
      "                    4.1676e-02, -2.6083e-02,  2.7997e-02, -1.6238e-02,\n",
      "                   -1.6692e-02, -1.1055e-02, -2.7720e-03,  4.7845e-02,\n",
      "                    3.2035e-02, -2.4046e-02, -8.8466e-04,  2.4262e-02,\n",
      "                   -2.1782e-02,  7.0880e-02,  6.9522e-03, -1.3840e-02,\n",
      "                    5.0622e-03,  4.1127e-02,  1.2091e-02, -1.1178e-02,\n",
      "                    3.1940e-02,  3.9618e-02, -1.7101e-02, -4.5474e-02,\n",
      "                   -6.7567e-02,  5.0196e-02, -1.0061e-02,  2.4575e-02,\n",
      "                    2.3508e-02,  5.5895e-02,  1.0439e-03, -1.5794e-02,\n",
      "                   -3.6027e-03,  2.0523e-02, -4.1193e-03,  2.0783e-02,\n",
      "                    5.1353e-02, -9.0158e-02,  1.8478e-02, -1.8507e-03,\n",
      "                    1.4910e-01,  5.5743e-02,  3.3727e-02,  1.1750e-02,\n",
      "                   -1.8479e-02,  2.9415e-02,  2.4266e-02, -1.4923e-02,\n",
      "                   -4.0368e-03, -8.0456e-03,  4.5536e-02, -1.0015e-02,\n",
      "                   -8.0306e-03, -5.3667e-03, -1.0928e-03,  9.7155e-03,\n",
      "                    2.0120e-03, -4.4750e-02, -3.2639e-02,  5.4881e-02,\n",
      "                   -2.0713e-02, -7.2202e-03,  5.4546e-02, -2.1562e-03,\n",
      "                    5.1933e-02, -3.9225e-02,  3.0680e-02, -1.7855e-02,\n",
      "                   -5.4979e-02, -3.6237e-02, -4.1395e-02,  8.3237e-04,\n",
      "                    1.0661e-02,  1.8539e-02, -5.2327e-02, -2.6222e-02,\n",
      "                    1.5446e-02, -6.2984e-02, -4.2181e-03, -9.7963e-03,\n",
      "                   -2.7744e-03, -8.0148e-02,  1.1006e-03,  2.8619e-02,\n",
      "                    3.4225e-02,  2.5505e-02,  9.9647e-03,  2.0412e-03,\n",
      "                    2.6844e-02,  2.3324e-02, -4.7876e-02, -1.7830e-02,\n",
      "                   -3.5476e-02,  3.1916e-02, -1.3048e-02, -2.6120e-02,\n",
      "                   -4.4125e-02,  3.4059e-03,  3.3746e-02, -1.5056e-03,\n",
      "                   -4.4817e-02, -6.0471e-02,  4.5835e-04, -3.1197e-02,\n",
      "                   -8.8366e-03,  4.0780e-02, -3.2848e-03,  1.2745e-04,\n",
      "                   -2.0323e-02,  1.4204e-05,  1.8543e-04, -3.4822e-02,\n",
      "                   -3.7487e-02,  2.2887e-03, -5.6218e-04,  3.5746e-02,\n",
      "                   -3.4446e-02,  1.7526e-02,  1.0984e-02, -1.1984e-02,\n",
      "                    1.1170e-02,  2.3287e-02,  1.8330e-02, -6.6640e-03,\n",
      "                    7.1425e-02, -9.5297e-03, -4.1384e-03, -3.1017e-02,\n",
      "                   -3.4313e-02, -6.1358e-02, -2.1505e-02,  3.0887e-02,\n",
      "                   -2.9941e-02,  6.5761e-02,  1.1370e-02, -3.2851e-02,\n",
      "                    2.5724e-02, -9.7549e-02, -1.8661e-02,  5.3381e-02,\n",
      "                    4.1002e-02, -1.8873e-03,  3.2428e-02,  6.9185e-03,\n",
      "                   -1.6632e-02, -1.0919e-03, -2.1888e-03, -5.5683e-02,\n",
      "                   -3.5126e-02,  1.1802e-02,  1.9351e-02,  9.5941e-03,\n",
      "                    1.9648e-02,  2.8356e-02, -4.6589e-03,  9.6013e-03,\n",
      "                   -9.8995e-03, -2.9428e-02,  4.8408e-03,  1.0526e-02,\n",
      "                    2.3027e-02,  7.3073e-02,  3.4499e-03, -1.0482e-02,\n",
      "                   -5.0735e-02, -5.4746e-03, -1.3002e-02, -1.7091e-03,\n",
      "                    4.6354e-03,  4.7631e-03, -4.4059e-02,  1.5419e-02,\n",
      "                   -8.6607e-03, -1.8564e-02,  1.1261e-02,  2.9089e-02,\n",
      "                    3.4540e-02, -1.4337e-02, -1.7087e-01, -1.4072e-02,\n",
      "                    1.1486e-02, -1.7160e-02,  3.7681e-02,  5.2096e-03,\n",
      "                   -1.3986e-02, -2.9453e-02, -2.0093e-02,  4.9826e-03,\n",
      "                   -6.0402e-03, -1.5152e-02, -4.8931e-02,  1.5018e-02,\n",
      "                    9.0948e-03,  1.4047e-02, -5.1250e-02, -1.9193e-02,\n",
      "                    5.9618e-02,  5.4084e-02, -8.5869e-03, -2.8576e-02,\n",
      "                    7.3871e-03,  4.7424e-02, -4.3804e-02,  5.3563e-02,\n",
      "                    3.3042e-02, -9.3803e-03,  3.5111e-03,  1.4866e-02,\n",
      "                   -6.2368e-02,  1.1829e-02, -2.6612e-02, -1.5571e-03,\n",
      "                    2.6156e-02,  2.3897e-02, -8.0603e-03,  1.1252e-03,\n",
      "                   -7.1897e-02,  7.2561e-02, -3.0975e-02, -2.3715e-02,\n",
      "                   -2.6798e-02,  1.3944e-02, -4.7896e-02, -7.7167e-03,\n",
      "                   -2.8434e-02,  5.7065e-03, -3.2635e-02,  2.6741e-02,\n",
      "                    1.0465e-02,  1.8881e-02,  1.3182e-02,  2.3640e-02,\n",
      "                    4.7310e-02, -1.8673e-02, -3.9348e-03,  1.3646e-02,\n",
      "                   -7.8557e-04,  2.0129e-02, -1.0061e-03,  4.2392e-04,\n",
      "                    2.2411e-02, -1.9293e-02,  4.7464e-02, -1.9804e-02,\n",
      "                    2.5959e-02, -8.5555e-03, -2.4415e-02, -9.8968e-04,\n",
      "                   -4.1986e-03,  3.2624e-02, -2.7910e-02, -1.0028e-02,\n",
      "                   -7.7741e-03, -1.1161e-02, -2.3405e-03, -2.3083e-02,\n",
      "                   -1.2386e-02,  2.0043e-02,  6.0855e-03,  7.7199e-03,\n",
      "                    1.8650e-03,  2.4150e-02,  2.6810e-03, -1.5613e-03,\n",
      "                    1.7955e-02,  1.0073e-01, -1.5043e-02, -1.4634e-02,\n",
      "                   -3.4132e-02, -4.5279e-02, -5.6860e-03, -2.3660e-02,\n",
      "                   -5.3413e-02,  2.7590e-02,  1.5180e-02, -1.8776e-02,\n",
      "                    3.4847e-02,  3.2584e-03,  5.1717e-03,  3.7879e-03,\n",
      "                   -2.5142e-02,  3.6746e-02, -1.6135e-02, -2.6658e-02,\n",
      "                    2.5618e-02, -3.2077e-02, -1.1796e-02,  6.8987e-03,\n",
      "                    3.4107e-02,  5.0101e-02, -1.5238e-02, -1.0167e-02,\n",
      "                    2.3758e-02, -1.3457e-02,  7.6280e-04,  1.4361e-02,\n",
      "                   -6.6225e-02, -2.8060e-02, -2.0991e-03, -3.3067e-03,\n",
      "                   -5.5176e-02, -2.1878e-02,  1.3979e-02, -6.6446e-03,\n",
      "                    7.6093e-03, -2.5024e-02, -4.0091e-02, -9.5097e-03,\n",
      "                    3.1341e-02,  1.5841e-02,  4.7786e-02, -1.5769e-02,\n",
      "                    8.5900e-03,  2.2712e-03,  1.4260e-02,  7.1511e-03,\n",
      "                    3.2053e-02, -2.7303e-02, -1.4749e-02, -1.8338e-02,\n",
      "                   -1.1167e-02, -1.7164e-02,  3.5994e-04, -3.6878e-03,\n",
      "                   -3.6313e-02, -3.7253e-02,  1.0259e-02,  1.5338e-02,\n",
      "                   -8.1879e-03,  8.6854e-03, -3.7732e-02, -3.8490e-02,\n",
      "                   -2.9558e-02, -3.6192e-02, -7.8468e-03, -2.9167e-02,\n",
      "                    4.2909e-02,  2.1192e-02, -3.5619e-03, -2.7651e-02,\n",
      "                    2.0726e-02], dtype=torch.float32, requires_grad=True))\n",
      "Radius: 0.6369348323554911\n",
      "Distances to center: tensor([0.6094, 0.5772, 0.5831,  ..., 0.5873, 0.5978, 0.6133],\n",
      "       dtype=torch.float32, grad_fn=<MulBackward0>)\n",
      "Max distance: 0.7861164212226868\n",
      "Radius: 0.6369348323554911\n",
      "Number of points inside radius: 154026.0/158700\n"
     ]
    }
   ],
   "source": [
    "curvature = 2.3026\n",
    "epochs =50\n",
    "\n",
    "# fit the SVDD model on the benign points\n",
    "benign_alt_model = test_svdd_fit_alternatively(hyper_points=benign_points, curvature=curvature, nu=0.05, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b8d7f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malicious predictions: tensor([0, 0, 1,  ..., 0, 0, 0], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "malicious_predictions = benign_alt_model.predict(malicious_points)\n",
    "print(f\"Malicious predictions: {malicious_predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc48289f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of malicious points classified as benign: 20670\n",
      "Accuracy on malicious points: 0.8698\n",
      "Benign predictions: tensor([1, 1, 1,  ..., 1, 1, 1], dtype=torch.int32)\n",
      "Number of benign points classified as benign: 154026\n",
      "Accuracy on benign points: 0.9705\n"
     ]
    }
   ],
   "source": [
    "# print the number of malicious points classified as benign\n",
    "num_malicious_benign = (malicious_predictions == 1).sum().item()\n",
    "print(f\"Number of malicious points classified as benign: {num_malicious_benign}\")\n",
    "# print the accuracy of the model on malicious points\n",
    "accuracy_malicious = (malicious_predictions == 0).sum().item() / malicious_predictions.shape[0]\n",
    "print(f\"Accuracy on malicious points: {accuracy_malicious:.4f}\")\n",
    "# get the model trained on benign points and predict on beign points\n",
    "benign_points_with_time = torch.cat(\n",
    "    [\n",
    "        torch.sqrt(\n",
    "            1 / curvature + torch.sum(benign_points**2, dim=-1, keepdim=True)\n",
    "        ),\n",
    "        benign_points,\n",
    "    ],\n",
    "    dim=-1,\n",
    ")\n",
    "\n",
    "benign_predictions = benign_alt_model.predict(benign_points_with_time)\n",
    "print(f\"Benign predictions: {benign_predictions}\")\n",
    "# print the number of benign points classified as benign\n",
    "num_benign_benign = (benign_predictions == 1).sum().item()\n",
    "print(f\"Number of benign points classified as benign: {num_benign_benign}\")\n",
    "# print the accuracy of the model on benign points\n",
    "accuracy_benign = (benign_predictions == 1).sum().item() / benign_predictions.shape[0]\n",
    "print(f\"Accuracy on benign points: {accuracy_benign:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8864b19c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6791493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "safe-clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
